{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raymond.djajalaksana/anaconda3/lib/python3.7/site-packages/gym-0.17.1-py3.7.egg/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym_anytrading\n",
    "window_size = 10\n",
    "env = gym.make('forex-v0', frame_bound=(50, 2000), window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "nb_actions = env.action_space.n\n",
    "max_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.08977e+00 -1.00000e-05]\n",
      " [ 1.09073e+00  9.60000e-04]\n",
      " [ 1.09039e+00 -3.40000e-04]\n",
      " [ 1.09054e+00  1.50000e-04]\n",
      " [ 1.09090e+00  3.60000e-04]\n",
      " [ 1.09087e+00 -3.00000e-05]\n",
      " [ 1.09070e+00 -1.70000e-04]\n",
      " [ 1.09097e+00  2.70000e-04]\n",
      " [ 1.09105e+00  8.00000e-05]\n",
      " [ 1.09091e+00 -1.40000e-04]]\n",
      "info: {'total_reward': 15.799999999963674, 'total_profit': 0.8483603717624304, 'position': 0}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEVCAYAAADn6Y5lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOy9e3xcZZ34//7MJGk7KS10WhFaMhFkWdEAQr2seE9doUi57ArrnkJpZdM2+tugK152dgV0Z1fFnxJlkzZiS0vPD5evCwISRFsVFGWhfMUGiqwFk1DKpU1tS5O2uczz++OcSeZyzpkzt2Qy87z7mlcz5zmXZ2ae8zmf5/N8LqKUQqPRaDTVQ2CqO6DRaDSayUULfo1Go6kytODXaDSaKkMLfo1Go6kytODXaDSaKkMLfo1Go6kytODPARGZKSJKRBZNdV8KQUS+JiK3TXU/NKVBRG4RkVsn6VpvF5FnROSwiKwQkTtF5B8n49qa/Jn2gt8ecIlXXESOJL03shx7gYjsKmJfHhORo/a194rIXSKyoFjnnwpEpF5E/ltE+uyH3rvT2r8mIiNpv8PJHuf7J/tch0Tkf5LPJyIBEfm2iPxZRPaJyL+lHfsOEXlKRIZE5HERedtkHFsoInJT0ndzVERGk94/6eP4p0Tkb4vUl0tFZMy+9uu20L6ygFP+C3CXUmq2UmqTUuoTSqnvJF3r6Rz7VyMit4rIAfse+nKW/b8kIv0iclBEfiMi5znsU2/v83Ta9o+JSI/9Pfxvsryw23ba590rIj8Qkflpxy+zjx8UkV4RuTCp7a9EZIc93n4rImfk8j2UHKVUxbyAXmBJDvtfAOzKYf+ZgAIWubQ/Biy3/54H/BL4/hR+HwEg4LD9a8BtPs8RAv4ROB/YD7y7gHO9HzgEnG337TrgpaT2NuBp4CSgAfgjcI3dNgvYA7QCM4Dr7faaUh5bgt9kDbA1x2OeAv42h/1vAW51absUeDppfFwNjACnOOxb4+Na2936lnytHPr+BeD/Am8ATrXv6b9z2fev7TF5pv1Zvgi84LDfzcAjyX0B5gJHgCsBAT5gvz/Vbj8ZODFp/HQCm5OOf5c9pj4IBIETgYjdNhvYC6yyx9u/AM/gcC9O1WvKO1DUD+Mg+O0f7T+Bl4Hd9iCoBcL2Dx0HDtuvMJaA+x/goP3DfjtJQPgW/Pb7zwJPJr0PAv8KvADsA0zgeLvtv4BP2X+/2b7OKvv924BX7L8XAA/aA2s/cC9wUlofvmJ/hqPAIvt8jwKv28eux6ewTvt8+yhM8K8AHkl6H7Y/5wn2+/8LXJ3U/ingl/bfy5Jvaqwb/RXgg6U8tgRj1FHwA0uwBPxB4DfA2+3ttwJj9lg9DMTs7d+3x+ch4LfA4qRz+RL8SduG7eufY1/jU8BLwP12+yeAPwB/Bh4C3mRvfzKtb28AfgR8DktwHrHbE/dXvY/vZydwRdL7fwJ+4rLvauCnSe8X2uNpVtK2t9nf68dJFfxnAMfSzvdH4EKH64SwZMhvkrZ1A//k0q8rgJ1J72twUJqm8jXtTT0+uAk4C2gCzsN6Qn9eKTUAXIYlEGbbrwEs7efTWBr7+4CLgWtzvaht4rkUSDYlXY+lpbwXSyCPYD1YAB62+waWZvwClhaSeP+w/XcAWIelmb7J3pY4R4LlWJrccVgC7i4sjScMfBO4Kq2vz4nI5bl+xiT+VkT229Ner+/qfmC2iJwrIjVYGtH/KKX+bLefCfw+af/fA2+1/35rcptSKo6lpb+1xMfmhIhIHscsxBKYNwLzgc1At4jUK6U+DfQAV9ljNGof9ojd7zDwM+C/RCSn+1lEgiJyDZbys9PeHML67KcBV9imk/XAJ7G02u3APSISUEqdl9a31xLnVkrtwXpgPJt0fw2KyEUi0ufSnxosgez3t7gHWCAiZ9nHrgQeVkodsc8nWJr6Z7HutXGUUs8BW0Vkuf09NANzgMeT+tMkIgeAQfvzfzPpFO8GQiLyBxHZIyK3ichxdlv6eBu1v9+8xlQpqAbBbwA3KKX2KaVeBf6NNMGXjFLqcaXUE0qpMaXU88BtTAhgP6wXkUPAa1izjc8kta0GvqiU2qOUOor1ULrSHqAPYwl47P+/lvT+A3Y7SqlXlVL3KqWOKKUOAv/h0L/blFLPKaVGsKbLZwI3KaWGlVLbgJ+kfeYzlFJ35/AZk9kC/CXWTORTwH+IyGUu+x7AmqE8jjUb+RyWBoyI1GJNiw8m7X8Q6+EF1vQ5uW28vcTHpmALiX+2H5Yvich37QfZQhH5PJYykSuXY2mTP1JKjSil1mF9Vx9xO0BZ9vQD9m/8VSxF4BSf13uLLdBew1JyrrAFNVhmj39VSh21BejfAz9QSj2qlBrGGrNvwlKmckYp9YBSKuLSPAtLJvn6LYABLM37d1jjqRVrDCa4BtitlPq5y/Gbge8Cx+zztNnKX6KvPUqp47EeeP+GrcSJSAg4AevB9lGs++sUrHsWPMabSz8mnYoW/LZAfSOQrGH0YU0J3Y45U0QeFJFXbQH+ZSwtzC+rlVJzgHPta5+c1JdTsDS5A/aN9zus3yCMpREERORMrBnBPcDrIhIhSeMXkeNEZIO9WHUI+KlD/15M+vtkYK/9oEn+DoqCUupppdQr9oPyEawpsdtC5KewbKpnYAnbfwB+IiILbAF2DEvrSjAHyzwFlqkguW28vcTHpvNmrO/7nVi/8R7gTixzyxuxTGm5cjKZv4nrOBWLL9sLkoewzH41+B+nzyqljldKhZVSi5VS9yW1DSULv/S+2cL/Zbe+FUjC9Or3t/gs8DGs32QG1lrUz0TkBBGZh3Xvfs7pQBF5B5ZStwyoAxYD3xCR96fva89kfog1KwPLNBYH1iul+pRSB4BvAEvtdtfx5vI5Jp2KFvzKMrC9AiRrGA1Y9kuw7IHpfA/L5nuaLcC/gqUF5Xrt32ENhluT+vIS8GH7pku8ZtqzEYU1fTeAo0qpfVjCfjXWTZ2Yin8Ry0z0Drt/f+3Qv+TP9TIwX0Rmpn0HpUI59CfB2cC9Sqnn7QfFfVia7bvs9p32Psn7P2P//Uxym23WeFtSe6mOTeePSqnPKqUO2rOv/7BnTA329iMux3mxh9QxCt7j9GNYpoeLsRYpF2CZMnIepw6kXyulb/YM6aSkvuVyLu+dLZPIc/j/Lc4G7lZK/ckeTz/EEsrnYc1ITgaeFJFXgI3AGSLyiv1QOBvYrpT6lVIqrpTqAX6OdT85UQM0iEhtkunG7fOlj7carFmB2+eYdCpa8NvcCdwgImEReQMQxTJPALwKvEFEZiftfxxwUCl1WETeiqWV5sttwGki8lH7/TrgayJyCoCIvEFELk7a/2Hg/2HCnv9LrKn4I/aDIdG/IeCA7V72L1n68L9YC3P/KiJ1IvIhLG8m34jIjKQHR13yQ0RELhORubYW+ldYWv29Lqd6AlgmIhF7/6VYQiXxUNsMXC8ib7S/o+uA2+22nwGzRGSNiMzAMqENAr8u8bEp2OsDxeYe4D0icrFY7oz/gLXGtNVufxXLZJfgOCxBvw9L0/13LMeBUnAnljnyr0SkDss5oQ/Y4ePYV4E3isisHK63GfiiiCwQkTdhjf/bXfZ9ArhURBbZ4+lSLLPMH7AWyCNYC9bnYP3mz9t//xlrYfpcsd2J7Zn2R7Bt8yJypYicap/3JCwl7hF7hgjWg2S1beI7Dmtm8WO7rRtLrlxjj7fP29/F+PrBlJPvqnA5vnD26glhLfC8gqW9fAuos9sE6yEwgKV5zgOasYTlYSzB++/YXhjk6NVjb7sB+LX9dxDLXe2PWNO+XVjrD4l9z7bPf6X9fgHWlLItaZ8GLIF1GGuAtwKjWfrwF1g3wmEcvHqwboi/8fheX7H7lfx6o912N9aNdBh4FlibdNwMe/s77PcBLDvoi/bnfybxWZPav22fbwDbgyWp/R1YHhpHsG76t03GsUUeo25ePX+NJXQOYpmNzktqW4K12P9nLHv+DOAHWB49u+0xcADbs4ccvXqS2s4BDjtsX46liR/AeoieltSW4mqK7dWT9L3eheXRcgCox5qt7Pb4fmqwZskHsB5syffHXHs8NSXt+037OziEtdB8ud/PjbUY/Ad7LPalXetLQD+WgrAH64GU7D0XsK+9H2ut5HvA7KT299j9OWL/nn9ZqjGVz0vsTmo0Go2mSqgGU49Go9FoktCCX6PRaKoMLfg1Go2mytCCX6PRaKoMLfg1Go2mytCCX6PRaKoMLfg1Go2mytCCX6PRaKoMLfg1Go2mytCCX6PRaKoMLfg1Go2mytCCX6PRaKoMLfg1Go2mytCCX6PRaKoMLfg1Go2mytCCX6PRaKoMLfg1Go2myqiZ6g6kM3/+fNXY2DjV3dBoNJppxZNPPrlPKbXAz75lJ/gbGxvZvn37VHdDo9FophUi0ud3X23q0Wg0mipDC36NRqOpMrTg12g0mipDC36NRqOpMrTg12g0mipDC36NRqOZJMwek8ZbGgncFKDxlkbMHnNK+qEFv0aj0UwCZo9Jy/0t9B3sQ6HoO9hHyw+WY35oPpiT+wDQgl+j0Wgmgei2KEMjQynbhuoges4AtLRMqvDXgl+j0Wgmgf6D/c7b5wJDQxCNTlpftODXaDSaSWDerHnODQrMJqDPd+BtwZRdygaNRqOpJlQAVl1i/W1M0jW1xq/RaDSTwP4j+13bhmsg2jx5fdGCX6PRaCaBhrkNnu39cyepI2jBr9FoNJNCrDkGyr294eDk9UULfo1Go5kEjB0QHHNpVBD7hUxaX7Tg12g0mskgGkW5SVwFxu/VpPnya8Gv0Wg0k0F/P3E3pT6xfZJ8+bXg12g0msmgoYFg3LlpfHu/c5BXsdGCX6PRaCaDWIyWpwKZC7wKZo3aQVwN3p4/xUILfo1Go5kMDIOOKzezascsJM7EA0Dg8AxYfjnINX3U3CC0fmtJSbuiBb9Go9FMFoZB3eW/YkbwxAm7fgKxXmMB6Dy0raTCXwt+jUajmURGxuIcVa957yTQdXBbyfqQVfCLyAYReU1EnnZpFxH5jojsEpEdInJuUtvXReRp+3VlMTuu0Wg00w2zx+QHLy7DM5LLZqyEbv1+NP7bgQs82i8ETrdfLUAngIhcBJwLnAO8C7heROYU0lmNRqOZFpgmNDZCIGD9b5rjhVgGx17xdQo3D6BikDU7p1LqERFp9NjlEmCzUkoBj4nI8SJyEnAm8LBSahQYFZHfYz1A7iq82xqNRlOmmKZVWGXILrrS1wctLUT/eRZDo0PexyZQ0LK9dF0sho1/IfBi0vvd9rbfAxeKSEhE5gMfAk4pwvU0Gs1U46DRamyi0Qmhn2BoiL6RAd+nCI5Bx85IkTs2QTHy8TtZopRS6qci8g7gN8Be4LfAqOMJRFqwzEQ0TJIfq0ajyRMXjRYAY7IyypcxDkFYZpMlKLNb9q2dNv04CLFYsXs2TjE0/t2kavKLgD0ASqmYUuocpdRHsD73H51OoJTqUkotVkotXrBgQRG6pNFoSoaLRjuZpQPLGgflNdoMyu9irQLjc5tK+hAthuC/D7ja9u55N3BQKfWyiARFJAwgImcBZwE/LcL1NBrNVOKWVmCS0g2UPbEY5nm1NF4HgRug8TroyyHXfl1NXclnTllNPSJyJ/BBYL6I7AZuAGoBlFLrgG5gKbALGAJW2ofWAr8SEYBDwHJ7oVej0Uxn5s3DPHmAaLNVPKThIMS2gbHHpaZslWGeBS3LhCHbrtN3PD5tPBbD8eGS9CsZP149n8jSroBPOWw/iuXZo9FoKgjz9KOsWmKVCwRLsK26BNh6dNJqxpYz0W1RhlSa8J68VPu+0JG7Go0mJ9reNzgu9BMM11jbNdB/sDCTV3hWuEg9cUcLfo1G4x/TZCDk3OS2vdrIVls3hTQTUO0otL9yTnE75IAW/BqNxj9enjtlZs6YKmIzlhIaSdvoYuOvPwaRAyDK+n/jvWC0/6LkfSyGH79Go6kW+vupPwaDMx3aFDR+Rog9Fca4tr1qffqNr3fDHGi7wJ4F2Vk306kdhfUPgNGT3lLCXA02WuPXaDS+MT8wj6O1Lo1iLfS2vGcA89srqzeat78fowdmj+AS3gqBOFz7pJPQnxy04NdoNL5pO/8gY0HvfYbqIPq+keoN6LIDuFx99wXiAdj0drvqVjr19SXrWgIt+DUajW8GavyF4vTPpXoDumIxFNmzaw7VWRG9KQSDsH59qXo2jhb8Go2m6NQPM2n1Y8sOw4AZMxjzIV375wKRCIhY/28qbaqGBHpxV6PR+EaUv5wzg7WUNMlY2TM8TDBOVrNYw2AQensnpUvJaI1fo9H4xm+iMSVUrVcPAEpl1fhFQezUlsnpTxpa8Gs0Gl+Yna0Ecsg5Y/ZUqVeP7c0UOeixj4I1j4OxtmNy+pSGFvwajSYrZo/Jyj2dxJ0khtPDQKycNVVJNIoAS5/D+btRcOar0PF46VMzuKEFv0ajyUr0vjZGclwRLDRnzbSlvx+zyXLXdPTjF3huAdDePskdm0ALfo1Gk5X+HMoGJsgpZ00lMW8e0WbLXdONsQBTugaiBb9Go8lKg5e9GgilZSEO1YaINVevV0+2wivBHNZKSoEW/BqNJiuxp8LuxUQEVrxnLQlxEpQgK85egdFUpV49+/d7B28paHli0nrjiBb8Go0mK8ZbrvBs3/T7TSSSi42pMTb9flP1evU0NLi7cipY+zh07IxMapfS0YJfo9Fkp7vb1T0xKEGGRlKLrw+NDFWvV08sRsMh54CHyEHo2FY35cFtWvBrNJrs9PcT2+Zgyx+2NHzHQ6rVq8cwuPHUFmal5eQPDUPssXrYsGHKg9u04NdoNNlpaMDoga77UwuHdP0mTKTG2R+9oaZ6i6//zbXfJaT+iXkzTkYQInMjdP3dFozfHp5yoQ9a8GvSMU1obIRAwPq/WnOqa1KJxSAUwuiB3lsgfhP0doUwrm0ntjVzJiAKlj75+tT0tQxQCmaPfYivn/8r4jfE6b2ut6wWu7Xg14xjdrYyf8dy5Jo+5MuK+Vf0VXdBjQrH7Gyl8foaAjcKjdfX0PqtJTTe0kjgpgCNtzSmLs4aBnR18ecFJxHHziTZ1QWGgfHwflb8jhSvHyXQedYwS7721kn/XGWB/V2IlGc9Si34NYAVkr/ilc6UUnED9bDqwhHM29qmunuaImN2trJyTyd9s8dQAn2zx+g8tI2+g30oFH0H+2i5vyVD+H9j3UO8699+amWUTJgsGhrYcC6ZUaoC247upPWB1kn6VOVHeYp9LfirDxdTTtuDbY4uaMM1ED0n96hNTXnT1tuZmYIhTUo5eeaMjsWpCaTuaF7+Zo65pXMQ6Npe+sIi5YZyDXooD3Q+/mrCNKGlBYZs17u+Pus9MHDEXbj3Z4lC1EwzTJOBWf527TvYB8CSzUvY9qdt4yaMJf9Qx9YPWt4p0eAvPVXbMVX64uHlhho39UxtP9zQGn81EY1OCP0EQ0PQ5m3KaaiduiyCmhKQQy3coARZ8s8L2fbCNmuDbQbctnCYJQ8tB9Okv97ZnXP8HNUn98cpU7mfXfCLyAYReU1EnnZpFxH5jojsEpEdInJuUts3ROQZEXnW3qdcv4fqwK0G6sCAezi+gtg876hNzTQjh1q4Y/ExttXtcbbfnwq0tXnn8VHQ8lzpi4eXG+Vt6PGn8d8OXODRfiFwuv1qAToBROQ9wPnAWcDbgHcAHyigr5pCSauBajZB43UQuCHLcXfdVbo+aSYd8wP+/euzausDA46BXSjrtXa70LGsCm38tq2nXHXdrIJfKfUIsN9jl0uAzcriMeB4ETkJ66efCdQBM4Ba4NXCu6zJGztMvPVCkC/D8suh73i7TJ7gXlBDL+5WFNEl+LZBZKsZC2AcimQEdm25G9RXA3R84o6yCFiaKspU7hdlcXch8GLS+93AQqXUb0XkF8DLWMPsVqXUs0W4niZfDIMlP1nOttNwLRDhhF7crSz6RnN8kLuMixmj9h+xGEZLC0bPxPqRAgifkE/3KoJKMPVkw2lYKBF5M/AWYBHWw+HDIvJ+xxOItIjIdhHZvnfv3iJ0SeOE2WO6C30PAhJwDurRTEuC+dz2aZJM4vD9+4DZs8eDuwhPOAEIWGtHV10FrdXnxz/u1TO13XClGIJ/N3BK0vtFwB7gMuAxpdRhpdRh4EHg3U4nUEp1KaUWK6UWL1iwoAhd0jgR3RbNfSQqGCM+HtRz1d3LqzogpxLI170yPDhhyrnjHjB6gBkzrEbDgNmzMZtg/vUgN1iv+Z9TmL/urN7o7zK19RRD8N8HXG1797wbOKiUehnoBz4gIjUiUou1sKtNPVNIztkSFRkPCgV0PtGpNf9pjFt6ZU8EBkJwx91Wrh6jx96+f2L5z5zTx4pLrYjvlOjvS6i66O9yD+Dy4855J/Bb4AwR2S0inxSRNSKyxt6lG3gB2AV8D0iogz8Engd6gN8Dv1dK3V/sD6DxT9FqoAq03bO6OOfSlAaPZHuxp8LUjboe6Y7A1ZdZ3mDjJHmKtV0UcFwMrsro7zI39WRd3FVKfSJLuwI+5bB9DNDSoYyINcdYedfyzFD9PBiIDxZ+Ek1p8IjQxjDgiitQezrzOnU8AG0X2Bp/KJRSUGRgprsJqdocBBL6fplaenTkbjVhNBlsvNey1Zb5TFRTCNEo5mlD4zEajdeBedpEhHb0WHdBD/+BECnZOf1QrdHfUqY6vxb85UwJcuMbhyLsu9lnGH2WMWt26kXecuStF/alxGj0HQ8tF4N58oCVYqHQylhCanZOm/Asd+G+9Jzqiv5WZa5YacFfriSm63191ihKTNcLFf6xGMMzZroXg/aLQPSFrgJPoik2b/3Pt7LzRDIzbdbBiksh8MflBOKFSyWnxf32C9upDdQ67l+pxdfNHtOxhkFicVebejS54TZdzyHBliOGwY8/fROLXIpB50K25FyaycXsMdm5b6frTG0saM0AxgJkmPpqRyF8NIAoqD+a2Z6OUyF1o8lg46UbCUrmCm8lFl83e0xa7m9JrWFw11UpM+Eylfta8Jcr5pw+Wi52mK7P6Sv43DvefxEy9/OEpK6g8zS8rodPOZGTYE2k6FDWms/Ge2Hf1xXx2yPMP0pWidV/0HkcGk2Ga/H1PpdjpivRbVGGRlKz3Q7VKNp6O5l51w+mqFf+0HdumRL9aJChNLk8VGfl1xmfUua5BjAaj7Mg0EzXZRvyXuQNDUPsNz6TumsmhZxt97av/ZGEdaahAWIxXx44DQednwye5hxFRUXxuj3IBmbBj7d8DtCmHk2O9M12MaOINeBa7lnFkp8up+Zqqz5uzdV9tP7X1b6E/+iYIhgQjB0QyFXw25GbXfeD8T9D2ffXTBr5xmkM1UG0GVi6FAwjuweOgthW54GTddaxbl3FRPE6mbQAEPiXc/fbf5an5NeCv0wJiPdPM6SG2fYmO3uiWP93nhtnybYVnseZPSYdf7iAJ0b/mvk7lhPPcVwKSZGbDUUKCNMUhVhzLDM9sk/65gLd3dZ5lrUTqg157j8euZuG16wjGMdyVCh0napMcDNpQfnHLWjBX6bE/eRTcSqO0TDm6maZWIx6ffRlQE0UVs+B8aIbtbUpwTuaqcdoMug60kzDAcbt9zlhF2gxmgy6Ls7isRVwFh3zxOWBoeCMRP7Fvsqw9Udq3GdGwYTiVp4Kvxb8FYeHm6XTYlROKFj6nF285Z9HaPy/V2tf/jLDOG8lL/xnLfGbrJz4OQn/pBmc0WQQmRtx3C1yEFjtHJR/7JjL+BLYeaKd7iHoI8n/NCC2FdfvdwxLcStTua8Ff9lhL9jWH83/FG5ulsXwquhanORpNCfOipc7tfAvF+zYj+DICIJljsmp3m3aDC7WHMsw+YSGISbN0NHheIrDtR5PGrHSPTBWGW7AxsP7qXH5KCfMLO9IZS34ywnTxLz5KuZf0cfgjPxP0zDorFFlWzcAy58bJ2GhrBzs6Um4xoKwend+eV80RSYancjPY/PBP+FL6xchIxI3YfKJzI0gCJG5Ebr+bgvGt7bm3cXxdA8VQOvHQ4y6TF7KvfRiMSpwaYqEecsnablIZbhx5oSC2Kktjk2u6wZJgmHOMTjnVWHbm1TKPDWgrARdTgzWYmmbVVxiryxIK6JuNsHPT8WXvWHN4rWO240mA6PJ/+8aHrLTMntRIWtDXWcecW07cGw/c9GmHo0Pou89VpjQB+pGwZhzfu4HJuVP//mpKmPEugn9cSrEU2NakojnUAqzifFo7+WXgcr2uylYu7OejoucTTe50v5E2Jo1enX3rKJcasoZc5waW7i6epYJWuMvI4riAiZ20YuzrMXc/oP9NMxtINYcIzwrzMARh7zoDsVWciGgyNA2NZOEaWJ+cwVtV4xZZhSY+D2zqZvK0tDPf7Z4KbaNa9vh2yu5+qIRZ2VBYNXd11j75jCTmG4kXD3L1NKjNf5yoiGfykhpDNdA2zsGMnKIXPXfyzknfiJ1wfynFHUjZD4VFKx+Au3TP0WYt65m5cfGUqpe+cae4bVcnCXiNhcMA+MzG9n8SNhVgxhmdNrl7XFLxubGwtlWNVot+DVZiW2jKHnyB0JkuG0qgZ8f3cmq0PsIxheAvVjnlkpXHAT8SA2pgiV5nwqx2043ou8eLLiwzlBdjnl+smEYGL/Y57nLdMrbY/aYrLhnRYoitfy/lzPTxaQlCB9s/Ci7Z6zkb+5r8PWgmGy04C8jjEMR6o957FDgQ0EJdL/0CxYd28it7/9feq/rpf3CzCjNUG2IDz+fJvzFwV5sa5id74TW4x8trHOavOgrUoRowTn6HfCq7ZuTm+kUs/r+1ZlRugJHgxBw+BwKxf/39PcZC+ydyNp5f0tZCX8t+MuJWIyZXi7OfqeNHvu9eJw1UgP2HNTRZe/iLna9IYDK4XpdT+rc/FNBsEgFP4pWjzkJrxnsWJmaQJwYHHFZAxFcU56kF1svt7TUenG3zNjvliJFkZv91mX/E4aAAASS2pxc9q6aszyHi3nnLdGUjpwK6niMoVhz8U11xp4wbUMDju6dXrOBaUUO92QpZlX5ojX+ciIaLcoCLzjY6BPb7YEayLLq1OASru96vbL1WK5s3NIqpFHUuPkAACAASURBVKAgcjjoKaRK4mHT3k77T8hIHBcatmcD04RAkcZ2KWZV+aIFfwnJ1ROA/n5i25xvFE/bfxqicDXT7LdT6AcC3oPZKVzfa42hvi5b1I6mFMSaY1nXfiLHR+i9edQ9906OD3nfGAbGMwG67rdSeUtySu+d5e3nnszqnaGC19dCtaGSzKryRQv+EuFUlu2qu6+i9QGPvDYNDRg9ON4o6x+AgE9risLyz3YiEIe+mRfzhUff6/kgcrL9N8880/UGGBwuni+4xsZHoR2jyfAWSgqWnr4UcMm9U2qBFI9j9FipvOM3JaX0nkb5ejr+zxBnvkruwt/OkBo5AF0Xd5VV3IKoMisHv3jxYrV9+/ap7kbBzP/GfMdgKVFwx4lrMdY6REq2tqI6O10nlq0XWh402Wae9Uctf/4MN780G2+oNuR7QCYeZG7ZPSM1YXqj3i58mhywE66l5N4JhaCrKyM1RuuVs+l8y6DruIjMjdB7Xa912h4zI7CvpAKpsdE5DXMkAr29pbtuMbE/g9xAzjkYIgeshx2TIGdF5Eml1GI/+2qNvwSYPaZzhCyWCSb6v53OVYi6u53HlQjU1dF9Br4G3uAMB6FP5rG5eBp4pnRWsHTHUczOVhqvryFwo9B4fY3O2lkIDgnXGBpyTI3REb7aUyNNXlQ0mgx6r+slfkOc3ut6S6+FxmLWAyuZUGh6xX3EYphn5ycq++cC4fLL1KkFfwnIJkz75+J4A5tz+sbzrDReZ+cuT7Bhg/+UDiXwNPDcT2DzqYO0vNRJ3+wxK2Xz7DFaXtIpm/PGLQVG+nbTxHz8NnaeiOvvPqWLioYBK1YQDwQty0cwCCtWTKuEfuZZsOqyQF4Z104YAq64ouh9KpSsgl9ENojIayLytEu7iMh3RGSXiOwQkXPt7R8SkaeSXkdF5NJif4ByJJswrR8mM5PiZ5fQcnFSrvvj7VD6Jqx0CIZBw/HFX4RrqJnnb78swmNwBgzVpm4bqoXlr3aWZeRi2eOWAiNtu3lbGy0fHfEUSlO6qGiasGkTgfiYFe83NgabNk2rurttD7YxTJbMcy4cnAnm47eV3ef1o/HfDlzg0X4hcLr9agE6AZRSv1BKnaOUOgf4MDAE/LSg3k4TsgnJw7Vk3MBRtS0jM+d4EWx7Wuy0OOfqRunHpKggds8hX4PS0cvHD4ni8GUWuVj2xGKYZ0vqDPBsyTCRRM8Z8MzoKsjULio6mKzM04Zo3L582pgE3cy2fhgLwuqPjJRd9tqsgl8p9Qiw32OXS4DNyuIx4HgROSltn78FHlRKFVD3b/oQa44REs+7kVnX7E4RhG5mnP65jE+LnTxt1ixeQy0FuMYN+xuUiWu7PWgCWR405Ra5WO6YT26k5SKVOgO8SGE+uTFlv2zmvzWL15Swlz5Im9m2XghXXZ40sy1zk2BOyoqbx9sMy4xbThTDxr8QeDHp/W57WzJ/B9xZhGtNC4wmg677xV3rFjgqY6y6d9X4wJrn8khM356+ONdx4HzmDDm4xvmxRyZK4flMqWw0Gdxx+R3UBtJsOgpqx6xaAF6UU+RiWWOa7jNAlRr51FDrvnC4dvHaouXZz5ukma3ZBOvemRljMlTrXid6qml7sK3wkyTuszKiGILfScSMizxb+28CHnI9gUiLiGwXke179+4tQpfKgGPHHBM4JTM8NjyhBc+a6byT2/YE0eh4UFY+DITIKaWy0WRw7bnXpm4UOFYLw0E8TUzzZvlbT6hqbDdOt+Rr6Rp+bFk7s0h9QoSkji2Xb5l6oQ+wdOn4n9Fm98DCPpc60VONHzNPbaCWLZdvIXzMXZwO5GElLSXFEPy7gVOS3i8C9iS9vwK4Ryk14nYCpVSXUmqxUmrxggULitClqSfaDHEfFpiEFrw/4Bya67Z94gT9had5yNG1rvuP3c4NueaD12QSjWKe5m4RTf+tjSaDf2vuIBhfMJFk77IN5RMs1G2NFbPJO5NosZLNTSaJ73vjpRsxmgyuWPChoqRVnwyKkaTtPuDTIvID4F3AQaXUy0ntnwC+VITrTCv8ul7OmzWP+d+Yn5HNL0FWV7yGBpY+1+crsMuJ8BA5u9bla7LZf8RrqUgDQH8/a76I6zzaKcfNx06/gu/8+I3c+vdv52NnnVzqHuZGfz9mE6y6BM/xmVOyuUnErWpdeFaYfZ9PDVjsDuyaNoqPH3fOO4HfAmeIyG4R+aSIrBGRxKpRN/ACsAv4HtCadGwj1mzg4SL3u+yZp7KYaACUNZV0m06GpC67K97Spdz1NvIacLWjVo3UXMnXL1ybenzQ0MBhD78A4w3NGdsSQaHZEu9NCQ0NtF1gRZJ7EY7PyNzoI2VFqWk/7oqMGsK1o9b2dLwUIrekiVOFH6+eTyilTlJK1SqlFimlvq+UWqeUWme3K6XUp5RSpymlmpRS25OO7VVKLVRKTaOyC8XhcK2PX9rjPg3Eoes+hbEjyzm6u/OzHyrY+OOgVSM1RxK5X3Ll8PDhvI6rKpZm+W537crYFLclfxmKfYjFfI3PATlG6xfear1pbWXJVYL8cTlyTR/yZcWS9/XB8uVWFPv8+ZP2EDC+3s3Ge1NzZ22819qejqtCpGDNEyXuaI6U6QSrTPGpgbQ+0MqxsRzSaToQFzCe9OFqmWeR8/ARMD63Ka8ISlcbfxYK+U7MHpP535iP3CTITcL8b8yvzLiA7m73lNouRe0TGn85Kvy+x5dA56ydtBonsOT1TradxsSakcC202BW1I5puGoA8+vLJ0f49/U5J5lzyD8Ua44RGk37ERQ0Pw8dO0uUATVPtOD3SyJpVl+fdaf19VnvHQZfUatROSW4SiabR47bxCMczjtsfrLrpZo9JlfffVWKSWzgyACr/vvqyhP+/f18+AUci9rPGAPzXZnq87jGX5aSPwcEOk8/MCH009qO1k7ENKy8BMxvrsj5EmaPyfyvzEZuFORGYf6Xgt4xBEEXDw2H7UaTQdfJa4gclPHZwZa7Yevd5ZebSAt+v+SQNMt3NSoPa1BdwgfKbeAliGXJx+6Wl7+AhdZgnsMmIPkd13bPauIOH3JY4kT/zxQHKBWbhgaeOglXwXfVRwdp/dYSx0PLVey7pQh3xOeHGKmBto/k5gJq9pis+OFyBtTg+ExiYGacVXs8Asjc0ke7bDfWdtB73h3Eb4/Q2y4YhyKOGVWnGi34/eI3aRYQFJ+RtB6DfDSxGJYlb7l56NG87vhCEneN5blks/q81XkdNxB3z/XfF6isdQPzC0s9beJKoPPQtpSZTlkv7gLtPyE3N0efHyPXta22H17r6D00XAPRXeudD4q4mGjctoMl5Ht7IR63/i8zoQ9a8PvHzaQyL9NTpeW8lsz9clzVHy/i7DXAsCMes90oadcutPhGvvVSz284P/eDsthxgxXmNhDdf1f231NSI0onTD0l7FgBGIcirH2ckvi452LqG5Cjrm39x6UOpPHqeSv7mP95mH99Us6k82rLznSTK1rw+yUWg9razO2vv54hnDoOnM/aJwMExwAFkodwCsbxlbe830/EozB+04VnhQuuBhT7uUc6Cg+W//dyjvvKrNzs8lkWt8vV/ztf+kf8JQRLXu9I/BTlqvETi9HxUAl+KIHofUVIqUBqYFxq9TxrZjFQn5QzaZlgnlWUy04ZFXbblBDDgDlzMJtIzZh4xnCmcIpG6bg/zuhXQd0EDYfIzRyjoOVJfNkGGwZzMyvtP7KfR/sfzaEzmRg7VH4anMBhdTS3RdksXkv5zj7KFd9R2IpxhSM+7tZTki4VjmHA5s1EDhW/g34flJ4oiD02UTPas+gQMKSGp33CQS34c8A8ecA5Z3565r00TxzfBVSS6OjGl20wdmoLIddkGJkoFOu2ryvMGyYcpuNBy2MhmEeKlWGJ+9bUWj/uZfC2I1nLLNd5ISzdU+87pXbCq6zcbfwAGAaxlXfkl9rbg3lD+Pr9Pce7AuPTEzb+fh9ea9M94aAW/DkQ/UjAOWPiR9O07rQbMNdcOuN269bsqWqNtR10LVxL5HDQtwauUEXRWIwe2PSj/KIS/WpqXWcecdVkw0O2T/WqVRUj/LvPmuk7s2rrByyvMlXOAVxJJFJ7F5M/zwLzG1dl/f2j26KuaTDWvnxyipLllik3mekeha4Fv19Mk77jnI31GZkF0worx7ZBaNj/pcbt1l3+bhJjbQe9N4+y5W+2+NaoCtJY9k+4gho9+a3ZBeIQuCmQtTrXGC4LJMr2FgEYdjC3TVP6R3262Qp0vtOabZa9jT8Jo8mwlJQiEQ9Ay8cU5rdXegp/r/HeYR5IPbbM0iuUAi34/RKNunqQBBWpEb1pGD3Qdb8V0OGHcbt1FlfOjOukFWoJz3LPw1NQHdY0D6ec7ezKqkykUFmrc3l57USbk+oS5xnBXG74LYUJWIubzRCPl7dXTzqxh8ZyUoSyMVQHbR/2jnJ3G++Rg2TE4+z3k2KigKpc5YAW/H7p73f1IBkTaLysD/NtyjXS1uiB3u8EOKn+FMf2BHWjSRkYswVvOV0nqVDLvs/vo/lNzUV35yQWszyOEm8dZjSu5h9FxpTbqzpXyxM4a2D2Gss1l9rC38GtdtphmsTuOZSTUOybO/H1TBfBbxyK0HU/RdWsB0LeVa4cS4cqqwyq2USK4uDHNOs7VqdM0YLfJ+YHPARLenF0XMb06tVc984vO7t3Kph9DDbca9utwVq8K6TPPSa/3f3bFEErCCvOXlFYvnbDsMxQkQiIpMxoEqHqax53MG953OhuU/GOnRGan7ePdTh+NAhrPpbvBykzolGMJ0dSvstsxXwALrjrL+ibeTGX3/P26ZHCIhbDeD5UXN9+8R4HidnwvCNJrshiuWkuvzzJicA0Wfpc9n75js4vU0Sp8jJoLV68WG3fvj37jpNM45ePoy+YPUo0PGjZnv+5GV6cC6cchH//uWCcvwY6Otjw8TP55JnPpj5yFax9HDoeTDtZgb9N4y2Njnl1InMj9F7XW9C5U3BRNc0mWH2RVXM028pjZGw2vV95PfMcn11Cy6zMMoQpKFBfEStScjoTCGT85maTJZj8rtyGakMFx2lMCqYJbW20vnOAde9Iq8yV78xFgbrR+56Zc2M9r4vz6u2Wy7fAP7ax8r0DjGRJI130e6gIiMiTSqnFfvbVGr9P+n2mBhgIWUUn+m2Xz/7joeXKWZhrzwfT5FNnPJv5rQt877y0+IAmCvZUcdOiJ8sVzeix8sv4iSxeut3h+zVNomQR+glyKB9Ztjh8BqMH1u6o860ZT5ui9oYB+/bRYWwhvimCusmKedly98RsJ5/Ax2z3jJvQBysaOnpOdqEPFGYqLQO04PeJb5dMySw6MX4ztrVx1GVQjQYd4gNuKywq0W1Bq6CFXSfCLovI4bC/yFqB7jMctre10TfHx+GKaR9CD2SsnQAgQscbP0l9Dhmtp5WPeSKvjT3TSU6BfMc9ZBRB8UIUBXl3DRwZ8BVzUxeoK/8ZVRa04PeJo0tmDpaY/oP9MODhCZC+4FkH0XMK8xyINceoC6aqy3VBH1W9cqW9PTOdRW0ttLf7zqXTN9fBvXNgIPvxCtbMbS7LRFg5YxiwYgUqeTAoBZs2sf4BcPNsTafoD/bJIi0vldFjFT2JHA4i9j9XFLzlNbJ6d9XXnOB5jmwKnsRhw6UbvHeaBmjB7xPjaZlwyUwsNOZgi8znZswn4jed9DWckqzpGAZs3Di+2EskYr03DFqe8xmJKhPunSt/tHJc+LvOGOxzzp4xm/M/srIoH6Ms6O5G0r+woSGMHqj34+2j8q+QNuU4zHiM50P0nrOJ+A1x7rj8DurcyoQLPHtiar2C8URrSQrFx9/8r67jsf4Y7gu7tvPFHT+tn/baPmjB759QCKPH0vwFchL6idq5ZhM5zRLmBeqz7+RBdFuUkXhqPoeR+EhpbMAuqWg7lq2n2amwiAcj8REr+2Qg4B4jYH//h4cPs/zu5chNkjUYLBsZgqKzNbear4kKbSJQU2P9n2utWA+NddChLG0GAt1P3eX/euVEmrcYkdRc9kaTwYbLb3cdS0og+p4jQHqitYl4EUvxcUi2CAzNsILinO7t8BC8/s3alNQO0xnt1eMX2+Oi8TrLBp8V+2sNxqHlqQAdV26mcftyf8fahGeF2ff5fXl1FyzTiXK4SwQhfsPkecD49YhKZ+3/MOHx4fNBWzMGt5+0FmNtR07XSgiK5ORcoRHoui/JvTYUck+cZ5qwciWMOCRO8jouncZG51iQSAS5ps/f9+DDu2U60xibT9+osxlUFMRvVK4ebSfMOJk/H92Tu+eQAnX6lrI2KWqvnlJge1z4Nr/YwmosCJua4pi3teVsuimkShZM4uJuFvItltL5TlABJm5SF1/+ZEaD8MmXOnP2iHLKyDhUCysuTfK0Os254hoAbW3OQh9cK7U5EosxOnNW6jY7PXf4mL/bNVC5Mh+A2LJ213GQyLPjtsD956N78rpmME5ZC/1c0YI/Ga9i6rEYYzNn5ZxwDSYWanM9tlAB7RStWHDUbh7kJYic1lB8amnHasC8NbdqX26CYiyYJRNrgoGBzJTdTUntflNKGAa///I32D1nASrN3NHesJo6H14u8Vy12WmG0WQwO8t6h2vqizy/m0qr+1BhH6cAshVTNwx23HAzF/qI6nOify7EpNl3OH4xBHR67p7I3MiUBPcUXRBl+/4FVn140L9NPhCg4XD2W8ExE2viVE04p+xOCH+/cQamyVu++zVOPrSP0YWLrAXPhI17bQcb7k1yMKhiBl1iO/aHgNZWYj884J4yPKkwkV8ir1eWqKysT1MI0SjmaUOpGlvS1L71gVYWD7exzmXxJxsNtWGMb22l60hm7pxkii2gk3P39F7XOzUeCcUU/D5v2OHaLHEQpmmlc7Yf9EufGfN17v7ZztLENWV3M1BX5y/OwDQxb76aM698iZobFKf/7YuYN1+d8gAzDkWod68gCED4aIWr/Li7XTYcBNav59GTxoqnpSuIvTm/etHlStUI/oTHhtwk1HylJsMLpPXMPpZfnqqxrbrEmtq3PtBK5/ZO4mosLyFWR41llwSMb20lcrxzHd3IQSH+5jumTkCXCK8soU6IgpluJg2/C72SJQ6irc1K52zTfYa/8zbMdf7t+ua4pOyeCxx3nC/7sHnralZeHE8ZgysvjqeYrVr/8c3sPNGjrwrauyt/OhB7Kpwxew4N2wkO43E634H37+n3PlbQ/Dw5OwuUO1Uh+JNdu2AiwVLCxav1gVZHN67hGmi7KMD6Jwtz4RohVUuMNccIjaZeLDQMsa2qYvLKJ9N+YTu1+MtmKMpK8HbMR9h8NjwX09OC6fwsvIeGIdb/Zsc2r2yN5sn+AvHa3jeYkS5gpMbanqDr9V94Cv21j1uzgkrHuLY9IzFg1/2WB5bZRFFnmVtfbi7eycqErIJfRDaIyGsi8rRLu4jId0Rkl4jsEJFzk9oaROSnIvKsiOwUkcbidd0/0fvaXGtoDo0M0fVkl+tAGZgRJ64Kc31UKMsv3cZoMui6VzkO2krJK5+M0WSw8fJNhMUjmEtZCe7uuNtKVuenClI2cllMd93X9iQKxGHF78D4zi8dd3PN1iiw6mJ/fRhwyQOfvH3MYyyKgo6HQ5WRviIbhoHx3rX8qV2I32SleUi43UabKZrgFwVs3Vqck5URfjT+24ELPNovBE63Xy1AZ1LbZuBmpdRbgHcCr+XXzQIwzaxl/iYjxWp64QbjUGQ8J0nyoK2IZGMOGE0G+758mC1/s8U51bDA0eCExvbnmZm71I16mIDST6csc4BfXKuk2aaleAC+fx6YZzqPlYiLCQis9YYlX3ur777khYI1T+A/XqAS6Oig61vXsuizgRRPqr4iRLwnqM+hnvV0IqvgV0o9Ang5lF8CbFYWjwHHi8hJInImUKOU+pl9nsNKqSLocTnS1lYU7bFg0jXdWIzhujTpFqp8bc1oMly9fAZnWDdu2wUQd7Cc1I7CbfeRfRFWwZrtgnFtu+su5rvrUxbygdSUHA4M19japANLT1/q3i+BbUd30nr5DHdPI9N0faiFfY7fDqO8A4yKjdlj8plBk5fmxMfXRK6+NIcTKDsNhkd8iJv30HSnGDb+hcCLSe9329v+AjggIneLyO9E5GaRKShb45UYLYlArkp/2kCpHc3clkzGzWsY/OAf/sXRX7tqEUvou5k8BmfYaYq3S+Z3bd+84UHY8lA9HZ+4wzXC1vzQfFo+PJiyiHrV5fDoImv25UX/XByFd/cfu7MuJna9bTjVRTipT63mcufMrQqu6JtI3RGpdZ7FROKzq27sRLdFOTKaemPFg+Rk5ll/vxXl7OZw0eCyfbpTDMHvUrueGuB9wOeAdwCnAtc4nkCkRUS2i8j2vXv3FqFLqWSroRmpCRPy8iJxoP5Y6sLStU96XEBB+xOpN6zZY/Lpk/6TUz6zjxO/djLm/bGquXG9NFg3oZ/A/EwzHZ+4gy0Phye+/5owW05cy2vfPZHXbhaMl+e7HGzFakTPGchwvVQC696ZFnTlQMNBLI+gNPykQh4LkBnFa6d6WO/mhSLQfdbEzDC2rJ2QpHY+JHXEPr4u6/UrDaeUDDkhlhsulE+w42RRDMG/G0guJLsI2GNv/51S6gWl1CjwI+Bch+NRSnUppRYrpRYvWLCgCF1KIhz2XOSrHYWlO45yOMcp3dCMibzhsW1w23m4PiTCQ6SYHRJeRq+Pvgyi2HvkJc+C45VG+0/ILwBJINqwy1rY+8U+er+tiN+o6G1sx/jcJhbsf5UAdvDdVVdBa2vq8dEoDA252oCV2NWu3FC2u6DDLNJPlPV4HeLkXDzRKIyMeAa59Y9OWFqNJoOuyzakBuVdtqGi3H8nk/7jrAWncgl2nCyKIfjvA662vXveDRxUSr0MPAGcICIJSf5hYGcRrpcb7e3uC3dYsvquyGDOXgDzhoC1a0Epoqsi7lV7FLS/eGaKNu+YF2a6VE4qAsahiGvIff0xj0LtuGjWdvDd/OtBbrBe8z+nMH+dlrPH9pjyzPHvFSegkhbh04g1xzI08YzDBY77UmYqh9YLPQ/LeKiURVBehZCsFFbT9+rHnfNO4LfAGSKyW0Q+KSJrRGSNvUs38AKwC/ge0AqglBrDMvNsE5EerNvpeyX4DN4YBsaeMF33O5dyG67Jbl5w0k4PzsIqpwj0Z5lyGnc+k/J+qksiTjmxGOu6Axl5Z4JjVqlG5TEqnTRrc04fKy+xCmcnBPdAvR2Alxy9O28eZlP+eVdqlC20HSqOGU0G/xle5T2TETg8wy7u/YA1GzHfFXJNBZygUs0NBZPrrDFt/9Bwbp5flYQfr55PKKVOUkrVKqUWKaW+r5Rap5RaZ7crpdSnlFKnKaWalFLbk479mVLqLHv7NUopn5lqikx7O48uSivoXCCjAcZ98xsO57ZmXS5ZM6cMw8C4fjMbttaP2+kbbG+aMY+vUpSzEIx+JOA44xquSY3eNd90mJaLydvHezRoZes0v3pFZqNpsuL6ze71A5IR6Nzeidlj0vb+7LPNStY8CyGXcpQwsR43HjvzUK2n51clUxWRuxgGXYvJ74b30CoSvvmxh9zzvIRDmRpFtS0kOWIYGL89PG6nP7XuZE+hD9ZX7CQEE3ZaJ8bt+aZJ9L3H/BVu92AsCC1/3pS5HhONIkeGrDUAn5po24NtDMzy3ifXdBfVxPoH8K/12yU6e++JEP+K0HtPBOMzG6vGoSKd6hD8eJfw83we+HhYGIcirH2cTBfPMStdQcb+VbaQlA2zs5VfzspeHMPV5c5Dyx6350ejRSllCS7rMfb6gdHjPw11elBfBsp5/GgsjJ3+Z9p1o9Dx2a2OVeKqkaoR/AE3qeLgEu60jxPj2lgsRsfDIbbcnTSVPChsPGmtqzCvpoWkbER3rc8q9BPlK53w0rLHAlgLvH19RQ3ky3AlnDeR/913GmqVPZNmNY+LrLS0+NqtdhQ2LFxb4s5MLype8CeycsZFeUZW5kyyNmbXCjUORehtF+K3R+g9746Ky+hXKrxMNWDlyen6xXHuD9E9YdfYgEh8NqxcSeuFPhbxcyAYZ8JjyDTh0KGJa+aQI2hGaK7ruMzlPFVJh8f9pSZs+RtPzr0UZ6VT0YI/PStnPgUY3FwLw0Np2phLsXFNdjyTqSnYfA8YD3tkDWlvp/1nQSt6OonauBD7maJ1yUhWz5lcGRNo/S87V77ti58gts3bJXUcgT3xAzT3Ssb+oWGIPVbvfJxmnNkjzj/q7GE7D9Z3g1roO1DRgt/JXz6nmz8xSXC4KdMjcTX5s9Sjqln9Mdt33it5nWFASwuS9ttKbS0MDha2sO8xS+w8N07rfauhvz+l7GK0GT78vH/h/4tGhcJyZyXhcdIdxPh0YenAq4F1i9ZQk5ZupWYM1v3YfuPTHFRtVLTgL9gvXpJeMJGetydQtW5gpcC1CIqyPTcAli71PEf0WDfDaWt9w2PDRJsLq5eaLdir64xBzHeFWHVJahGfXzXCmh117uX/kojbYyzh1bR0Tz3G5zbpWaMPjLUd3H7SWiKHg+Omndt/ZC/8rl3rbQ6qYopQ7qJ8mTdrnrPnhFMhbz+IdZNuWlzD+WeBvi2Lgy9vm+5u73O4POQLTdGbzcV0LABt7x9kOO1OGq6Bu04fJp7rQ0eg88xBPb5ywFjbgYEW8LlQ0Rq/KwXaeofUcNWkV5gMGgZdpKtYWTNbLyQ1v43TObyC3/I18/g4Loi4+uIPzPL4bFnQ40tTSipa8O8/4lVGoDCqJr3CJBA7tYWQS8ELv1kznYLiAG/h7WHDl7h3cZXE8R98qda7Xx6fzQs9vjSlpKIFfylTIFRNeoVJwFjbQdfCta5CWIl7AZTxczQZdJ2wgoaDfgIzbDweCvNqZxNrjnkv0Ar86o3DrqkDwkMTny1yOJiTR5keX5pSUtGC31ELz/VNAwAAEaJJREFUtBdoC6Hq0itMAsbaDtfIXPC3DmB8vZu+b6uieG3ujw9iNBmsedzbOydh289wJR21009jfbbem0cJBvybffT40pSSihb8xg74qz+Npmpa4iOyMotmVs3pFUqJl4bd8Hr2oWrO6WP+9fml+s+4nq1xdzwe5sPP43nSwRmw8d7UBGAb77VSeSTTcl6Lr7KRaxe7R3xrNMWgcgW/aWJ+eyU/XzicOaUvQCWMzI3om7JEGE0Ga+Y0OwczvXm157Fmj5mamtkPCpqfxzNhnvnVK/j5aVnOKfDrxrRbqa42o35yx0UdNM8807tE5zGh4yLtoaIpLZUr+KNRou8byS8Vs0chDj0FLy0dn93KHSeuZeGhgKU9Hw7StSh7yH10W9S9GE469qLu2sdh651Bz4R50WPdvsbQunPjKX78LcsE86zM/bZ+8ZnMjUkMzCjGfEWj8aZyBX9/f37ZGBXMDM50bKoftsxHmhLz3vN5ZXYYhcDCRfDe87MekpMXjFh5cDoeBFpaPBPm+T5v2sOhEJdfs7M1+04aTQFUruBvaHDPAZPFUyMYCFKXFnFZNwrrf0xqoWxN0UnkVxoL7AVR9B3s81WPOFcvmP65+IrsLMS7xu2h4Zm2WaCtX6dq0JSWyhX8sRixX9Vm1Nr1kz9lcGSQT25PXazbcK+dM6Zf+1eXknzrEceaYxmeNV40HB/xFc4fa47lvVrs9tDIFs07MKNAtzONJguVK/gNA+Od19J1f6oAX/O4v8O73xqk9xY7w98tSUW2vZKFaQom33rERpPBxnud6yqnk4s7rtFkUC8zsu+YviA94r4elDUwTKMpMZUr+AHuugujhxQB7poQLI3+2WOY59WOZ1xsvA62nJvpqaEpLoXUIzZeqOeOe8go4p5MUII5u+PODHhH5wITKb8VhAeha1u96zWyzSLCAZ2OWVNaKlfwmyYMZCZo87vgO29WmJZlkuKpcfWyEVqPf7TIHdUkU1A94vXrMZ4JsOFeXAVrXMVzdsfdP3bY3452ls39s4DBQdfdjCaD8DGXW09B+2Xaxq8pLZUr+NvaUnKkN15n5XvxLPqRwBYaQ2o4Y/O67euyLjRq8qegesSGAZs3YxyKuFavmjdrnnODB77GTBIqAG1LvaeV7Q2rM3L4iIK1c5p1nIim5IhS5eU3vHjxYrV9+/aCz2OeJbRcDEN1E9tCw7Did7BpcYAhj0TrEgcCgnJRGyNzI/Re11twHzWlw+wxWfmjlYzEU6VrHTVsuPz2nISr+aH5tLxnIGUsZUWButH73jI7W4m+0EV//RgNg0Fip7boalGavBGRJ5VSi33tW6mCv/EzlpkmncgBiD0VJroE+kZsU1CycmYH9nT/dSSzoDYTu8dvKK/vTZPJ/BtmMRA4mrE9UhOmN7rP/4nsKPDo+0bon2tp5lnz7PsQ/BpNMclF8FesqcfNlt8/16rf2hvdh/pmPWsfnyh5FxyzhH7H42HvvDGH88uxrplETJMByRT6AP0jDsV5vDAMjM9spPeeCPGvCJvv8VlWUaMpUypW8DfUOtfEbTjIhEvm+vV0bK1l9KugboLRr0LH1lpob3fNzBgahthDPurpaaaU1vvcc/vMG3JtcscwoLcX4nGMnuyu/eHg7DwuotFMDlkFv4hsEJHXRORpl3YRke+IyC4R2SEi5ya1jYnIU/brvmJ2PBuxZe2E0outKjhcC+blb7beGwZs3AiRCIhY/2/cOF7rtGNnhDvuTo0D6Lo/M+uipvzoOmPQ3W03WKC+Ew57Rt/WjUL7pesKu4ZGU0L83AG3Axd4tF8InG6/WoDOpLYjSqlz7NeyvHuZB0aTQdfPZhEeZEI9Eyt7Y0v9zyc8c5I0OXp7UwtcuxX4zlL4WzP1eBVY3z+z8MhY19Teyo7y1p45mjImq+BXSj0CeNUwvATYrCweA44XkZOK1cG8MU2MxwaZPUJmAq0a5SuBlvnsXbRcTGrWxYut7ZrpS0OhkbP7vUt6Gjv1GpCmvCmGjX8h8GLS+932NoCZIrJdRB4TkUuLcC3/2MnUXBd5fWRdjJ6T6cI3VGdt10xTipFau6GBsMs6QXgIaGkp7PwaTYkphuB3mvQmjCsNtnvR3wO3iMhpjicQabEfENv37t1bhC5Z1Zgar3NfhGuoyR7I4+UZpClv3AK4wkNFMMPEYrT/xKXc4s/rfCV/02imkmII/t3AKUnvFwF7AJRSif9fAH4JvN3pBEqpLqXUYqXU4gULFhTcIbPHpGWZZZpxeywt3eHs6peMq2eQy3ZN+RB7KpyRmTU0DO1PFOG3MwyM967NLLf4YC3GZzYUfn6NpsQUQ/DfB1xte/e8GziolHpZRE4QsdIaish84HxgZxGul5XofW0MeeXVEug+2T2XSoLYsnZCkmrrCUkdsWXtBfZQU2qMa9vpeqg21SProVqMa4v023V0YHxhy7hvf+89EYzPbEx1DtBoypSsxepE5E7gg8B8EdkN3ADUAiil1gHdwFJgFzAErLQPfQuwXsRKgAB8TSk1KYK/f2QgawZOP+Yao8mAXz/KF3atZ89xcU4ZDPLvp35Se2xMBwwDAzCiUauGQkODlVm1mILZMLSg10xLKjJlg1u6hmR8he2bprVQN5S0khcKQVeXvuE1Gk1ZUfUpG5buqfcMrfRtrolGU4U+WO91+UWNRjONqUjBf9dfjrku6oZnhem6bIM/c41bmUVdflGj0Uxjstr4pyNuybkA9n0+h6yM8+Y5FnNhXu453TUajaZcqEiNX6PRaDTuVKTgrz+W23ZX3ELzs4TsazQaTTlTkYJfXD7VTOWjynoyDS4Fvt22azQazTSg4gS/2WNy2KVE3v5ZObquxmKW+2YyoZC1XaPRaKYpFSf4vbJu5pyV0TAsn/3kfP3ah1+j0UxzKs6rxyvrZl5ZGXV0pkajqTAqTuNvmOtsfw/PCutUCxqNRkMFCv5Yc4xQbapdPlQbov1CnVhNo9FooAIFv9Fk0HVxF+GZC0EJi447ha6Lu7S2r9FoNDYVZ+MHS/gfO/gevvLjnTz1+Y9wfMjFzUej0WiqkIrT+AHMzlZu/NHp9M/8GGffEMLsbJ3qLmk0Gk3ZUHGC3+xspeWlTl48bgwl0D97jJaXOrXw12g0GpuKE/xt/eszqm8N1UL0ha6p6ZBGo9GUGRUl+M0ek4EZcce2vvqxSe6NRqPRlCcVJfij26JZSy5qNBpNtVNRgt8ralej0Wg0FhUl+N8QWujaFiyv0sIajUYzZVSU4B89cCU4mfgVtMxtnvT+aDQaTTlSUYIfAAmmvlfQPPNMOj67dWr6o9FoNGVGRQn+AzWbQdK8dwR2zRycmg5pNBpNGVJRgn9MnAup60VfjUajmaCiBH9QzXfc7paqWaPRaKqRihL87//TTEj33lGw9OX6KemPRqPRlCNZBb+IbBCR10TkaZd2EZHviMguEdkhIuemtc8RkZdE5NZiddqNHW98MTOAS+AutbPUl9ZoNJppgx+N/3bgAo/2C4HT7VcL0JnW/lXg4Xw6lysDody2azQaTTWSVfArpR4B9nvscgmwWVk8BhwvIicBiMh5wInAT4vRWY1Go9EUTjFs/AuBF5Pe7wYWikgA+H+B64twjeyY5qRcRqPRaKY7xRD8TmnRFNAKdCulXnRoTz2BSIuIbBeR7Xv37s2rE+Ztba5t4VA4r3NqNBpNJVKM0ou7gVOS3i8C9gB/BbxPRFqB2UCdiBxWSn0x/QRKqS6gC2Dx4sV5ZdWJnjPg+gjShdY1Go1mgmII/vuAT4vID4B3AQeVUi8D49XNReQaYLGT0C8W/XPd23ShdY1Go5kgq+AXkTuBDwLzRWQ3cANQC6CUWgd0A0uBXcAQsLJUnfViUU2YF8cGMrZHarWZR6PRaJLJKviVUp/I0q6AT2XZ53Yst9CS8R/L2rnmh9cwGhwd3xaSOmLLtJlHo9FokqmYyF3jLINrz76Zk+oXIQiRuRG6LtugzTwajUaThlgKe/mwePFitX379qnuhkaj0UwrRORJpdRiP/tWjMav0Wg0Gn9owa/RaDRVhhb8Go1GU2Vowa/RaDRVhhb8Go1GU2Vowa/RaDRVhhb8Go1GU2Vowa/RaDRVRtkFcInIXqCvgFPMB/YVqTvFplz7Vq79At23fNF9y49y7ZuffkWUUgv8nKzsBH+hiMh2v9Frk0259q1c+wW6b/mi+5Yf5dq3YvdLm3o0Go2mytCCX6PRaKqMShT8XVPdAQ/KtW/l2i/QfcsX3bf8KNe+FbVfFWfj12g0Go03lajxazQajcaDihH8InKBiDwnIrtEpGS1fT2uf4qI/EJEnhWRZ0Skzd5+o4i8JCJP2a+lScd8ye7vcyLy0RL3r1dEeuw+bLe3zRORn4nIH+3/T7C3i4h8x+7bDhE5t4T9OiPpu3lKRA6JyHVT9b2JyAYReU1Enk7alvP3JCIr7P3/KCIrStSvm0XkD/a17xGR4+3tjSJyJOm7W5d0zHn2ONhl911K1Lecf79S3MMuffuvpH71ishT9vbJ/t7cZEbpx5tSatq/gCDwPHAqUAf8HjhzkvtwEnCu/fdxwP/C/9/e2YVKUYZx/PegJfRhHftCjpXHsAuvUkROlN4UJ4+U9gFxIlAqiKAuIoKEA9GtQV0VBVGkYRlR0bmRlC7qJi08ZRqWHk9B4nYEjRKCPv9dzDM1Z9sdmtPOzLL7/GCYd5+dnf3v/33n2XeemWVZATwFPN5i+xWucwEw5PrnlajvW+DSptjTwFZvbwW2eXsDsBswYBjYX2E/fg9cXZdvwDpgFXB4rj4Bi4BpXw94e6AEXSPAfG9vy+hamt2uaT+fANe75t3AaEmeFeq/so7hVtqann8GeLIm39rljNLHW6/M+NcAU5KmJf0K7AI2VSlAUkPSpLfPAkeAwZyXbAJ2SfpF0jckf1a/pnyl/9Kw3dvbgdsz8R1K2AdcbGaLK9BzE3BcUt4P+Er1TdJHwJkW71nEp1uAvZLOSPoB2Aus77QuSXskpX8yvQ9YkrcP17ZQ0sdKMsaOzGfpqLYc2vVfKcdwnjaftd8NvJG3jxJ9a5czSh9vvZL4B4HvMo9PkJ90S8XMlgIrgf0eesRPzV5JT9uoXrOAPWZ2wMwe9NgVkhqQDELg8pq0pYwx+yDsBt+guE91aLyfZDaYMmRmn5nZh2a21mODrqUqXUX6rw7P1gIzko5lYrX41pQzSh9vvZL4W9XbarldycwuAN4GHpX0E/ACcA1wHdAgObWE6jXfIGkVMAo8bGbrcrat3E8zOxfYCLzloW7xLY92WirVaGbjwO/ATg81gKskrQQeA143s4UV6yraf3X06z3MnmjU4luLnNF20zY6CuvrlcR/Argy83gJcLJqEWZ2DkkH7pT0DoCkGUl/SPoTeIl/yhKVapZ00tengHddx0xawvH1qTq0OaPApKQZ19kVvjlFfapMo1/IuxW418sQeBnltLcPkNTOr3Vd2XJQabrm0H+V9quZzQfuBN7MaK7ct1Y5gwrGW68k/k+B5WY25DPHMWCiSgFeL3wZOCLp2Uw8Wxu/A0jvLpgAxsxsgZkNActJLiCVoe18M7swbZNcFDzsGtI7ALYA72W0bfa7CIaBH9NTzxKZNfvqBt8yFPXpfWDEzAa8xDHisY5iZuuBJ4CNkn7OxC8zs3neXkbi0bRrO2tmwz5eN2c+S6e1Fe2/qo/hm4GvJP1dwqnat3Y5gyrG2/+9Mt0tC8kV76Mk39LjNbz/jSSnV18An/uyAXgNOOTxCWBx5jXjrvdrOnCXQI62ZSR3SRwEvkz9AS4BPgCO+XqRxw143rUdAlaX7N15wGngokysFt9IvnwawG8kM6kH5uITSc19ypf7StI1RVLbTcfbi77tXd7PB4FJ4LbMflaTJOHjwHP4jzhL0Fa4/8o4hltp8/irwENN21btW7ucUfp4i1/uBkEQ9Bm9UuoJgiAI/iOR+IMgCPqMSPxBEAR9RiT+IAiCPiMSfxAEQZ8RiT8IgqDPiMQfBEHQZ0TiD4Ig6DP+AtjNDyxLWmc7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions \n",
    "from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL\n",
    "import matplotlib.pyplot as plt\n",
    "observation = env.reset()\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(observation)\n",
    "        print(\"info:\", info)\n",
    "        break\n",
    "\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Input, Concatenate, BatchNormalization, Conv2D, Conv1D, Permute\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.agents.ddpg import DDPGAgent\n",
    "from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy, LinearAnnealedPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint, TrainEpisodeLogger\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class FileEpisodeLogger(TrainEpisodeLogger):\n",
    "    def __init__(self, filepath):\n",
    "        TrainEpisodeLogger.__init__(self)\n",
    "        self.filepath = filepath\n",
    "        \n",
    "    def on_episode_end(self, episode, logs):\n",
    "        episode_steps = len(self.observations[episode])\n",
    "        variables = [episode+1, episode_steps, np.sum(self.rewards[episode]), np.mean(self.rewards[episode]), np.mean(self.actions[episode])]\n",
    "        row = ''\n",
    "        for var in variables:\n",
    "            row += '{},'.format(var)\n",
    "        # Overwrite already open file. We can simply seek to the beginning since the file will\n",
    "        # grow strictly monotonously.\n",
    "        with open(self.filepath,'a') as fd:\n",
    "            fd.write(row[:-1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        assert observation.ndim == 2  # (height, width, channel)\n",
    "        return self.process_obs_1(observation)\n",
    "    \n",
    "    def process_obs_1(self, observation):\n",
    "        prices = []\n",
    "        diff = []\n",
    "        for o in observation:\n",
    "            prices.append(o[0])\n",
    "            diff.append(o[1])\n",
    "        prices = preprocessing.normalize([prices], norm='l2', axis=1, copy=True, return_norm=False)[0]\n",
    "        diff = preprocessing.normalize([diff], norm='l2', axis=1, copy=True, return_norm=False)[0]\n",
    "        new_obs = np.column_stack((prices, diff))\n",
    "        return new_obs\n",
    "    \n",
    "    def process_obs_3(self, observation):\n",
    "        prices = []\n",
    "        for o in observation:\n",
    "            prices.append(o[0])\n",
    "#         prices = preprocessing.normalize([prices], norm='l2', axis=1, copy=True, return_norm=False)[0]\n",
    "        return np.column_stack([prices])\n",
    "    \n",
    "    def process_obs_2(self, observation):\n",
    "        prices = []\n",
    "        diff = []\n",
    "        for o in observation:\n",
    "            prices.append(o[0])\n",
    "            diff.append(o[1] / o[0] * 100)\n",
    "        prices = preprocessing.normalize([prices], norm='l2', axis=1, copy=True, return_norm=False)[0]\n",
    "        new_obs = np.column_stack((prices, diff))\n",
    "        return new_obs\n",
    "        \n",
    "    def process_state_batch(self, batch):\n",
    "#         print(batch)\n",
    "        return batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return reward - max_reward\n",
    "\n",
    "class DDPGEnvProcessor(EnvProcessor):\n",
    "    def __init__(self, train_policy, test_policy):\n",
    "        EnvProcessor.__init__(self)\n",
    "        self.nb_act_count = [0,0]\n",
    "        self.count = 0\n",
    "        self.train_policy = train_policy\n",
    "        self.test_policy = test_policy\n",
    "        \n",
    "    def process_action(self,actions):\n",
    "        if self.is_train:\n",
    "            choice = self.train_policy.select_action(q_values=actions)\n",
    "        else:\n",
    "            choice = self.test_policy.select_action(q_values=actions)\n",
    "        self.nb_act_count[choice] +=1\n",
    "        self.count += 1\n",
    "        if self.count % 1949 == 0:\n",
    "            print(self.nb_act_count)\n",
    "        if self.count % 400 == 0:\n",
    "            print(actions)\n",
    "            \n",
    "        return choice\n",
    "    def train_mode(self, is_train=True):\n",
    "        self.is_train = is_train\n",
    "    \n",
    "class CustomEpsGreedyQPolicy(EpsGreedyQPolicy):\n",
    "    def __init__(self, eps=0.1, update_interval=100):\n",
    "        EpsGreedyQPolicy.__init__(self, eps)\n",
    "        self.update_interval = update_interval\n",
    "        self.count = 0\n",
    "        self.init_eps = self.eps\n",
    "        \n",
    "    def select_action(self, q_values):\n",
    "        assert q_values.ndim == 1\n",
    "        nb_actions = q_values.shape[0]\n",
    "\n",
    "        if np.random.uniform() < self.eps:\n",
    "            action = np.random.randint(0, nb_actions)\n",
    "        else:\n",
    "            action = np.argmax(q_values)\n",
    "        self.count += 1\n",
    "        if (self.count % self.update_interval) == 0:\n",
    "            self.eps = self.init_eps / (self.count / self.update_interval)\n",
    "            print(self.eps)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 = enable_double_dqn=True, nb_steps=1000000, EpsGreedyQPolicy **\n",
    "# 4 = enable_double_dqn=True, nb_steps=100000, EpsGreedyQPolicy\n",
    "# 5 = enable_double_dqn=True, nb_steps=100000, BoltzmannQPolicy **\n",
    "# 6 = enable_double_dqn=True, nb_steps=1000000, CustomEpsGreedyQPolicy, process_obs_2\n",
    "# 7 = enable_double_dqn=True, nb_steps=1000000, EpsGreedyQPolicy, process_obs_2 **\n",
    "# 8 = enable_double_dqn=True, nb_steps=1000000, CustomEpsGreedyQPolicy **\n",
    "# 9 = enable_double_dqn=True, nb_steps=1000000, CustomEpsGreedyQPolicy(update_interval=2500), train_interval=256, batch_size=512\n",
    "# 10 = enable_double_dqn=True, nb_steps=1000000, BoltzmannQPolicy, train_interval=256, batch_size=512 **\n",
    "# 11 = DDPG, train_interval=256, batch_size=512 ***\n",
    "# 12 = enable_double_dqn=True, nb_steps=1000000, BoltzmannQPolicy, train_interval=32, batch_size=64 \n",
    "# 13 = DDPG, train_interval=128, batch_size=64 ***\n",
    "# 14 = DDPG, train_interval=128, batch_size=256, lr = 0.0002, target_model_update=0.0002, gamma=0.99\n",
    "# 15 = DDPG, train_interval=256, batch_size=512, lr = 0.0002, target_model_update=0.0002, gamma=0.9, linear\n",
    "train_no = 22\n",
    "weights_filename = 'dqn_weights_{}.h5f'.format(train_no)\n",
    "checkpoint_weights_filename = 'dqn_weights_{step}_'+'{}.h5f'.format(train_no)\n",
    "log_filename = 'dqn_log_{}.csv'.format(train_no)\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
    "callbacks += [FileEpisodeLogger(log_filename)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_80 (Flatten)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 32)                672       \n",
      "_________________________________________________________________\n",
      "activation_235 (Activation)  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_236 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation_237 (Activation)  (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,234\n",
      "Trainable params: 1,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb_actions = env.action_space.n\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = EnvProcessor()\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "# policy = CustomEpsGreedyQPolicy(update_interval = 2500, eps = 1.0)\n",
    "policy = BoltzmannQPolicy()\n",
    "agent = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=20,\n",
    "               target_model_update=1e-2, policy=policy, batch_size=64, processor=processor, \n",
    "               train_interval=32, enable_double_dqn=True)\n",
    "agent.compile(Adam(lr=1e-3), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIth DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model no 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"action_input_2:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"observation_input_2:0\", shape=(?, 1, 10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nb_actions = env.action_space.n\n",
    "env_shape = (10,2)\n",
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env_shape))\n",
    "actor.add(Dropout(0.2))\n",
    "actor.add(Dense(32))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dropout(0.2))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('softmax'))\n",
    "# print(actor.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env_shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "print(action_input)\n",
    "print(observation_input)\n",
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(16)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('softmax')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "# print(critic.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model no 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"action_input_8:0\", shape=(?, 2), dtype=float32)\n",
      "Tensor(\"observation_input_10:0\", shape=(?, 1, 15, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "nb_actions = env.action_space.n\n",
    "env_shape = (15,2)\n",
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env_shape))\n",
    "actor.add(Dropout(0.2))\n",
    "actor.add(Dense(128))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dropout(0.2))\n",
    "actor.add(Dense(64))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('tanh'))\n",
    "# print(actor.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env_shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "print(action_input)\n",
    "print(observation_input)\n",
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "# print(critic.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model no 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_shape = (15,2)\n",
    "observation_input = Input(shape=(1,) + env_shape, name='observation_input')\n",
    "obs = Permute((2, 3, 1), input_shape=(1,) + env_shape)(observation_input)\n",
    "obs = Conv2D(filters=64, kernel_size=(2,1), activation='relu', padding='same')(obs)\n",
    "obs = BatchNormalization()(obs)\n",
    "obs = Conv2D(filters=64, kernel_size=(2,1), activation='relu', padding='same')(obs)\n",
    "obs = BatchNormalization()(obs)\n",
    "obs = Flatten()(obs)\n",
    "\n",
    "obs_1 = Dense(256, activation='relu')(obs)\n",
    "obs_1 = Dropout(0.2)(obs_1)\n",
    "obs_1 = Dense(64, activation='relu')(obs_1)\n",
    "obs_out = Dense(nb_actions, activation='tanh')(obs_1)\n",
    "actor = Model(inputs=[observation_input], outputs=obs_out)\n",
    "# print(actor.summary())\n",
    "\n",
    "obs_2 = Permute((2, 3, 1), input_shape=(1,) + env_shape)(observation_input)\n",
    "obs_2 = Conv2D(filters=64, kernel_size=(2,1), activation='relu', padding='same')(obs_2)\n",
    "obs_2 = BatchNormalization()(obs_2)\n",
    "obs_2 = Conv2D(filters=64, kernel_size=(2,1), activation='relu', padding='same')(obs_2)\n",
    "obs_2 = BatchNormalization()(obs_2)\n",
    "obs_2 = Flatten()(obs_2)\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "a1 = Dense(64, activation='linear')(action_input)\n",
    "\n",
    "x = Concatenate()([a1, obs])\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "# print(critic.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1.0, value_min=0.08, value_test=0.05, nb_steps=10000)\n",
    "test_policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=0.05, value_min=0.05, value_test=0.0, nb_steps=10000)\n",
    "processor = DDPGEnvProcessor(train_policy,test_policy)\n",
    "processor.train_mode(True)\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.3, mu=0.2, sigma=.3)\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input,\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,\n",
    "                  random_process=random_process,processor=processor, gamma=0.99, target_model_update=2e-3, \n",
    "                  batch_size=1949, train_interval=1949)\n",
    "agent.compile((Adam(lr=2e-3),Adam(lr=2e-3)), metrics=['mae'])\n",
    "train_policy._set_agent(agent)\n",
    "test_policy._set_agent(agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1500000 steps ...\n",
      "Training for 1500000 steps ...\n",
      "[-0.28624207  1.1480056 ]\n",
      "[0.2686283 1.172402 ]\n",
      "[0.48600024 0.5027147 ]\n",
      "[-0.10709486  0.29376188]\n",
      "[932, 1017]\n",
      "    1949/1500000: episode: 1, duration: 5.485s, episode steps: 1949, steps per second: 355, episode reward: 515.300, mean reward: 0.264 [-59.200, 168.700], mean action: 0.522 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: --, mean_absolute_error: --, mean_q: --\n",
      "[0.74580663 1.0941386 ]\n",
      "[0.72079605 1.1411868 ]\n",
      "[0.78010863 1.223862  ]\n",
      "[0.4354499 1.3158137]\n",
      "[0.8507445 1.1751362]\n",
      "[1662, 2236]\n",
      "    3898/1500000: episode: 2, duration: 3.772s, episode steps: 1949, steps per second: 517, episode reward: 716.400, mean reward: 0.368 [-73.800, 168.700], mean action: 0.625 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 247.851105, mean_absolute_error: 20.433908, mean_q: 19.386702\n",
      "[-1.1824536  1.420336 ]\n",
      "[-1.2274784  1.2944006]\n",
      "[-1.3065213  0.9914729]\n",
      "[-0.87308294  1.3570884 ]\n",
      "[-0.6926074  1.2944281]\n",
      "[2176, 3671]\n",
      "    5847/1500000: episode: 3, duration: 3.318s, episode steps: 1949, steps per second: 587, episode reward: 402.300, mean reward: 0.206 [-57.400, 143.400], mean action: 0.736 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.859119, mean_absolute_error: 5.814376, mean_q: -1.950970\n",
      "[-1.3892488  1.0262828]\n",
      "[-1.3511282  0.5395156]\n",
      "[-1.1801361  0.8377693]\n",
      "[-0.3824539   0.90119815]\n",
      "[-1.1729666   0.65657926]\n",
      "[2558, 5238]\n",
      "    7796/1500000: episode: 4, duration: 3.116s, episode steps: 1949, steps per second: 626, episode reward: 303.000, mean reward: 0.155 [-78.400, 190.200], mean action: 0.804 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.884716, mean_absolute_error: 6.265843, mean_q: -2.945491\n",
      "[-0.740901   0.5231248]\n",
      "[-1.2896832  1.1476496]\n",
      "[-1.5701333  0.6184926]\n",
      "[-0.9150945  0.8049939]\n",
      "[-1.6639411  1.7567651]\n",
      "[2748, 6997]\n",
      "    9745/1500000: episode: 5, duration: 3.140s, episode steps: 1949, steps per second: 621, episode reward: 947.700, mean reward: 0.486 [-104.600, 162.400], mean action: 0.903 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.823994, mean_absolute_error: 5.016898, mean_q: -0.178272\n",
      "[-1.2408818  0.9410575]\n",
      "[-1.3435459  1.3994209]\n",
      "[-0.8282348  0.8704177]\n",
      "[-0.7335672  1.1193897]\n",
      "[-0.9251861  0.9735382]\n",
      "[2831, 8863]\n",
      "   11694/1500000: episode: 6, duration: 3.383s, episode steps: 1949, steps per second: 576, episode reward: 361.200, mean reward: 0.185 [-139.000, 273.800], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.470268, mean_absolute_error: 4.972327, mean_q: 1.552133\n",
      "[-1.1189104  1.405954 ]\n",
      "[-0.9279755  1.6626817]\n",
      "[-0.1543271  1.3152292]\n",
      "[-0.96027875  1.9494063 ]\n",
      "[-0.67221266  1.2927024 ]\n",
      "[2921, 10722]\n",
      "   13643/1500000: episode: 7, duration: 3.327s, episode steps: 1949, steps per second: 586, episode reward: 650.800, mean reward: 0.334 [-107.800, 159.600], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 84.445976, mean_absolute_error: 4.576873, mean_q: -0.001301\n",
      "[-0.6798013   0.53716004]\n",
      "[-0.9671128   0.65584177]\n",
      "[-1.4227256   0.94787115]\n",
      "[-0.6434987  1.0463958]\n",
      "[3001, 12591]\n",
      "   15592/1500000: episode: 8, duration: 3.318s, episode steps: 1949, steps per second: 587, episode reward: 691.900, mean reward: 0.355 [-68.200, 183.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 88.603737, mean_absolute_error: 4.669928, mean_q: -0.402763\n",
      "[-0.97210234  0.9810864 ]\n",
      "[-0.5796771  1.373366 ]\n",
      "[-1.131485   0.8903491]\n",
      "[-0.82489693  1.1307087 ]\n",
      "[-1.9253381  2.0548794]\n",
      "[3080, 14461]\n",
      "   17541/1500000: episode: 9, duration: 3.344s, episode steps: 1949, steps per second: 583, episode reward: 495.000, mean reward: 0.254 [-175.000, 182.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.388985, mean_absolute_error: 3.623014, mean_q: 0.463783\n",
      "[-0.80378354  0.7472317 ]\n",
      "[-0.4694709  1.3706559]\n",
      "[-0.17307456  0.78846407]\n",
      "[-0.4191317  1.5748166]\n",
      "[-0.84918654  0.9501109 ]\n",
      "[3153, 16337]\n",
      "   19490/1500000: episode: 10, duration: 3.273s, episode steps: 1949, steps per second: 595, episode reward: 884.300, mean reward: 0.454 [-82.100, 136.900], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.656471, mean_absolute_error: 3.750818, mean_q: 0.051625\n",
      "[-0.858568   1.2455174]\n",
      "[0.01528152 0.29715943]\n",
      "[-0.1672722  0.6016443]\n",
      "[-0.5483621  0.9831408]\n",
      "[-0.7493481  0.8473087]\n",
      "[3259, 18180]\n",
      "   21439/1500000: episode: 11, duration: 3.308s, episode steps: 1949, steps per second: 589, episode reward: 355.800, mean reward: 0.183 [-116.000, 126.400], mean action: 0.946 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.687260, mean_absolute_error: 3.614933, mean_q: 0.539501\n",
      "[-0.27232355  0.6205914 ]\n",
      "[-0.3003414  1.3256332]\n",
      "[-0.838784  1.61009 ]\n",
      "[-0.959636  1.285265]\n",
      "[-1.1807611  1.1707435]\n",
      "[3349, 20039]\n",
      "   23388/1500000: episode: 12, duration: 3.200s, episode steps: 1949, steps per second: 609, episode reward: 497.500, mean reward: 0.255 [-108.700, 168.900], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.919289, mean_absolute_error: 3.348969, mean_q: -0.045798\n",
      "[-0.6016313  0.8772085]\n",
      "[-0.40621442  1.4969882 ]\n",
      "[-0.44997555  1.3004012 ]\n",
      "[-0.3228996  1.7926824]\n",
      "[-0.6410805  1.0654918]\n",
      "[3441, 21896]\n",
      "   25337/1500000: episode: 13, duration: 3.292s, episode steps: 1949, steps per second: 592, episode reward: 300.000, mean reward: 0.154 [-109.700, 139.900], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.305992, mean_absolute_error: 3.430411, mean_q: 0.203035\n",
      "[-1.1532861  1.2582073]\n",
      "[-1.3170723  1.5072821]\n",
      "[-1.4069268   0.29338887]\n",
      "[-0.82364345  0.6103991 ]\n",
      "[-0.42527518  1.3352534 ]\n",
      "[3524, 23762]\n",
      "   27286/1500000: episode: 14, duration: 3.400s, episode steps: 1949, steps per second: 573, episode reward: 415.100, mean reward: 0.213 [-141.900, 222.200], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.149910, mean_absolute_error: 3.070745, mean_q: 0.040127\n",
      "[-0.9886183  1.3142494]\n",
      "[-1.3410496  1.5528704]\n",
      "[-1.608744   1.4241518]\n",
      "[-1.5025123  1.1008483]\n",
      "[-0.6652259  1.2034467]\n",
      "[3607, 25628]\n",
      "   29235/1500000: episode: 15, duration: 3.621s, episode steps: 1949, steps per second: 538, episode reward: -76.700, mean reward: -0.039 [-168.700, 108.000], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.882027, mean_absolute_error: 2.702276, mean_q: 0.291648\n",
      "[-1.2157754  1.5272808]\n",
      "[-0.9137358  1.2595198]\n",
      "[-0.99333453  1.5970181 ]\n",
      "[-0.7000432  1.3903537]\n",
      "[3703, 27481]\n",
      "   31184/1500000: episode: 16, duration: 3.435s, episode steps: 1949, steps per second: 567, episode reward: 365.000, mean reward: 0.187 [-109.500, 148.900], mean action: 0.951 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.590015, mean_absolute_error: 2.649060, mean_q: 0.169475\n",
      "[-0.7720578  0.9090617]\n",
      "[-0.8183507   0.34325144]\n",
      "[-0.6676394  1.1576619]\n",
      "[-0.77200425  1.4346676 ]\n",
      "[-0.56281054  1.5213462 ]\n",
      "[3784, 29349]\n",
      "   33133/1500000: episode: 17, duration: 3.369s, episode steps: 1949, steps per second: 578, episode reward: 676.200, mean reward: 0.347 [-124.100, 168.100], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 62.805382, mean_absolute_error: 2.729584, mean_q: -0.127864\n",
      "[-1.0710307  1.124343 ]\n",
      "[-1.1689466   0.90121084]\n",
      "[-0.87520677  1.1003401 ]\n",
      "[-0.5251946  1.375612 ]\n",
      "[-0.15089399  1.0039223 ]\n",
      "[3868, 31214]\n",
      "   35082/1500000: episode: 18, duration: 3.399s, episode steps: 1949, steps per second: 573, episode reward: 343.900, mean reward: 0.176 [-135.800, 204.400], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.645229, mean_absolute_error: 2.715065, mean_q: -0.403386\n",
      "[-0.79061186  1.3857929 ]\n",
      "[-0.11126434  0.4050551 ]\n",
      "[-0.5912495  0.3533856]\n",
      "[-0.9988009  0.460456 ]\n",
      "[-1.3741179  1.1569463]\n",
      "[3945, 33086]\n",
      "   37031/1500000: episode: 19, duration: 3.377s, episode steps: 1949, steps per second: 577, episode reward: 537.500, mean reward: 0.276 [-148.400, 151.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.618622, mean_absolute_error: 2.915871, mean_q: 0.207215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0229535  0.8875635]\n",
      "[-1.0347079  1.3926013]\n",
      "[-1.0635228  0.8533842]\n",
      "[-0.9515221  1.3843927]\n",
      "[0.11469353 0.9291677 ]\n",
      "[4011, 34969]\n",
      "   38980/1500000: episode: 20, duration: 3.120s, episode steps: 1949, steps per second: 625, episode reward: 146.200, mean reward: 0.075 [-134.300, 125.200], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.250092, mean_absolute_error: 2.857554, mean_q: 0.219400\n",
      "[-0.58849394  1.0529317 ]\n",
      "[-0.5902195  0.5980395]\n",
      "[-0.580822   1.3305588]\n",
      "[-1.2971386  1.2424614]\n",
      "[-1.2749746  1.3633786]\n",
      "[4103, 36826]\n",
      "   40929/1500000: episode: 21, duration: 3.261s, episode steps: 1949, steps per second: 598, episode reward: 275.700, mean reward: 0.141 [-113.100, 105.100], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.166309, mean_absolute_error: 2.368628, mean_q: 0.173545\n",
      "[-0.82095885  0.9541148 ]\n",
      "[-0.7828815  1.1205755]\n",
      "[-0.3816776  1.6743436]\n",
      "[-0.3371508   0.91594744]\n",
      "[-0.38393497  1.3964123 ]\n",
      "[4184, 38694]\n",
      "   42878/1500000: episode: 22, duration: 3.490s, episode steps: 1949, steps per second: 558, episode reward: 475.800, mean reward: 0.244 [-81.600, 224.000], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 79.410217, mean_absolute_error: 2.801252, mean_q: 0.018136\n",
      "[-0.9941661   0.73625964]\n",
      "[-0.5395214  0.7254513]\n",
      "[-1.479087  1.739551]\n",
      "[-1.023279  1.433484]\n",
      "[-0.63957274  1.0899444 ]\n",
      "[4270, 40557]\n",
      "   44827/1500000: episode: 23, duration: 3.336s, episode steps: 1949, steps per second: 584, episode reward: 306.400, mean reward: 0.157 [-111.900, 120.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.519310, mean_absolute_error: 2.324938, mean_q: 0.069188\n",
      "[-1.0621593  0.9568387]\n",
      "[-0.80270326  1.6577915 ]\n",
      "[-1.1159333  1.8868488]\n",
      "[-1.0402501  1.2745364]\n",
      "[4349, 42427]\n",
      "   46776/1500000: episode: 24, duration: 3.515s, episode steps: 1949, steps per second: 554, episode reward: 500.900, mean reward: 0.257 [-106.100, 182.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.165062, mean_absolute_error: 2.533099, mean_q: 0.154103\n",
      "[-0.957728   1.0888412]\n",
      "[-1.4813918  0.6631013]\n",
      "[-0.56224936  1.2706214 ]\n",
      "[-0.88373166  1.2222223 ]\n",
      "[-0.33940062  1.0568972 ]\n",
      "[4434, 44291]\n",
      "   48725/1500000: episode: 25, duration: 3.337s, episode steps: 1949, steps per second: 584, episode reward: 475.300, mean reward: 0.244 [-93.600, 127.800], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 68.853676, mean_absolute_error: 2.853147, mean_q: 0.246674\n",
      "[-1.1033932   0.63041675]\n",
      "[-0.70293456  1.1790683 ]\n",
      "[-0.95454675  1.4366329 ]\n",
      "[-0.46703762  1.3437469 ]\n",
      "[-0.764377   1.5254458]\n",
      "[4513, 46161]\n",
      "   50674/1500000: episode: 26, duration: 3.320s, episode steps: 1949, steps per second: 587, episode reward: 572.100, mean reward: 0.294 [-118.200, 166.100], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.025879, mean_absolute_error: 2.235239, mean_q: 0.278658\n",
      "[-0.75468534  1.460113  ]\n",
      "[-0.6194605  1.9479269]\n",
      "[0.17721206 1.8322108 ]\n",
      "[-0.07016546  1.9014374 ]\n",
      "[-0.6286135  1.673254 ]\n",
      "[4597, 48026]\n",
      "   52623/1500000: episode: 27, duration: 3.341s, episode steps: 1949, steps per second: 583, episode reward: 437.000, mean reward: 0.224 [-117.400, 191.500], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.663845, mean_absolute_error: 2.497769, mean_q: 0.229031\n",
      "[-0.6792728  1.1710455]\n",
      "[-0.4541967  1.35308  ]\n",
      "[-1.1408725  1.2633455]\n",
      "[-0.55020994  1.2878609 ]\n",
      "[-0.67944765  1.3577542 ]\n",
      "[4671, 49901]\n",
      "   54572/1500000: episode: 28, duration: 3.298s, episode steps: 1949, steps per second: 591, episode reward: 751.300, mean reward: 0.385 [-90.100, 160.600], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.814892, mean_absolute_error: 2.181170, mean_q: 0.186619\n",
      "[-0.7392632  1.0043489]\n",
      "[-0.7752421   0.52777463]\n",
      "[-1.1004031  1.3967664]\n",
      "[-0.28667152  1.3095477 ]\n",
      "[-0.5353561  1.3485878]\n",
      "[4756, 51765]\n",
      "   56521/1500000: episode: 29, duration: 3.491s, episode steps: 1949, steps per second: 558, episode reward: 745.000, mean reward: 0.382 [-121.600, 174.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.682255, mean_absolute_error: 2.334913, mean_q: 0.138671\n",
      "[-0.895184   1.0509638]\n",
      "[-0.63210356  0.74889153]\n",
      "[-1.225889   1.2895056]\n",
      "[-0.3793759  1.0429193]\n",
      "[-0.29086855  1.2411784 ]\n",
      "[4843, 53627]\n",
      "   58470/1500000: episode: 30, duration: 3.497s, episode steps: 1949, steps per second: 557, episode reward: 569.800, mean reward: 0.292 [-129.700, 154.700], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.210155, mean_absolute_error: 2.283296, mean_q: 0.153526\n",
      "[-0.45841932  1.6256222 ]\n",
      "[-1.0055339  0.8637302]\n",
      "[-0.36894166  1.5389612 ]\n",
      "[-1.0586705  1.1258466]\n",
      "[-0.9530451  1.7940714]\n",
      "[4930, 55489]\n",
      "   60419/1500000: episode: 31, duration: 3.386s, episode steps: 1949, steps per second: 576, episode reward: 434.400, mean reward: 0.223 [-157.400, 174.000], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.555134, mean_absolute_error: 2.248196, mean_q: 0.129373\n",
      "[-0.40880346  1.0674721 ]\n",
      "[-0.16464023  1.5409875 ]\n",
      "[-0.37757045  1.7823335 ]\n",
      "[-0.671771   1.2256904]\n",
      "[4998, 57370]\n",
      "   62368/1500000: episode: 32, duration: 3.470s, episode steps: 1949, steps per second: 562, episode reward: 672.200, mean reward: 0.345 [-139.100, 225.500], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.825745, mean_absolute_error: 2.179446, mean_q: 0.155687\n",
      "[-0.9655504  1.3224351]\n",
      "[-1.2091942  1.8636035]\n",
      "[-1.006101   0.8263085]\n",
      "[-1.5006961  1.1239595]\n",
      "[-1.2625387  1.3475151]\n",
      "[5071, 59246]\n",
      "   64317/1500000: episode: 33, duration: 3.405s, episode steps: 1949, steps per second: 572, episode reward: 531.900, mean reward: 0.273 [-85.800, 177.000], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 28.696083, mean_absolute_error: 1.883054, mean_q: 0.168505\n",
      "[-1.2528822  1.1470131]\n",
      "[-0.7082565  1.5599508]\n",
      "[-0.966957   1.1553931]\n",
      "[-0.7838436  1.276998 ]\n",
      "[-1.2588075  1.8721662]\n",
      "[5164, 61102]\n",
      "   66266/1500000: episode: 34, duration: 3.370s, episode steps: 1949, steps per second: 578, episode reward: 654.100, mean reward: 0.336 [-119.800, 271.900], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.808033, mean_absolute_error: 2.213849, mean_q: 0.117738\n",
      "[-1.1659776  0.615701 ]\n",
      "[-1.2793274  1.059251 ]\n",
      "[-1.2086477  1.216672 ]\n",
      "[-1.4186258  1.1166651]\n",
      "[-1.2913048  0.6506187]\n",
      "[5249, 62966]\n",
      "   68215/1500000: episode: 35, duration: 3.443s, episode steps: 1949, steps per second: 566, episode reward: 523.300, mean reward: 0.268 [-163.900, 120.000], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.406563, mean_absolute_error: 2.414291, mean_q: 0.059321\n",
      "[-1.1562146  1.4038358]\n",
      "[-0.9995124  1.3708216]\n",
      "[-0.2197592  1.1243354]\n",
      "[-0.7480725  1.2702147]\n",
      "[-0.9111884  1.3281418]\n",
      "[5329, 64835]\n",
      "   70164/1500000: episode: 36, duration: 3.358s, episode steps: 1949, steps per second: 580, episode reward: 850.300, mean reward: 0.436 [-99.900, 194.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.740097, mean_absolute_error: 2.342379, mean_q: 0.015699\n",
      "[-1.1073036   0.58826137]\n",
      "[-0.85007393  0.48917642]\n",
      "[-1.5413322  0.5592633]\n",
      "[-1.4876438  1.5588826]\n",
      "[-1.2470446  1.5167317]\n",
      "[5412, 66701]\n",
      "   72113/1500000: episode: 37, duration: 3.487s, episode steps: 1949, steps per second: 559, episode reward: 296.500, mean reward: 0.152 [-112.400, 153.200], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.726078, mean_absolute_error: 2.320545, mean_q: 0.046553\n",
      "[-1.0913222  1.2640824]\n",
      "[-1.4654413  1.0001854]\n",
      "[-0.5874725  1.189648 ]\n",
      "[-0.5828328  1.2524955]\n",
      "[-0.7262823  0.9646402]\n",
      "[5495, 68567]\n",
      "   74062/1500000: episode: 38, duration: 3.351s, episode steps: 1949, steps per second: 582, episode reward: 534.500, mean reward: 0.274 [-119.200, 145.600], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.290695, mean_absolute_error: 2.112107, mean_q: 0.085002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0964484  1.774286 ]\n",
      "[-1.4944606  0.8796304]\n",
      "[-0.71965617  1.6278561 ]\n",
      "[-1.6514903  1.7148739]\n",
      "[-1.3703425  1.5769637]\n",
      "[5560, 70451]\n",
      "   76011/1500000: episode: 39, duration: 3.315s, episode steps: 1949, steps per second: 588, episode reward: 286.800, mean reward: 0.147 [-117.900, 146.900], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.053303, mean_absolute_error: 2.359577, mean_q: 0.194312\n",
      "[-1.3653916   0.65297794]\n",
      "[-0.05957187  1.5150992 ]\n",
      "[-0.7121823  1.0651178]\n",
      "[-0.09550013  1.4153908 ]\n",
      "[5632, 72328]\n",
      "   77960/1500000: episode: 40, duration: 3.345s, episode steps: 1949, steps per second: 583, episode reward: 577.400, mean reward: 0.296 [-139.300, 199.400], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.112473, mean_absolute_error: 2.447033, mean_q: 0.291323\n",
      "[-0.8729865  1.174605 ]\n",
      "[-0.9336839  1.5246216]\n",
      "[-0.73877734  1.358011  ]\n",
      "[-1.347247   1.0372554]\n",
      "[-0.20564114  0.9926218 ]\n",
      "[5724, 74185]\n",
      "   79909/1500000: episode: 41, duration: 3.393s, episode steps: 1949, steps per second: 574, episode reward: 562.400, mean reward: 0.289 [-83.400, 159.200], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.762131, mean_absolute_error: 2.628147, mean_q: 0.342844\n",
      "[-0.87406343  1.0218076 ]\n",
      "[-1.078486   1.1961874]\n",
      "[-0.77695364  1.1596341 ]\n",
      "[-1.0442362  1.1138506]\n",
      "[-0.8773176   0.87353516]\n",
      "[5808, 76050]\n",
      "   81858/1500000: episode: 42, duration: 3.556s, episode steps: 1949, steps per second: 548, episode reward: 570.000, mean reward: 0.292 [-129.000, 220.300], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.714199, mean_absolute_error: 2.251734, mean_q: 0.406141\n",
      "[-0.41352713  0.91310567]\n",
      "[-0.9507195  1.1283053]\n",
      "[-0.8105312  1.2390672]\n",
      "[-0.68976057  1.5207632 ]\n",
      "[-0.4896481  1.0284446]\n",
      "[5885, 77922]\n",
      "   83807/1500000: episode: 43, duration: 3.548s, episode steps: 1949, steps per second: 549, episode reward: 551.300, mean reward: 0.283 [-123.900, 236.600], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 72.273094, mean_absolute_error: 2.810523, mean_q: 0.379826\n",
      "[-1.0527358  0.7297057]\n",
      "[-1.0660927  1.6116987]\n",
      "[-1.1367557  1.4580169]\n",
      "[-1.2932619  2.1798818]\n",
      "[-0.97621447  1.6713895 ]\n",
      "[5969, 79787]\n",
      "   85756/1500000: episode: 44, duration: 5.874s, episode steps: 1949, steps per second: 332, episode reward: 670.700, mean reward: 0.344 [-144.600, 166.100], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.316402, mean_absolute_error: 2.083801, mean_q: 0.241112\n",
      "[-0.23167804  1.0631607 ]\n",
      "[-0.9074152  1.2382177]\n",
      "[-1.2655798  1.498703 ]\n",
      "[-1.0350914  0.6034815]\n",
      "[-0.68511593  1.0232831 ]\n",
      "[6036, 81669]\n",
      "   87705/1500000: episode: 45, duration: 3.820s, episode steps: 1949, steps per second: 510, episode reward: 739.300, mean reward: 0.379 [-91.400, 213.800], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.817104, mean_absolute_error: 2.049317, mean_q: 0.097760\n",
      "[-0.8614466  0.7617163]\n",
      "[-1.1680634  0.8347072]\n",
      "[-1.0733755  1.6580758]\n",
      "[-1.2433041  1.4330937]\n",
      "[-1.4102812  1.5640612]\n",
      "[6099, 83555]\n",
      "   89654/1500000: episode: 46, duration: 3.599s, episode steps: 1949, steps per second: 542, episode reward: 619.600, mean reward: 0.318 [-132.900, 164.100], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 72.585335, mean_absolute_error: 2.349441, mean_q: -0.008493\n",
      "[-0.3649097  1.3934926]\n",
      "[-0.41716895  1.4945852 ]\n",
      "[-0.39947334  1.1870525 ]\n",
      "[-0.2916028  1.025095 ]\n",
      "[-1.3845024   0.64101404]\n",
      "[6161, 85442]\n",
      "   91603/1500000: episode: 47, duration: 3.426s, episode steps: 1949, steps per second: 569, episode reward: 222.800, mean reward: 0.114 [-117.500, 180.000], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 62.772415, mean_absolute_error: 2.090466, mean_q: -0.016833\n",
      "[-0.6654604  1.5303539]\n",
      "[-0.9513333   0.87265056]\n",
      "[-1.3568403   0.79008406]\n",
      "[-0.49520987  0.40747577]\n",
      "[6235, 87317]\n",
      "   93552/1500000: episode: 48, duration: 3.514s, episode steps: 1949, steps per second: 555, episode reward: 390.600, mean reward: 0.200 [-134.300, 146.800], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.670883, mean_absolute_error: 2.036877, mean_q: 0.048484\n",
      "[-1.0202353  1.1363134]\n",
      "[-1.0570008  1.3449782]\n",
      "[-1.329407   1.8990545]\n",
      "[-0.98140657  1.901737  ]\n",
      "[-1.7000377  1.3886006]\n",
      "[6326, 89175]\n",
      "   95501/1500000: episode: 49, duration: 3.425s, episode steps: 1949, steps per second: 569, episode reward: 421.100, mean reward: 0.216 [-86.600, 173.100], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.837204, mean_absolute_error: 1.583858, mean_q: 0.037001\n",
      "[-1.0091231  1.0513206]\n",
      "[-0.86183053  0.888135  ]\n",
      "[-0.87324226  1.3191646 ]\n",
      "[-0.3124279  1.0547965]\n",
      "[-0.4156302  1.2822319]\n",
      "[6399, 91051]\n",
      "   97450/1500000: episode: 50, duration: 3.561s, episode steps: 1949, steps per second: 547, episode reward: 794.700, mean reward: 0.408 [-109.200, 209.100], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.606201, mean_absolute_error: 1.850052, mean_q: 0.190659\n",
      "[-0.95394325  1.6536623 ]\n",
      "[-0.6381317  1.2148094]\n",
      "[-0.112204   1.0286676]\n",
      "[-1.1089808  1.489959 ]\n",
      "[-0.58960986  0.5494585 ]\n",
      "[6473, 92926]\n",
      "   99399/1500000: episode: 51, duration: 3.558s, episode steps: 1949, steps per second: 548, episode reward: 676.600, mean reward: 0.347 [-106.000, 153.200], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 81.887009, mean_absolute_error: 2.778077, mean_q: 0.455448\n",
      "[-1.2846427   0.91653204]\n",
      "[-0.71480405  1.1806267 ]\n",
      "[-0.6083471  1.4661199]\n",
      "[-0.8585665  1.4876968]\n",
      "[-0.8108178  1.5602274]\n",
      "[6548, 94800]\n",
      "  101348/1500000: episode: 52, duration: 3.493s, episode steps: 1949, steps per second: 558, episode reward: 340.100, mean reward: 0.174 [-89.800, 204.700], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.865589, mean_absolute_error: 2.261932, mean_q: 0.422673\n",
      "[-0.6228861  1.0267233]\n",
      "[-0.0270524  1.17638  ]\n",
      "[-0.5499446  1.259537 ]\n",
      "[-0.9295993  1.7748061]\n",
      "[-0.3060845  0.7796696]\n",
      "[6623, 96674]\n",
      "  103297/1500000: episode: 53, duration: 3.402s, episode steps: 1949, steps per second: 573, episode reward: 781.000, mean reward: 0.401 [-100.200, 133.300], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 89.346924, mean_absolute_error: 2.637410, mean_q: 0.203596\n",
      "[-0.63506794  0.6400032 ]\n",
      "[-1.5924964  1.117942 ]\n",
      "[-0.723536   1.0229647]\n",
      "[-1.1726376  1.303806 ]\n",
      "[-0.9589748  1.0195355]\n",
      "[6699, 98547]\n",
      "  105246/1500000: episode: 54, duration: 3.436s, episode steps: 1949, steps per second: 567, episode reward: 282.100, mean reward: 0.145 [-179.200, 155.800], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.818771, mean_absolute_error: 2.152410, mean_q: 0.157514\n",
      "[-0.81982785  1.6377927 ]\n",
      "[-0.6091682  1.1437035]\n",
      "[-1.1576033  1.1723831]\n",
      "[-1.0112691  1.6608162]\n",
      "[6784, 100411]\n",
      "  107195/1500000: episode: 55, duration: 3.394s, episode steps: 1949, steps per second: 574, episode reward: 572.400, mean reward: 0.294 [-84.800, 141.500], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.063499, mean_absolute_error: 2.081384, mean_q: 0.155518\n",
      "[-0.9801436  1.1214473]\n",
      "[-0.5828538  0.465531 ]\n",
      "[-1.1354134   0.77786255]\n",
      "[-1.1345881  1.4570566]\n",
      "[-0.9511727  1.466771 ]\n",
      "[6861, 102283]\n",
      "  109144/1500000: episode: 56, duration: 3.344s, episode steps: 1949, steps per second: 583, episode reward: 233.900, mean reward: 0.120 [-123.100, 148.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.101692, mean_absolute_error: 1.908979, mean_q: 0.193994\n",
      "[-1.134679   0.9699285]\n",
      "[-0.2825253  1.683956 ]\n",
      "[-0.38245425  1.5011647 ]\n",
      "[-0.5238303  1.6182019]\n",
      "[-0.7748242  1.7780862]\n",
      "[6934, 104159]\n",
      "  111093/1500000: episode: 57, duration: 3.432s, episode steps: 1949, steps per second: 568, episode reward: 605.000, mean reward: 0.310 [-101.300, 192.200], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.300426, mean_absolute_error: 1.671937, mean_q: 0.216973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7950661  0.9192273]\n",
      "[-1.079615    0.62608117]\n",
      "[-0.6521603  1.60364  ]\n",
      "[-1.2992285  1.4846764]\n",
      "[-0.75745714  1.1533307 ]\n",
      "[7012, 106030]\n",
      "  113042/1500000: episode: 58, duration: 3.396s, episode steps: 1949, steps per second: 574, episode reward: 627.800, mean reward: 0.322 [-175.500, 152.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.549210, mean_absolute_error: 1.919059, mean_q: 0.207682\n",
      "[-1.1310868  0.8139917]\n",
      "[-0.9509781  1.5467178]\n",
      "[-0.5537992  0.8877406]\n",
      "[-0.9034553  1.32129  ]\n",
      "[-1.4379855  1.7319148]\n",
      "[7092, 107899]\n",
      "  114991/1500000: episode: 59, duration: 3.434s, episode steps: 1949, steps per second: 568, episode reward: 668.600, mean reward: 0.343 [-138.900, 136.300], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.144402, mean_absolute_error: 1.728806, mean_q: 0.196306\n",
      "[-0.77540237  0.994977  ]\n",
      "[-0.7010878  1.3287572]\n",
      "[-0.48587024  1.5657094 ]\n",
      "[-0.6233982  1.4741147]\n",
      "[-0.5625937  1.4441595]\n",
      "[7169, 109771]\n",
      "  116940/1500000: episode: 60, duration: 3.581s, episode steps: 1949, steps per second: 544, episode reward: 398.900, mean reward: 0.205 [-133.100, 166.100], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.448967, mean_absolute_error: 1.813042, mean_q: 0.195598\n",
      "[-0.9485041  1.2165939]\n",
      "[-0.6178383  1.1443796]\n",
      "[-1.0024157  1.0057505]\n",
      "[-0.5589543  1.3226763]\n",
      "[-0.09152774  1.7728684 ]\n",
      "[7246, 111643]\n",
      "  118889/1500000: episode: 61, duration: 3.508s, episode steps: 1949, steps per second: 556, episode reward: 360.800, mean reward: 0.185 [-114.900, 159.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.776436, mean_absolute_error: 1.808616, mean_q: 0.111822\n",
      "[-1.5075393  0.8107304]\n",
      "[-1.0712206  1.1374338]\n",
      "[-1.0908636  1.2014858]\n",
      "[-0.71142405  1.007801  ]\n",
      "[-0.7593629  1.719631 ]\n",
      "[7331, 113507]\n",
      "  120838/1500000: episode: 62, duration: 3.415s, episode steps: 1949, steps per second: 571, episode reward: 651.100, mean reward: 0.334 [-71.600, 223.500], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.581547, mean_absolute_error: 2.056787, mean_q: 0.070641\n",
      "[-1.4855756  1.5443425]\n",
      "[-1.6476866  1.9692225]\n",
      "[-1.0881207  1.3845371]\n",
      "[-0.87115216  1.5774295 ]\n",
      "[7407, 115380]\n",
      "  122787/1500000: episode: 63, duration: 3.567s, episode steps: 1949, steps per second: 546, episode reward: 334.900, mean reward: 0.172 [-133.300, 195.100], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.334763, mean_absolute_error: 1.694395, mean_q: 0.063896\n",
      "[-1.017341   0.8963324]\n",
      "[-0.68983626  0.9954175 ]\n",
      "[-0.5514973  1.256597 ]\n",
      "[-0.35874045  1.585668  ]\n",
      "[-0.8456665  1.5147275]\n",
      "[7504, 117232]\n",
      "  124736/1500000: episode: 64, duration: 3.458s, episode steps: 1949, steps per second: 564, episode reward: 628.400, mean reward: 0.322 [-96.400, 139.800], mean action: 0.950 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.364868, mean_absolute_error: 1.698899, mean_q: 0.082149\n",
      "[-0.89964527  1.1048577 ]\n",
      "[-1.336921   1.5566498]\n",
      "[-1.651312   1.3297348]\n",
      "[-0.32049143  1.3247579 ]\n",
      "[-0.5991263  1.412425 ]\n",
      "[7592, 119093]\n",
      "  126685/1500000: episode: 65, duration: 3.428s, episode steps: 1949, steps per second: 569, episode reward: 615.800, mean reward: 0.316 [-134.300, 185.600], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.202091, mean_absolute_error: 1.625859, mean_q: 0.120714\n",
      "[-0.89453703  1.2547458 ]\n",
      "[-0.602152    0.96230316]\n",
      "[-0.6010351  1.5563911]\n",
      "[-0.55758816  1.0148888 ]\n",
      "[-0.59345454  2.0604334 ]\n",
      "[7668, 120966]\n",
      "  128634/1500000: episode: 66, duration: 3.322s, episode steps: 1949, steps per second: 587, episode reward: 297.000, mean reward: 0.152 [-198.800, 192.700], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 74.360466, mean_absolute_error: 2.239676, mean_q: 0.134169\n",
      "[-0.6091883  1.11738  ]\n",
      "[-0.81870943  0.9316448 ]\n",
      "[-1.3343055  0.8242215]\n",
      "[-0.81135607  1.0497963 ]\n",
      "[-0.63597566  1.2889988 ]\n",
      "[7741, 122842]\n",
      "  130583/1500000: episode: 67, duration: 3.378s, episode steps: 1949, steps per second: 577, episode reward: 425.800, mean reward: 0.218 [-84.300, 177.000], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 70.437378, mean_absolute_error: 2.005082, mean_q: 0.165798\n",
      "[-0.7628899  1.2395228]\n",
      "[-0.66556776  1.3642178 ]\n",
      "[-0.633388   1.3613639]\n",
      "[-0.6760576  1.0563717]\n",
      "[-0.3066686  0.5067482]\n",
      "[7845, 124687]\n",
      "  132532/1500000: episode: 68, duration: 3.361s, episode steps: 1949, steps per second: 580, episode reward: 594.000, mean reward: 0.305 [-107.800, 154.500], mean action: 0.947 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 30.595469, mean_absolute_error: 1.324403, mean_q: 0.226917\n",
      "[-0.93163824  0.73065597]\n",
      "[-1.0886399  0.5454601]\n",
      "[-1.0015323  0.7801407]\n",
      "[-1.8910011  0.4316518]\n",
      "[-1.7788595  0.7753956]\n",
      "[7907, 126574]\n",
      "  134481/1500000: episode: 69, duration: 3.415s, episode steps: 1949, steps per second: 571, episode reward: 690.600, mean reward: 0.354 [-67.000, 219.300], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 31.390615, mean_absolute_error: 1.660388, mean_q: 0.257321\n",
      "[-0.69313335  0.2977755 ]\n",
      "[-0.50886136  0.7556556 ]\n",
      "[-0.7163766  1.1506314]\n",
      "[-0.5486243  1.1123472]\n",
      "[-0.5400108  1.6513876]\n",
      "[7976, 128454]\n",
      "  136430/1500000: episode: 70, duration: 3.313s, episode steps: 1949, steps per second: 588, episode reward: 577.800, mean reward: 0.296 [-150.900, 130.600], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.907982, mean_absolute_error: 1.981803, mean_q: 0.286278\n",
      "[-0.73147464  0.6971406 ]\n",
      "[-1.0316793  1.0139413]\n",
      "[-1.2906823  1.8536651]\n",
      "[-1.1810375  1.1507213]\n",
      "[8052, 130327]\n",
      "  138379/1500000: episode: 71, duration: 3.398s, episode steps: 1949, steps per second: 574, episode reward: 421.400, mean reward: 0.216 [-99.100, 207.900], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.062248, mean_absolute_error: 2.192192, mean_q: 0.270226\n",
      "[-1.0543507   0.89457786]\n",
      "[-0.6493222   0.93252635]\n",
      "[-1.3026828  0.7709871]\n",
      "[-1.2454333  1.5555025]\n",
      "[-0.548723   0.5411855]\n",
      "[8154, 132174]\n",
      "  140328/1500000: episode: 72, duration: 3.287s, episode steps: 1949, steps per second: 593, episode reward: 892.800, mean reward: 0.458 [-110.100, 185.300], mean action: 0.948 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.091591, mean_absolute_error: 1.905467, mean_q: 0.278340\n",
      "[-0.883372   0.9371617]\n",
      "[-1.5989114  1.0090152]\n",
      "[-0.93198496  1.2786874 ]\n",
      "[-1.0557132  1.6842028]\n",
      "[-0.40206665  0.9271267 ]\n",
      "[8225, 134052]\n",
      "  142277/1500000: episode: 73, duration: 3.391s, episode steps: 1949, steps per second: 575, episode reward: 679.600, mean reward: 0.349 [-81.000, 189.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.238083, mean_absolute_error: 2.015141, mean_q: 0.258655\n",
      "[-0.84683216  0.95255136]\n",
      "[-1.5410075  1.0236558]\n",
      "[-1.1101933  0.6395643]\n",
      "[-0.3061816  1.5481701]\n",
      "[-0.91281676  0.7840843 ]\n",
      "[8317, 135909]\n",
      "  144226/1500000: episode: 74, duration: 3.421s, episode steps: 1949, steps per second: 570, episode reward: 599.900, mean reward: 0.308 [-86.200, 197.000], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.350571, mean_absolute_error: 2.406458, mean_q: 0.243966\n",
      "[-1.0842407  1.0367304]\n",
      "[-0.3135208  1.3082038]\n",
      "[0.13494144 2.0458963 ]\n",
      "[-0.99654245  1.4069432 ]\n",
      "[-0.8345582   0.81455594]\n",
      "[8384, 137791]\n",
      "  146175/1500000: episode: 75, duration: 3.337s, episode steps: 1949, steps per second: 584, episode reward: 611.100, mean reward: 0.314 [-126.400, 227.800], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.107414, mean_absolute_error: 2.202847, mean_q: 0.255079\n",
      "[-0.44383416  1.2582725 ]\n",
      "[-1.0074629   0.80455256]\n",
      "[-0.27961302  1.5478299 ]\n",
      "[-1.4117835  1.3752233]\n",
      "[-0.82793283  1.8786758 ]\n",
      "[8470, 139654]\n",
      "  148124/1500000: episode: 76, duration: 3.345s, episode steps: 1949, steps per second: 583, episode reward: 552.800, mean reward: 0.284 [-152.900, 167.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.663445, mean_absolute_error: 1.856528, mean_q: 0.283714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8881838  1.0516942]\n",
      "[-0.7929784  1.474873 ]\n",
      "[-0.33144236  1.4631829 ]\n",
      "[-0.8496097  1.1381382]\n",
      "[-1.3485646  1.4213115]\n",
      "[8532, 141541]\n",
      "  150073/1500000: episode: 77, duration: 3.317s, episode steps: 1949, steps per second: 588, episode reward: 413.200, mean reward: 0.212 [-88.200, 219.200], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.784237, mean_absolute_error: 1.983355, mean_q: 0.303776\n",
      "[-0.6841744   0.85580575]\n",
      "[-0.6910369  0.5895689]\n",
      "[-0.8223978  1.8134905]\n",
      "[-1.1052886  1.3205619]\n",
      "[-0.6231059  1.9534109]\n",
      "[8608, 143414]\n",
      "  152022/1500000: episode: 78, duration: 3.334s, episode steps: 1949, steps per second: 585, episode reward: 328.400, mean reward: 0.168 [-92.100, 183.400], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.916901, mean_absolute_error: 2.078285, mean_q: 0.230388\n",
      "[-1.1358348   0.91275924]\n",
      "[-1.5263764  0.5975858]\n",
      "[-1.1337203  0.7561228]\n",
      "[-0.70304406  1.1722597 ]\n",
      "[8681, 145290]\n",
      "  153971/1500000: episode: 79, duration: 3.182s, episode steps: 1949, steps per second: 613, episode reward: 323.900, mean reward: 0.166 [-121.600, 177.700], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.024361, mean_absolute_error: 1.871844, mean_q: 0.159430\n",
      "[-0.9418828  0.8243089]\n",
      "[-1.0220776  1.1732156]\n",
      "[-0.72620815  1.686628  ]\n",
      "[-0.70310193  1.1448283 ]\n",
      "[-1.0063472  0.8203362]\n",
      "[8739, 147181]\n",
      "  155920/1500000: episode: 80, duration: 3.487s, episode steps: 1949, steps per second: 559, episode reward: 561.600, mean reward: 0.288 [-108.000, 127.100], mean action: 0.970 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.863762, mean_absolute_error: 1.970882, mean_q: 0.104371\n",
      "[-0.95297945  1.1322732 ]\n",
      "[0.23289797 0.44863445]\n",
      "[-0.68944097  1.1655928 ]\n",
      "[-0.6710101  1.4502419]\n",
      "[-0.7134123  1.1385517]\n",
      "[8813, 149056]\n",
      "  157869/1500000: episode: 81, duration: 3.403s, episode steps: 1949, steps per second: 573, episode reward: 619.400, mean reward: 0.318 [-188.700, 235.900], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.067299, mean_absolute_error: 2.002690, mean_q: 0.075772\n",
      "[-1.0140144  1.1833907]\n",
      "[-1.2678673  1.0115482]\n",
      "[-0.76284355  0.6486027 ]\n",
      "[-0.510071   1.5699418]\n",
      "[-1.565969   1.1995101]\n",
      "[8884, 150934]\n",
      "  159818/1500000: episode: 82, duration: 3.314s, episode steps: 1949, steps per second: 588, episode reward: 315.600, mean reward: 0.162 [-168.700, 148.800], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.504807, mean_absolute_error: 1.550230, mean_q: 0.071520\n",
      "[-1.2829273   0.67014295]\n",
      "[-1.2463673  0.6962727]\n",
      "[-1.0036104   0.75905156]\n",
      "[-1.7218897  1.3920588]\n",
      "[-0.57159543  1.6577398 ]\n",
      "[8954, 152813]\n",
      "  161767/1500000: episode: 83, duration: 3.357s, episode steps: 1949, steps per second: 581, episode reward: 417.300, mean reward: 0.214 [-132.200, 181.600], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.070995, mean_absolute_error: 1.776000, mean_q: 0.084123\n",
      "[-1.0993639   0.39987174]\n",
      "[-1.054844   1.5672953]\n",
      "[-1.0019641  1.0203567]\n",
      "[-0.9647024  1.576893 ]\n",
      "[-0.99524635  1.3678857 ]\n",
      "[9024, 154692]\n",
      "  163716/1500000: episode: 84, duration: 3.284s, episode steps: 1949, steps per second: 593, episode reward: 476.300, mean reward: 0.244 [-155.100, 125.200], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.251358, mean_absolute_error: 2.506451, mean_q: 0.656025\n",
      "[-1.0680192  1.1231189]\n",
      "[-1.0460469  0.2665758]\n",
      "[-1.3959253  -0.00155709]\n",
      "[-0.37572128  1.5272868 ]\n",
      "[-0.64098537  1.3999057 ]\n",
      "[9112, 156553]\n",
      "  165665/1500000: episode: 85, duration: 3.366s, episode steps: 1949, steps per second: 579, episode reward: 413.400, mean reward: 0.212 [-83.800, 150.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.072479, mean_absolute_error: 1.845119, mean_q: 0.137387\n",
      "[-1.310998  0.903437]\n",
      "[-1.1697804  1.2624942]\n",
      "[-0.5230191  0.6610423]\n",
      "[-0.6680846  0.8422465]\n",
      "[-0.8883065  1.4485147]\n",
      "[9185, 158429]\n",
      "  167614/1500000: episode: 86, duration: 3.427s, episode steps: 1949, steps per second: 569, episode reward: 156.200, mean reward: 0.080 [-168.700, 142.900], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.730556, mean_absolute_error: 1.604787, mean_q: 0.101283\n",
      "[-0.99049044  0.8401923 ]\n",
      "[-0.72767574  1.0616512 ]\n",
      "[-1.045852   0.9980934]\n",
      "[-0.8988135  1.0839577]\n",
      "[9263, 160300]\n",
      "  169563/1500000: episode: 87, duration: 3.342s, episode steps: 1949, steps per second: 583, episode reward: 185.100, mean reward: 0.095 [-115.900, 248.000], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 32.039154, mean_absolute_error: 1.569924, mean_q: 0.202258\n",
      "[-0.9722886  1.1295733]\n",
      "[-0.7778752  1.0779804]\n",
      "[-0.5208412  1.0410956]\n",
      "[-1.3296629  0.4360384]\n",
      "[-0.9576062  0.6983072]\n",
      "[9348, 162164]\n",
      "  171512/1500000: episode: 88, duration: 3.403s, episode steps: 1949, steps per second: 573, episode reward: 309.000, mean reward: 0.159 [-211.400, 160.400], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 35.882065, mean_absolute_error: 1.612114, mean_q: 0.237517\n",
      "[-0.6060703   0.98428506]\n",
      "[-0.8413786  1.4032254]\n",
      "[-1.1993223  1.1956526]\n",
      "[-0.6767905  1.2132095]\n",
      "[-1.1289521  1.7830158]\n",
      "[9425, 164036]\n",
      "  173461/1500000: episode: 89, duration: 3.313s, episode steps: 1949, steps per second: 588, episode reward: 776.700, mean reward: 0.399 [-138.300, 174.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.122631, mean_absolute_error: 1.900311, mean_q: 0.262647\n",
      "[-0.67208403  0.7987053 ]\n",
      "[-0.34595966  0.69570047]\n",
      "[-0.9322091  1.1315507]\n",
      "[-1.0304464  0.6240142]\n",
      "[-0.8719063  1.441228 ]\n",
      "[9516, 165894]\n",
      "  175410/1500000: episode: 90, duration: 3.407s, episode steps: 1949, steps per second: 572, episode reward: 633.800, mean reward: 0.325 [-143.000, 146.900], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.632805, mean_absolute_error: 1.603573, mean_q: 0.304131\n",
      "[-1.1887832  1.3466698]\n",
      "[-1.3549544  1.0425717]\n",
      "[-0.90353554  1.2483314 ]\n",
      "[-0.5533592  1.4160355]\n",
      "[-0.77616835  1.7071617 ]\n",
      "[9592, 167767]\n",
      "  177359/1500000: episode: 91, duration: 3.367s, episode steps: 1949, steps per second: 579, episode reward: 601.000, mean reward: 0.308 [-128.200, 197.000], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.558083, mean_absolute_error: 1.893101, mean_q: 0.325673\n",
      "[-0.6222527  1.5250552]\n",
      "[-0.73929894  1.6903095 ]\n",
      "[-1.2998077  1.4101808]\n",
      "[-0.5445777  1.1612259]\n",
      "[-1.1565946  1.25155  ]\n",
      "[9672, 169636]\n",
      "  179308/1500000: episode: 92, duration: 3.175s, episode steps: 1949, steps per second: 614, episode reward: 191.900, mean reward: 0.098 [-100.800, 130.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.270393, mean_absolute_error: 2.156706, mean_q: 0.211274\n",
      "[-0.65084594  1.4899307 ]\n",
      "[-0.8843176  1.6151   ]\n",
      "[-0.7963911  1.3521928]\n",
      "[-0.32562938  1.1946515 ]\n",
      "[-0.74224865  1.5496262 ]\n",
      "[9759, 171498]\n",
      "  181257/1500000: episode: 93, duration: 3.232s, episode steps: 1949, steps per second: 603, episode reward: 795.900, mean reward: 0.408 [-84.700, 192.900], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.803852, mean_absolute_error: 1.685917, mean_q: 0.181975\n",
      "[-1.034377   1.1258487]\n",
      "[-0.7283346  1.3812484]\n",
      "[-0.47426897  1.0902681 ]\n",
      "[-0.05266311  1.2722303 ]\n",
      "[-0.5827762  1.2621019]\n",
      "[9816, 173390]\n",
      "  183206/1500000: episode: 94, duration: 3.168s, episode steps: 1949, steps per second: 615, episode reward: 635.300, mean reward: 0.326 [-77.300, 166.100], mean action: 0.971 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 26.024452, mean_absolute_error: 1.256924, mean_q: 0.128486\n",
      "[-0.25315812  1.4019061 ]\n",
      "[0.01640637 1.6214054 ]\n",
      "[-0.33096147  0.7406198 ]\n",
      "[-0.9969896   0.32241958]\n",
      "[9897, 175258]\n",
      "  185155/1500000: episode: 95, duration: 3.165s, episode steps: 1949, steps per second: 616, episode reward: 565.500, mean reward: 0.290 [-105.100, 159.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.511158, mean_absolute_error: 1.866269, mean_q: 0.054499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6306599  1.0101256]\n",
      "[-0.5791379  1.0014187]\n",
      "[-1.1086454  0.9030504]\n",
      "[-0.1685089  1.5838876]\n",
      "[-0.5727233  1.5449849]\n",
      "[9969, 177135]\n",
      "  187104/1500000: episode: 96, duration: 3.327s, episode steps: 1949, steps per second: 586, episode reward: 408.300, mean reward: 0.209 [-100.900, 170.200], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.333370, mean_absolute_error: 1.649923, mean_q: 0.039542\n",
      "[-0.7069023  0.652196 ]\n",
      "[-0.76953316  0.7722228 ]\n",
      "[-1.5135064  1.0940797]\n",
      "[-0.9718044  0.7946279]\n",
      "[-0.43748942  1.0486286 ]\n",
      "[10058, 178995]\n",
      "  189053/1500000: episode: 97, duration: 3.349s, episode steps: 1949, steps per second: 582, episode reward: 642.500, mean reward: 0.330 [-108.400, 140.800], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 31.565212, mean_absolute_error: 1.396656, mean_q: 0.027514\n",
      "[-0.9132031  0.9515548]\n",
      "[-0.74972194  0.63238144]\n",
      "[-1.0843742   0.46184003]\n",
      "[-0.3178336  0.3673886]\n",
      "[-0.84675825  0.512378  ]\n",
      "[10135, 180867]\n",
      "  191002/1500000: episode: 98, duration: 3.372s, episode steps: 1949, steps per second: 578, episode reward: 536.300, mean reward: 0.275 [-104.800, 174.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.094017, mean_absolute_error: 1.497444, mean_q: 0.044587\n",
      "[-0.67731553  1.2747049 ]\n",
      "[-0.7245133  1.3224899]\n",
      "[-1.133505   1.8665172]\n",
      "[-0.8738936  1.6521493]\n",
      "[-0.59642905  1.2166    ]\n",
      "[10213, 182738]\n",
      "  192951/1500000: episode: 99, duration: 3.329s, episode steps: 1949, steps per second: 585, episode reward: 228.100, mean reward: 0.117 [-154.500, 194.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.437309, mean_absolute_error: 1.746018, mean_q: 0.099415\n",
      "[-0.8990322  1.0185182]\n",
      "[-0.85190475  1.0207858 ]\n",
      "[-0.8060179  1.6522013]\n",
      "[-0.7250431  0.9236552]\n",
      "[-1.3009198  1.1003983]\n",
      "[10279, 184621]\n",
      "  194900/1500000: episode: 100, duration: 3.553s, episode steps: 1949, steps per second: 549, episode reward: 437.500, mean reward: 0.224 [-187.200, 236.600], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.346722, mean_absolute_error: 1.898765, mean_q: 0.180426\n",
      "[-1.2126068  1.5074672]\n",
      "[-1.0459158  1.2549794]\n",
      "[-0.74861586  0.88326347]\n",
      "[-1.3457191  1.4168591]\n",
      "[-0.43797246  1.7000146 ]\n",
      "[10366, 186483]\n",
      "  196849/1500000: episode: 101, duration: 3.445s, episode steps: 1949, steps per second: 566, episode reward: 548.700, mean reward: 0.282 [-109.000, 150.400], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 28.414165, mean_absolute_error: 1.644974, mean_q: 0.264569\n",
      "[-0.27515078  1.8036554 ]\n",
      "[-0.3513068  1.875077 ]\n",
      "[-0.81383353  1.4133738 ]\n",
      "[-0.83533806  1.7885303 ]\n",
      "[10444, 188354]\n",
      "  198798/1500000: episode: 102, duration: 4.354s, episode steps: 1949, steps per second: 448, episode reward: 640.700, mean reward: 0.329 [-123.400, 122.600], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.611237, mean_absolute_error: 1.974439, mean_q: 0.232528\n",
      "[-1.0076792   0.95337325]\n",
      "[-1.1968453  1.1198148]\n",
      "[-0.20940687  0.7746069 ]\n",
      "[-1.635952   1.8174059]\n",
      "[-1.298155   1.7675583]\n",
      "[10535, 190212]\n",
      "  200747/1500000: episode: 103, duration: 4.522s, episode steps: 1949, steps per second: 431, episode reward: 474.100, mean reward: 0.243 [-148.300, 174.200], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 61.481628, mean_absolute_error: 2.053483, mean_q: 0.137505\n",
      "[-0.98326457  1.1186646 ]\n",
      "[-0.6960902  1.4862835]\n",
      "[-0.71660817  1.7423121 ]\n",
      "[-0.9159362  1.3613615]\n",
      "[-0.32611686  0.800049  ]\n",
      "[10616, 192080]\n",
      "  202696/1500000: episode: 104, duration: 4.200s, episode steps: 1949, steps per second: 464, episode reward: 563.300, mean reward: 0.289 [-187.600, 209.200], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 62.165504, mean_absolute_error: 2.257187, mean_q: 0.089926\n",
      "[-0.7884581   0.74210846]\n",
      "[-0.7029308  1.1672555]\n",
      "[-1.4111922  0.83329  ]\n",
      "[-1.2825415   0.93105483]\n",
      "[-1.2727547  1.3148239]\n",
      "[10703, 193942]\n",
      "  204645/1500000: episode: 105, duration: 3.853s, episode steps: 1949, steps per second: 506, episode reward: 709.600, mean reward: 0.364 [-114.400, 178.300], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.835102, mean_absolute_error: 1.739956, mean_q: 0.069853\n",
      "[-0.5836512  0.6569666]\n",
      "[-0.5480483  0.8104833]\n",
      "[-0.3180534  1.0687989]\n",
      "[-0.5746657  0.5307008]\n",
      "[-1.1136144  1.2821431]\n",
      "[10802, 195792]\n",
      "  206594/1500000: episode: 106, duration: 3.454s, episode steps: 1949, steps per second: 564, episode reward: 271.000, mean reward: 0.139 [-138.300, 129.500], mean action: 0.949 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 80.230415, mean_absolute_error: 2.324472, mean_q: 0.107286\n",
      "[-0.97811204  1.5246799 ]\n",
      "[-0.92378366  0.9373316 ]\n",
      "[-0.371554   0.6395688]\n",
      "[-0.8197932  0.6215406]\n",
      "[-0.9339219  0.5996992]\n",
      "[10872, 197671]\n",
      "  208543/1500000: episode: 107, duration: 3.528s, episode steps: 1949, steps per second: 552, episode reward: 194.400, mean reward: 0.100 [-99.700, 139.800], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.744267, mean_absolute_error: 1.456528, mean_q: 0.134550\n",
      "[-0.3418881  1.3801025]\n",
      "[-0.87314916  0.48285943]\n",
      "[-0.581464   1.2676739]\n",
      "[-0.26592463  1.017608  ]\n",
      "[-1.0765673  1.2475299]\n",
      "[10932, 199560]\n",
      "  210492/1500000: episode: 108, duration: 3.338s, episode steps: 1949, steps per second: 584, episode reward: 802.800, mean reward: 0.412 [-88.200, 184.900], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.521381, mean_absolute_error: 1.663152, mean_q: 0.134287\n",
      "[-0.6760145  1.2911706]\n",
      "[-0.6619588  0.8960633]\n",
      "[-0.8974439   0.77174103]\n",
      "[-0.7212051  0.6190926]\n",
      "[-1.0129023  0.6902744]\n",
      "[11009, 201432]\n",
      "  212441/1500000: episode: 109, duration: 3.394s, episode steps: 1949, steps per second: 574, episode reward: 271.500, mean reward: 0.139 [-112.200, 99.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.896248, mean_absolute_error: 1.684599, mean_q: 0.167352\n",
      "[-1.035385   1.2660704]\n",
      "[-0.6680725  1.2286708]\n",
      "[-0.2220102  1.1555889]\n",
      "[-1.4503376  0.3899403]\n",
      "[11102, 203288]\n",
      "  214390/1500000: episode: 110, duration: 3.244s, episode steps: 1949, steps per second: 601, episode reward: 692.700, mean reward: 0.355 [-132.100, 184.100], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.823906, mean_absolute_error: 2.053391, mean_q: 0.193203\n",
      "[-1.0504929  1.0326439]\n",
      "[-0.53532565  1.5323268 ]\n",
      "[-1.0087631  1.7116286]\n",
      "[-0.8397447  1.554795 ]\n",
      "[-0.6337153  1.7793288]\n",
      "[11186, 205153]\n",
      "  216339/1500000: episode: 111, duration: 3.371s, episode steps: 1949, steps per second: 578, episode reward: 594.300, mean reward: 0.305 [-100.100, 122.200], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.689548, mean_absolute_error: 1.847568, mean_q: 0.195820\n",
      "[-1.1399266  1.102745 ]\n",
      "[-1.256711   1.0202867]\n",
      "[-1.4666172   0.50611305]\n",
      "[-0.43510425  0.9138521 ]\n",
      "[-0.60377073  1.5531003 ]\n",
      "[11264, 207024]\n",
      "  218288/1500000: episode: 112, duration: 3.528s, episode steps: 1949, steps per second: 552, episode reward: 638.000, mean reward: 0.327 [-103.000, 223.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.118999, mean_absolute_error: 2.084405, mean_q: 0.231364\n",
      "[-1.3762394  1.4242084]\n",
      "[-1.2826197  1.9400634]\n",
      "[-0.4463909  1.2011228]\n",
      "[-0.59506834  1.586749  ]\n",
      "[-0.49301982  1.0481066 ]\n",
      "[11334, 208903]\n",
      "  220237/1500000: episode: 113, duration: 3.352s, episode steps: 1949, steps per second: 581, episode reward: 669.200, mean reward: 0.343 [-141.000, 145.200], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.566689, mean_absolute_error: 1.755675, mean_q: 0.258426\n",
      "[-0.52132565  1.2171346 ]\n",
      "[-0.39044735  0.66304487]\n",
      "[-0.96909803  0.83479804]\n",
      "[-0.9341803  1.5004264]\n",
      "[-0.9663135  2.0160065]\n",
      "[11424, 210762]\n",
      "  222186/1500000: episode: 114, duration: 3.385s, episode steps: 1949, steps per second: 576, episode reward: 315.900, mean reward: 0.162 [-88.700, 130.600], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.116051, mean_absolute_error: 1.758638, mean_q: 0.255386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.94535273  1.0182405 ]\n",
      "[-1.0324354  1.5516242]\n",
      "[-1.3210936  1.9044704]\n",
      "[-1.5167202  1.823229 ]\n",
      "[-0.9074842  1.5307722]\n",
      "[11507, 212628]\n",
      "  224135/1500000: episode: 115, duration: 3.306s, episode steps: 1949, steps per second: 590, episode reward: 739.900, mean reward: 0.380 [-77.400, 198.200], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.121395, mean_absolute_error: 1.815317, mean_q: 0.233988\n",
      "[-0.94414574  0.78224903]\n",
      "[-0.7335326   0.81663173]\n",
      "[-0.63986343  1.8861549 ]\n",
      "[-1.0407349  2.4385839]\n",
      "[-1.0327857  2.1363482]\n",
      "[11584, 214500]\n",
      "  226084/1500000: episode: 116, duration: 3.416s, episode steps: 1949, steps per second: 571, episode reward: 459.300, mean reward: 0.236 [-112.700, 235.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.849548, mean_absolute_error: 2.195339, mean_q: 0.203098\n",
      "[-1.303392   0.6118244]\n",
      "[-1.0838432  1.3105501]\n",
      "[-0.883025   1.5564678]\n",
      "[-0.47488645  0.7843889 ]\n",
      "[-0.9323244  1.0495998]\n",
      "[11664, 216369]\n",
      "  228033/1500000: episode: 117, duration: 3.425s, episode steps: 1949, steps per second: 569, episode reward: 603.500, mean reward: 0.310 [-135.200, 184.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.734158, mean_absolute_error: 1.698094, mean_q: 0.140631\n",
      "[-1.5005993  0.5468073]\n",
      "[-1.2029878  0.4292788]\n",
      "[-1.0717078   0.48147517]\n",
      "[-0.1792715  0.6283322]\n",
      "[11745, 218237]\n",
      "  229982/1500000: episode: 118, duration: 3.281s, episode steps: 1949, steps per second: 594, episode reward: 317.100, mean reward: 0.163 [-81.200, 110.500], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.585907, mean_absolute_error: 1.907690, mean_q: 0.096873\n",
      "[-0.9711813  1.1822318]\n",
      "[-0.38807142  0.7770253 ]\n",
      "[-1.0268171   0.69419426]\n",
      "[-0.8551569  1.0825754]\n",
      "[-0.57072806  1.3555446 ]\n",
      "[11817, 220114]\n",
      "  231931/1500000: episode: 119, duration: 3.569s, episode steps: 1949, steps per second: 546, episode reward: 636.800, mean reward: 0.327 [-74.600, 127.100], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.078781, mean_absolute_error: 1.764231, mean_q: 0.037018\n",
      "[-1.1862848  0.7456264]\n",
      "[-0.66123974  1.575069  ]\n",
      "[-0.9990955  1.1293949]\n",
      "[-1.0265877  1.2965915]\n",
      "[-0.19581729  1.8565884 ]\n",
      "[11895, 221985]\n",
      "  233880/1500000: episode: 120, duration: 3.578s, episode steps: 1949, steps per second: 545, episode reward: 498.800, mean reward: 0.256 [-121.700, 153.600], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 32.239281, mean_absolute_error: 1.341503, mean_q: 0.029325\n",
      "[-0.7865577  0.9787755]\n",
      "[-1.2283669  1.2328615]\n",
      "[-0.7958268  1.593656 ]\n",
      "[-0.91009784  2.0498664 ]\n",
      "[-0.53162867  1.0981901 ]\n",
      "[11964, 223865]\n",
      "  235829/1500000: episode: 121, duration: 3.715s, episode steps: 1949, steps per second: 525, episode reward: 651.700, mean reward: 0.334 [-129.900, 167.000], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.086079, mean_absolute_error: 1.692743, mean_q: 0.059702\n",
      "[-1.0256379  1.4444437]\n",
      "[-0.25857973  0.49318647]\n",
      "[-0.60919315  0.66909194]\n",
      "[-1.1760682  1.3566166]\n",
      "[-1.3711673  1.5743265]\n",
      "[12051, 225727]\n",
      "  237778/1500000: episode: 122, duration: 3.362s, episode steps: 1949, steps per second: 580, episode reward: 468.300, mean reward: 0.240 [-80.800, 148.400], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 70.291969, mean_absolute_error: 2.234676, mean_q: 0.099863\n",
      "[-0.7701664  1.1185389]\n",
      "[-0.7633667  1.5012693]\n",
      "[-0.52213764  1.1639465 ]\n",
      "[-0.8047139  1.2097653]\n",
      "[-0.338684   1.5366178]\n",
      "[12134, 227593]\n",
      "  239727/1500000: episode: 123, duration: 3.372s, episode steps: 1949, steps per second: 578, episode reward: 479.100, mean reward: 0.246 [-86.700, 149.000], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 71.964233, mean_absolute_error: 2.129437, mean_q: 0.160913\n",
      "[-1.41342    0.8701647]\n",
      "[-0.72671    1.0882729]\n",
      "[-0.899018   1.4059564]\n",
      "[-1.4861823  1.437512 ]\n",
      "[-0.9984533  1.1646068]\n",
      "[12221, 229455]\n",
      "  241676/1500000: episode: 124, duration: 3.285s, episode steps: 1949, steps per second: 593, episode reward: 706.000, mean reward: 0.362 [-116.200, 148.600], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.448357, mean_absolute_error: 2.179050, mean_q: 0.415650\n",
      "[-0.7964364  0.9490568]\n",
      "[-0.887579   1.0696468]\n",
      "[-1.0614512  0.9849129]\n",
      "[-0.80823123  1.0169351 ]\n",
      "[-1.5146323  1.6158856]\n",
      "[12302, 231323]\n",
      "  243625/1500000: episode: 125, duration: 3.345s, episode steps: 1949, steps per second: 583, episode reward: 559.800, mean reward: 0.287 [-80.800, 143.400], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.535690, mean_absolute_error: 2.159708, mean_q: 0.205029\n",
      "[-1.4403408   0.21233813]\n",
      "[-0.7659193  1.1768994]\n",
      "[-0.0953012  1.2384568]\n",
      "[-0.35299847  1.4272562 ]\n",
      "[12385, 233189]\n",
      "  245574/1500000: episode: 126, duration: 3.390s, episode steps: 1949, steps per second: 575, episode reward: 442.600, mean reward: 0.227 [-106.300, 249.500], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.668373, mean_absolute_error: 1.772617, mean_q: 0.228323\n",
      "[-1.0837688  1.019756 ]\n",
      "[-0.3139972  0.776563 ]\n",
      "[-0.8923164   0.54819214]\n",
      "[-0.9666357   0.93499225]\n",
      "[-1.4609109  1.3371333]\n",
      "[12473, 235050]\n",
      "  247523/1500000: episode: 127, duration: 3.208s, episode steps: 1949, steps per second: 608, episode reward: 491.500, mean reward: 0.252 [-108.600, 189.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 35.252384, mean_absolute_error: 1.783853, mean_q: 0.265037\n",
      "[-0.8000855  1.228212 ]\n",
      "[-0.87646425  0.79201853]\n",
      "[-0.25484842  0.704887  ]\n",
      "[-0.9466475  0.9975405]\n",
      "[-1.105125   1.4790583]\n",
      "[12552, 236920]\n",
      "  249472/1500000: episode: 128, duration: 3.336s, episode steps: 1949, steps per second: 584, episode reward: 371.300, mean reward: 0.191 [-107.900, 194.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.673939, mean_absolute_error: 1.880369, mean_q: 0.270288\n",
      "[-0.88828063  1.2927349 ]\n",
      "[-0.9596241  0.8705955]\n",
      "[-0.37317628  2.4499953 ]\n",
      "[-1.2503111  1.2422441]\n",
      "[-0.42513457  1.0693864 ]\n",
      "[12622, 238799]\n",
      "  251421/1500000: episode: 129, duration: 4.437s, episode steps: 1949, steps per second: 439, episode reward: 544.600, mean reward: 0.279 [-70.900, 198.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 28.074131, mean_absolute_error: 1.541583, mean_q: 0.253197\n",
      "[-1.0283635  1.040144 ]\n",
      "[-0.46374387  1.476983  ]\n",
      "[-0.907611   1.1263053]\n",
      "[-1.6939137  1.3315084]\n",
      "[-1.3903873  0.870761 ]\n",
      "[12709, 240661]\n",
      "  253370/1500000: episode: 130, duration: 3.591s, episode steps: 1949, steps per second: 543, episode reward: 749.700, mean reward: 0.385 [-128.700, 206.300], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.293781, mean_absolute_error: 1.944542, mean_q: 0.237167\n",
      "[-0.48241588  0.9680451 ]\n",
      "[-0.18090312  1.2896849 ]\n",
      "[-0.99982536  1.5164876 ]\n",
      "[-0.737696   1.4813588]\n",
      "[-0.6912236  1.191562 ]\n",
      "[12796, 242523]\n",
      "  255319/1500000: episode: 131, duration: 4.354s, episode steps: 1949, steps per second: 448, episode reward: 471.500, mean reward: 0.242 [-89.500, 159.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.947979, mean_absolute_error: 1.537866, mean_q: 0.189608\n",
      "[-1.1620668   0.69020516]\n",
      "[-1.3383158  0.5944686]\n",
      "[-0.8619305  1.3957235]\n",
      "[-1.0989199  1.4268398]\n",
      "[-0.9633135  0.9634076]\n",
      "[12882, 244386]\n",
      "  257268/1500000: episode: 132, duration: 4.258s, episode steps: 1949, steps per second: 458, episode reward: 964.400, mean reward: 0.495 [-102.600, 145.600], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.285748, mean_absolute_error: 1.897199, mean_q: 0.134801\n",
      "[-0.8628311  1.2655487]\n",
      "[-0.99064803  1.1249827 ]\n",
      "[-0.7913854  0.7945923]\n",
      "[-0.91323763  0.8358868 ]\n",
      "[-0.3845206  1.3641843]\n",
      "[12981, 246236]\n",
      "  259217/1500000: episode: 133, duration: 3.696s, episode steps: 1949, steps per second: 527, episode reward: 435.900, mean reward: 0.224 [-133.200, 165.100], mean action: 0.949 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.180641, mean_absolute_error: 1.369102, mean_q: 0.043676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8971267  1.4913963]\n",
      "[-0.7685728   0.66696763]\n",
      "[-0.660381    0.59599006]\n",
      "[-0.8292207   0.77454007]\n",
      "[13062, 248104]\n",
      "  261166/1500000: episode: 134, duration: 3.596s, episode steps: 1949, steps per second: 542, episode reward: 433.000, mean reward: 0.222 [-62.500, 168.100], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.227009, mean_absolute_error: 1.554017, mean_q: 0.012717\n",
      "[-0.78554136  1.2516526 ]\n",
      "[-0.26166636  1.3901033 ]\n",
      "[-0.49671957  1.1451669 ]\n",
      "[-0.57187164  0.8694437 ]\n",
      "[-0.73535955  0.83058107]\n",
      "[13141, 249974]\n",
      "  263115/1500000: episode: 135, duration: 3.409s, episode steps: 1949, steps per second: 572, episode reward: 450.200, mean reward: 0.231 [-99.300, 162.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.699387, mean_absolute_error: 1.651856, mean_q: 0.017351\n",
      "[-0.97098863  1.2728179 ]\n",
      "[-0.5510721  0.4911557]\n",
      "[-0.88841754  1.0339874 ]\n",
      "[-0.88186246  1.3814863 ]\n",
      "[-1.1582415  1.4967868]\n",
      "[13232, 251832]\n",
      "  265064/1500000: episode: 136, duration: 3.337s, episode steps: 1949, steps per second: 584, episode reward: 538.700, mean reward: 0.276 [-117.800, 206.300], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.985325, mean_absolute_error: 1.887377, mean_q: 0.021303\n",
      "[-0.54023993  0.6930603 ]\n",
      "[ 0.5757303  -0.07070987]\n",
      "[-0.85618323  0.9635387 ]\n",
      "[-1.4134638  1.5475427]\n",
      "[-0.7373287  1.0613855]\n",
      "[13385, 253628]\n",
      "  267013/1500000: episode: 137, duration: 3.504s, episode steps: 1949, steps per second: 556, episode reward: 373.400, mean reward: 0.192 [-181.900, 161.900], mean action: 0.921 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.129662, mean_absolute_error: 1.631974, mean_q: 0.027111\n",
      "[-0.96884185  1.4919225 ]\n",
      "[-0.40924898  1.2280768 ]\n",
      "[-1.1296761  1.1416757]\n",
      "[-1.2998047  0.9522191]\n",
      "[-0.79795885  1.3260266 ]\n",
      "[13473, 255489]\n",
      "  268962/1500000: episode: 138, duration: 3.498s, episode steps: 1949, steps per second: 557, episode reward: 222.200, mean reward: 0.114 [-76.000, 159.800], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.208664, mean_absolute_error: 1.567024, mean_q: 0.035195\n",
      "[-0.33279657  0.5391929 ]\n",
      "[-0.78328896  0.9844171 ]\n",
      "[-0.37083843  0.8496059 ]\n",
      "[-1.312323   1.2818865]\n",
      "[-1.0710324  1.3469664]\n",
      "[13551, 257360]\n",
      "  270911/1500000: episode: 139, duration: 3.569s, episode steps: 1949, steps per second: 546, episode reward: 606.700, mean reward: 0.311 [-114.500, 137.100], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.372810, mean_absolute_error: 2.248409, mean_q: 0.040601\n",
      "[-1.5646279  1.6373912]\n",
      "[-1.7974528  0.978504 ]\n",
      "[-1.1334184  0.8435809]\n",
      "[-1.1769676  0.9505995]\n",
      "[-0.34952414  0.826814  ]\n",
      "[13629, 259231]\n",
      "  272860/1500000: episode: 140, duration: 3.391s, episode steps: 1949, steps per second: 575, episode reward: 354.600, mean reward: 0.182 [-91.200, 197.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.245274, mean_absolute_error: 1.702813, mean_q: 0.051363\n",
      "[-0.23215157  1.9255093 ]\n",
      "[-0.42007154  1.7008775 ]\n",
      "[-0.7186064  1.5534776]\n",
      "[-1.8019171  2.1840663]\n",
      "[-1.2325343  1.7273889]\n",
      "[13697, 261112]\n",
      "  274809/1500000: episode: 141, duration: 3.382s, episode steps: 1949, steps per second: 576, episode reward: 444.100, mean reward: 0.228 [-129.700, 174.500], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.180637, mean_absolute_error: 1.997061, mean_q: 0.059152\n",
      "[-1.1502568  1.4637668]\n",
      "[-0.7662504  1.2824069]\n",
      "[-1.1389637  1.6997949]\n",
      "[-0.5042465  1.0988444]\n",
      "[13776, 262982]\n",
      "  276758/1500000: episode: 142, duration: 3.279s, episode steps: 1949, steps per second: 594, episode reward: 696.400, mean reward: 0.357 [-128.400, 153.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.873482, mean_absolute_error: 2.066347, mean_q: 0.070393\n",
      "[-0.9793105  1.1247616]\n",
      "[-0.26688552  1.3704952 ]\n",
      "[-0.6948545  1.5196451]\n",
      "[-0.8827254  1.2352881]\n",
      "[-0.7188074  1.2982908]\n",
      "[13848, 264859]\n",
      "  278707/1500000: episode: 143, duration: 3.371s, episode steps: 1949, steps per second: 578, episode reward: 199.000, mean reward: 0.102 [-102.200, 145.600], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.430931, mean_absolute_error: 1.974993, mean_q: 0.088802\n",
      "[-0.95706326  1.1660599 ]\n",
      "[-1.1161327  1.1841036]\n",
      "[-1.3843485   0.25214392]\n",
      "[-0.9437691   0.31378862]\n",
      "[-1.2843255  0.6353928]\n",
      "[13913, 266743]\n",
      "  280656/1500000: episode: 144, duration: 3.385s, episode steps: 1949, steps per second: 576, episode reward: 564.000, mean reward: 0.289 [-116.200, 137.200], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.936834, mean_absolute_error: 1.441655, mean_q: 0.120592\n",
      "[-0.46910247  1.7353466 ]\n",
      "[-0.4409681  1.7008066]\n",
      "[-0.37415656  1.965512  ]\n",
      "[-1.4760929  0.9063771]\n",
      "[-0.76323974  0.7631179 ]\n",
      "[13994, 268611]\n",
      "  282605/1500000: episode: 145, duration: 3.339s, episode steps: 1949, steps per second: 584, episode reward: 468.600, mean reward: 0.240 [-97.900, 183.000], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.528934, mean_absolute_error: 1.707972, mean_q: 0.150686\n",
      "[-0.52703184  0.9398278 ]\n",
      "[-1.3448235  1.0777351]\n",
      "[-0.8956283  1.1627786]\n",
      "[-0.61024237  0.7642961 ]\n",
      "[0.13016467 0.97727364]\n",
      "[14069, 270485]\n",
      "  284554/1500000: episode: 146, duration: 3.265s, episode steps: 1949, steps per second: 597, episode reward: 548.400, mean reward: 0.281 [-82.400, 142.100], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.982288, mean_absolute_error: 2.093168, mean_q: 0.190072\n",
      "[-0.7763257   0.94920975]\n",
      "[-1.3898864  1.0873785]\n",
      "[-1.0191209  1.5807234]\n",
      "[-1.6723601  1.844652 ]\n",
      "[-0.5267094  1.4007641]\n",
      "[14122, 272381]\n",
      "  286503/1500000: episode: 147, duration: 3.261s, episode steps: 1949, steps per second: 598, episode reward: 847.800, mean reward: 0.435 [-93.200, 205.200], mean action: 0.973 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.317913, mean_absolute_error: 1.897049, mean_q: 0.207521\n",
      "[-0.5120488  1.0867696]\n",
      "[-1.239169   1.7949092]\n",
      "[-1.2681814  1.0796225]\n",
      "[-1.2574502  1.6043736]\n",
      "[-1.1947504  1.6035253]\n",
      "[14183, 274269]\n",
      "  288452/1500000: episode: 148, duration: 3.361s, episode steps: 1949, steps per second: 580, episode reward: 311.800, mean reward: 0.160 [-168.700, 102.100], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.828915, mean_absolute_error: 2.267195, mean_q: 0.208528\n",
      "[-0.3204032  0.5345477]\n",
      "[-1.1222241  1.1878576]\n",
      "[-0.8509986  1.0186114]\n",
      "[-0.5630708   0.99897194]\n",
      "[-0.7141783   0.77268803]\n",
      "[14263, 276138]\n",
      "  290401/1500000: episode: 149, duration: 3.417s, episode steps: 1949, steps per second: 570, episode reward: 407.100, mean reward: 0.209 [-133.600, 176.900], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.271744, mean_absolute_error: 1.943689, mean_q: 0.242118\n",
      "[-0.7112576   0.77589476]\n",
      "[-0.60416615  1.2363305 ]\n",
      "[-0.8524123  1.4440193]\n",
      "[-1.2452662  1.0493267]\n",
      "[14328, 278022]\n",
      "  292350/1500000: episode: 150, duration: 3.351s, episode steps: 1949, steps per second: 582, episode reward: 274.000, mean reward: 0.141 [-128.700, 167.400], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.430485, mean_absolute_error: 1.739671, mean_q: 0.242948\n",
      "[-1.3831007   0.75483733]\n",
      "[-0.8003713  1.289439 ]\n",
      "[-0.8720684  1.7249322]\n",
      "[-1.3074758  1.3910642]\n",
      "[-1.3000919  1.7610952]\n",
      "[14407, 279892]\n",
      "  294299/1500000: episode: 151, duration: 3.440s, episode steps: 1949, steps per second: 567, episode reward: 465.800, mean reward: 0.239 [-74.700, 203.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.518814, mean_absolute_error: 2.090841, mean_q: 0.243102\n",
      "[-0.3893395  1.4065955]\n",
      "[-1.0589857  1.3364296]\n",
      "[-1.1000587  1.3262366]\n",
      "[-0.9298097  1.070937 ]\n",
      "[-0.3735199  0.799065 ]\n",
      "[14485, 281763]\n",
      "  296248/1500000: episode: 152, duration: 3.555s, episode steps: 1949, steps per second: 548, episode reward: 300.700, mean reward: 0.154 [-190.000, 151.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.682152, mean_absolute_error: 2.146188, mean_q: 0.208364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1644326  1.1202377]\n",
      "[-0.5875686  1.2852291]\n",
      "[-1.8132348  0.9297839]\n",
      "[-1.1820253  1.4347551]\n",
      "[-1.1687258  1.5499461]\n",
      "[14568, 283629]\n",
      "  298197/1500000: episode: 153, duration: 3.346s, episode steps: 1949, steps per second: 582, episode reward: 891.000, mean reward: 0.457 [-128.500, 164.300], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.577671, mean_absolute_error: 1.690430, mean_q: 0.164861\n",
      "[-0.7065073  0.9736048]\n",
      "[-1.103674   1.2631195]\n",
      "[-0.310643   0.9957199]\n",
      "[-1.3657918  1.0506741]\n",
      "[-0.69668317  1.5578659 ]\n",
      "[14652, 285494]\n",
      "  300146/1500000: episode: 154, duration: 3.384s, episode steps: 1949, steps per second: 576, episode reward: 592.500, mean reward: 0.304 [-92.000, 132.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.570835, mean_absolute_error: 1.786875, mean_q: 0.138895\n",
      "[-0.76813304  0.79200387]\n",
      "[-0.5821054  0.7612225]\n",
      "[-0.82680845  1.1854854 ]\n",
      "[-0.2286833  0.8121806]\n",
      "[-0.19977845  0.985964  ]\n",
      "[14740, 287355]\n",
      "  302095/1500000: episode: 155, duration: 3.353s, episode steps: 1949, steps per second: 581, episode reward: 625.000, mean reward: 0.321 [-104.900, 246.300], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.036922, mean_absolute_error: 1.581787, mean_q: 0.116484\n",
      "[-0.273299   1.2668867]\n",
      "[-0.77506983  1.261157  ]\n",
      "[-0.00987535  1.7409992 ]\n",
      "[0.02582944 1.4995232 ]\n",
      "[0.01411897 0.96129215]\n",
      "[14815, 289229]\n",
      "  304044/1500000: episode: 156, duration: 3.334s, episode steps: 1949, steps per second: 585, episode reward: 396.100, mean reward: 0.203 [-132.000, 163.300], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.214882, mean_absolute_error: 2.078067, mean_q: 0.101511\n",
      "[-1.505047   1.0302746]\n",
      "[-0.9919672  1.2577357]\n",
      "[-1.0586172  1.871088 ]\n",
      "[-1.0348432  1.2331662]\n",
      "[14894, 291099]\n",
      "  305993/1500000: episode: 157, duration: 3.592s, episode steps: 1949, steps per second: 543, episode reward: 59.400, mean reward: 0.030 [-102.700, 131.100], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.302471, mean_absolute_error: 1.709992, mean_q: 0.090459\n",
      "[-1.1260694  1.0111499]\n",
      "[-1.5365946   0.40762463]\n",
      "[-1.062638   1.0452307]\n",
      "[-0.5974038  1.4925439]\n",
      "[-1.1642399  1.2674706]\n",
      "[14976, 292966]\n",
      "  307942/1500000: episode: 158, duration: 3.628s, episode steps: 1949, steps per second: 537, episode reward: 359.200, mean reward: 0.184 [-96.900, 187.000], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.678818, mean_absolute_error: 2.028306, mean_q: 0.095057\n",
      "[-1.0502396   0.81172156]\n",
      "[-1.245575   1.3826455]\n",
      "[-0.3104971  1.3013111]\n",
      "[-1.1828631  0.8243516]\n",
      "[-0.7687514   0.62336826]\n",
      "[15038, 294853]\n",
      "  309891/1500000: episode: 159, duration: 3.329s, episode steps: 1949, steps per second: 585, episode reward: 496.500, mean reward: 0.255 [-159.500, 125.600], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.853909, mean_absolute_error: 1.779519, mean_q: 0.106118\n",
      "[-1.1199696  1.0152082]\n",
      "[-0.07121137  1.0559603 ]\n",
      "[-0.3708227  1.0833439]\n",
      "[-0.6473118  1.1272553]\n",
      "[-0.78620887  0.8610143 ]\n",
      "[15115, 296725]\n",
      "  311840/1500000: episode: 160, duration: 3.338s, episode steps: 1949, steps per second: 584, episode reward: 456.700, mean reward: 0.234 [-109.200, 144.900], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.923767, mean_absolute_error: 1.775400, mean_q: 0.115681\n",
      "[-1.1532089   0.83444977]\n",
      "[-0.9868767  1.0580757]\n",
      "[-1.3469046  1.3695986]\n",
      "[-1.0947942  1.4282547]\n",
      "[-1.313874    0.47536135]\n",
      "[15166, 298623]\n",
      "  313789/1500000: episode: 161, duration: 3.317s, episode steps: 1949, steps per second: 588, episode reward: 644.300, mean reward: 0.331 [-69.600, 174.900], mean action: 0.974 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.785820, mean_absolute_error: 2.004340, mean_q: 0.121745\n",
      "[-0.7780874  1.1831337]\n",
      "[-0.83497053  1.0680431 ]\n",
      "[-1.0495727  1.1170461]\n",
      "[-1.2506341  1.0061166]\n",
      "[-1.0816487  1.2947655]\n",
      "[15237, 300501]\n",
      "  315738/1500000: episode: 162, duration: 3.307s, episode steps: 1949, steps per second: 589, episode reward: 394.100, mean reward: 0.202 [-108.200, 187.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.792908, mean_absolute_error: 1.753410, mean_q: 0.141660\n",
      "[-0.69197   1.122331]\n",
      "[-1.3040634  1.0891443]\n",
      "[-1.1448281  1.5710651]\n",
      "[-0.94535565  1.3659719 ]\n",
      "[-1.0811043  1.080956 ]\n",
      "[15321, 302366]\n",
      "  317687/1500000: episode: 163, duration: 3.421s, episode steps: 1949, steps per second: 570, episode reward: 649.700, mean reward: 0.333 [-121.800, 116.500], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.203854, mean_absolute_error: 1.848631, mean_q: 0.132011\n",
      "[-1.0672857  1.5174114]\n",
      "[-1.1024588  1.2676609]\n",
      "[-0.07348922  1.2967223 ]\n",
      "[-0.7699874  0.9363534]\n",
      "[-0.46778473  1.3542523 ]\n",
      "[15393, 304243]\n",
      "  319636/1500000: episode: 164, duration: 3.229s, episode steps: 1949, steps per second: 604, episode reward: 202.800, mean reward: 0.104 [-158.000, 210.200], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.919037, mean_absolute_error: 1.914621, mean_q: 0.132879\n",
      "[-0.56120855  1.2296335 ]\n",
      "[-0.93725955  0.92778265]\n",
      "[-1.0376481   0.91256976]\n",
      "[-0.9731449  1.0153401]\n",
      "[15473, 306112]\n",
      "  321585/1500000: episode: 165, duration: 3.293s, episode steps: 1949, steps per second: 592, episode reward: 497.200, mean reward: 0.255 [-150.300, 206.300], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.165012, mean_absolute_error: 2.159822, mean_q: 0.121351\n",
      "[-0.7386826  1.0085171]\n",
      "[-0.9179688  1.3138013]\n",
      "[-0.87891006  1.3064603 ]\n",
      "[-0.6611738  1.6298143]\n",
      "[-0.3463417  1.5185533]\n",
      "[15555, 307979]\n",
      "  323534/1500000: episode: 166, duration: 3.331s, episode steps: 1949, steps per second: 585, episode reward: 739.800, mean reward: 0.380 [-79.800, 181.000], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.270657, mean_absolute_error: 2.112406, mean_q: 0.113359\n",
      "[-0.89013517  0.9019059 ]\n",
      "[-1.2153655  1.370916 ]\n",
      "[-0.4550756  1.6251473]\n",
      "[-1.5333095  1.5554975]\n",
      "[-0.7691166  1.1181905]\n",
      "[15635, 309848]\n",
      "  325483/1500000: episode: 167, duration: 3.348s, episode steps: 1949, steps per second: 582, episode reward: 408.500, mean reward: 0.210 [-105.600, 166.100], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 31.017511, mean_absolute_error: 1.424056, mean_q: 0.092836\n",
      "[-1.1772807  1.1561657]\n",
      "[-1.4118655   0.80931646]\n",
      "[-1.2380563  1.0803655]\n",
      "[-0.904881    0.44244152]\n",
      "[-0.6750253   0.57095695]\n",
      "[15735, 311697]\n",
      "  327432/1500000: episode: 168, duration: 3.463s, episode steps: 1949, steps per second: 563, episode reward: 824.000, mean reward: 0.423 [-101.800, 137.200], mean action: 0.949 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.600330, mean_absolute_error: 1.821230, mean_q: 0.084547\n",
      "[-0.63163036  0.6594088 ]\n",
      "[-0.5803706  1.1903415]\n",
      "[-0.7810365  1.3725692]\n",
      "[-0.5766436  1.2831596]\n",
      "[-1.0325247  0.9873946]\n",
      "[15816, 313565]\n",
      "  329381/1500000: episode: 169, duration: 3.340s, episode steps: 1949, steps per second: 584, episode reward: 528.500, mean reward: 0.271 [-113.100, 166.100], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.321014, mean_absolute_error: 1.661026, mean_q: 0.068245\n",
      "[-0.5460097  0.7531923]\n",
      "[-0.32101607  0.7966823 ]\n",
      "[-0.4685674  1.157159 ]\n",
      "[-0.65958285  1.2435968 ]\n",
      "[-0.55919313  1.4052907 ]\n",
      "[15900, 315430]\n",
      "  331330/1500000: episode: 170, duration: 3.356s, episode steps: 1949, steps per second: 581, episode reward: 675.500, mean reward: 0.347 [-78.000, 196.000], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 31.964329, mean_absolute_error: 1.394027, mean_q: 0.063857\n",
      "[-0.35617328  1.3029649 ]\n",
      "[-0.24802522  1.0185045 ]\n",
      "[-0.43989244  1.4235096 ]\n",
      "[-0.835476   1.2745985]\n",
      "[-0.518639  1.633877]\n",
      "[15972, 317307]\n",
      "  333279/1500000: episode: 171, duration: 3.282s, episode steps: 1949, steps per second: 594, episode reward: 557.400, mean reward: 0.286 [-200.100, 160.700], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.320553, mean_absolute_error: 2.096604, mean_q: 0.056376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.4179771   0.87555164]\n",
      "[-0.87305045  1.7068924 ]\n",
      "[-0.65771043  1.4496887 ]\n",
      "[-0.9189328  1.0348443]\n",
      "[-0.7698624  1.0422673]\n",
      "[16048, 319180]\n",
      "  335228/1500000: episode: 172, duration: 3.376s, episode steps: 1949, steps per second: 577, episode reward: 203.000, mean reward: 0.104 [-111.800, 196.700], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.073395, mean_absolute_error: 1.869392, mean_q: 0.056956\n",
      "[-0.46130517  1.4775214 ]\n",
      "[-0.6763481   0.73605204]\n",
      "[-1.0229843  0.7510979]\n",
      "[-0.24979773  1.1590246 ]\n",
      "[16118, 321059]\n",
      "  337177/1500000: episode: 173, duration: 3.383s, episode steps: 1949, steps per second: 576, episode reward: 423.600, mean reward: 0.217 [-80.300, 213.800], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 30.891521, mean_absolute_error: 1.433773, mean_q: 0.058836\n",
      "[-0.9838454   0.92933947]\n",
      "[-1.5620921  1.0383067]\n",
      "[-1.6233971  1.6135958]\n",
      "[-1.0026937  1.7556217]\n",
      "[-1.4048085  1.6871336]\n",
      "[16197, 322929]\n",
      "  339126/1500000: episode: 174, duration: 3.399s, episode steps: 1949, steps per second: 573, episode reward: 511.200, mean reward: 0.262 [-168.700, 145.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.449211, mean_absolute_error: 2.050067, mean_q: 0.054145\n",
      "[-0.78946006  1.1828243 ]\n",
      "[-0.39115375  1.0886593 ]\n",
      "[-0.9280154  1.2539659]\n",
      "[-0.7163818  0.8614691]\n",
      "[-0.4425275  1.3032544]\n",
      "[16293, 324782]\n",
      "  341075/1500000: episode: 175, duration: 3.225s, episode steps: 1949, steps per second: 604, episode reward: 569.700, mean reward: 0.292 [-84.800, 163.000], mean action: 0.951 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.885685, mean_absolute_error: 1.669957, mean_q: 0.059365\n",
      "[-0.8126737  1.3126764]\n",
      "[-0.9408572  1.2010301]\n",
      "[-0.46448982  0.37699917]\n",
      "[-0.25814497  0.5246008 ]\n",
      "[-0.9900803  1.0884039]\n",
      "[16373, 326651]\n",
      "  343024/1500000: episode: 176, duration: 3.378s, episode steps: 1949, steps per second: 577, episode reward: 478.900, mean reward: 0.246 [-83.100, 170.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.764942, mean_absolute_error: 1.573452, mean_q: 0.062959\n",
      "[-0.83588105  0.7747855 ]\n",
      "[-0.8648975  0.8855   ]\n",
      "[-0.21667145  0.9826756 ]\n",
      "[-0.33663496  0.9184754 ]\n",
      "[-0.6507376  1.3833821]\n",
      "[16435, 328538]\n",
      "  344973/1500000: episode: 177, duration: 3.690s, episode steps: 1949, steps per second: 528, episode reward: 348.400, mean reward: 0.179 [-101.300, 227.800], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.100819, mean_absolute_error: 1.601678, mean_q: 0.065572\n",
      "[-1.3243914  1.0414108]\n",
      "[-1.0978739  1.0352407]\n",
      "[-0.8704674  0.936864 ]\n",
      "[-0.6191786  1.0846658]\n",
      "[-1.7160505  1.3190699]\n",
      "[16497, 330425]\n",
      "  346922/1500000: episode: 178, duration: 3.368s, episode steps: 1949, steps per second: 579, episode reward: 383.100, mean reward: 0.197 [-102.400, 186.300], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.229389, mean_absolute_error: 1.730365, mean_q: 0.065368\n",
      "[-0.85376805  1.1790117 ]\n",
      "[-0.25935608  0.70535165]\n",
      "[-1.2274362  1.3817483]\n",
      "[-1.1920015   0.50687706]\n",
      "[-0.90645313  0.58184004]\n",
      "[16579, 332292]\n",
      "  348871/1500000: episode: 179, duration: 3.384s, episode steps: 1949, steps per second: 576, episode reward: 274.800, mean reward: 0.141 [-184.100, 197.100], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.726284, mean_absolute_error: 2.218467, mean_q: 0.062306\n",
      "[-0.7243865  0.8045649]\n",
      "[-0.82386315  1.8249652 ]\n",
      "[-1.2427342  1.7727292]\n",
      "[-0.5885855  1.4225069]\n",
      "[-0.25715512  1.2689232 ]\n",
      "[16666, 334154]\n",
      "  350820/1500000: episode: 180, duration: 3.436s, episode steps: 1949, steps per second: 567, episode reward: 714.300, mean reward: 0.366 [-184.200, 140.800], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.497953, mean_absolute_error: 1.395007, mean_q: 0.048523\n",
      "[-0.29488954  0.73522   ]\n",
      "[-1.1240025  1.3755318]\n",
      "[-0.58343345  0.9714162 ]\n",
      "[-0.907541   0.7605001]\n",
      "[16735, 336034]\n",
      "  352769/1500000: episode: 181, duration: 3.395s, episode steps: 1949, steps per second: 574, episode reward: 218.700, mean reward: 0.112 [-168.700, 141.100], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.692490, mean_absolute_error: 2.029065, mean_q: 0.043684\n",
      "[-0.95337903  0.98434603]\n",
      "[-0.51492584  1.3569157 ]\n",
      "[-0.4077354  1.0960089]\n",
      "[-0.4701727   0.70085084]\n",
      "[-0.47723737  1.2068753 ]\n",
      "[16806, 337912]\n",
      "  354718/1500000: episode: 182, duration: 3.457s, episode steps: 1949, steps per second: 564, episode reward: 743.700, mean reward: 0.382 [-102.300, 222.400], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.725407, mean_absolute_error: 1.888005, mean_q: 0.056025\n",
      "[-0.786389   1.1077118]\n",
      "[-1.4927963  1.4992467]\n",
      "[-1.6141578  1.8828238]\n",
      "[-0.8111032  0.6884576]\n",
      "[-0.9555775  1.2005007]\n",
      "[16879, 339788]\n",
      "  356667/1500000: episode: 183, duration: 3.469s, episode steps: 1949, steps per second: 562, episode reward: 632.200, mean reward: 0.324 [-113.400, 186.300], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.229546, mean_absolute_error: 1.982522, mean_q: 0.075302\n",
      "[-1.3974992  0.7609634]\n",
      "[-1.191299   1.1515138]\n",
      "[-0.43440637  1.818864  ]\n",
      "[-0.6340461  1.2613251]\n",
      "[-0.02818096  1.22467   ]\n",
      "[16962, 341654]\n",
      "  358616/1500000: episode: 184, duration: 3.420s, episode steps: 1949, steps per second: 570, episode reward: 445.300, mean reward: 0.228 [-131.900, 141.000], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.186241, mean_absolute_error: 1.866167, mean_q: 0.103713\n",
      "[-0.9899458  1.4685683]\n",
      "[-0.6930045  1.1936657]\n",
      "[-0.8669363  1.4902575]\n",
      "[-0.10831457  0.5358409 ]\n",
      "[-0.9837149  1.3353065]\n",
      "[17043, 343522]\n",
      "  360565/1500000: episode: 185, duration: 3.528s, episode steps: 1949, steps per second: 552, episode reward: 436.500, mean reward: 0.224 [-183.300, 198.300], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 74.195908, mean_absolute_error: 1.932973, mean_q: 0.128241\n",
      "[-0.75547063  0.9078206 ]\n",
      "[-1.2434081  1.3676987]\n",
      "[-1.3734832  1.659593 ]\n",
      "[-0.37683836  1.0332342 ]\n",
      "[-0.9877256   0.75449634]\n",
      "[17113, 345401]\n",
      "  362514/1500000: episode: 186, duration: 3.543s, episode steps: 1949, steps per second: 550, episode reward: 610.600, mean reward: 0.313 [-120.700, 133.900], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.306061, mean_absolute_error: 1.802922, mean_q: 0.142169\n",
      "[-1.8103863  0.3689934]\n",
      "[-0.4148092  1.0876933]\n",
      "[-1.0338932  1.3104801]\n",
      "[-1.2429006  1.7872641]\n",
      "[-1.0008248  1.5806757]\n",
      "[17178, 347285]\n",
      "  364463/1500000: episode: 187, duration: 3.422s, episode steps: 1949, steps per second: 570, episode reward: 267.300, mean reward: 0.137 [-123.100, 209.100], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.764725, mean_absolute_error: 1.654294, mean_q: 0.118339\n",
      "[-0.7207912  1.7192992]\n",
      "[-0.7151443  1.3659016]\n",
      "[-1.3314257  1.399832 ]\n",
      "[-1.2182049  1.2842363]\n",
      "[-1.0259526  1.5636986]\n",
      "[17264, 349148]\n",
      "  366412/1500000: episode: 188, duration: 3.311s, episode steps: 1949, steps per second: 589, episode reward: 462.500, mean reward: 0.237 [-74.900, 146.700], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.639641, mean_absolute_error: 2.002173, mean_q: 0.081417\n",
      "[-0.7190187  1.058915 ]\n",
      "[-1.0363346  1.4397808]\n",
      "[-0.78437626  1.7399081 ]\n",
      "[-0.9666012  1.6066197]\n",
      "[17354, 351007]\n",
      "  368361/1500000: episode: 189, duration: 3.270s, episode steps: 1949, steps per second: 596, episode reward: 692.500, mean reward: 0.355 [-93.800, 209.400], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 32.737762, mean_absolute_error: 1.535374, mean_q: 0.078104\n",
      "[-1.1223712  0.8459623]\n",
      "[-1.1898842   0.69144607]\n",
      "[-0.7758148   0.94210786]\n",
      "[-0.6285189   0.55842876]\n",
      "[-0.74355483  1.2734606 ]\n",
      "[17425, 352885]\n",
      "  370310/1500000: episode: 190, duration: 3.429s, episode steps: 1949, steps per second: 568, episode reward: 422.700, mean reward: 0.217 [-166.700, 154.800], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.063221, mean_absolute_error: 1.938200, mean_q: 0.092391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8363151  1.3691943]\n",
      "[-1.0535719  1.1056292]\n",
      "[-0.73326683  1.0377474 ]\n",
      "[-0.63445985  0.94116867]\n",
      "[-0.70339584  0.01956141]\n",
      "[17500, 354759]\n",
      "  372259/1500000: episode: 191, duration: 3.576s, episode steps: 1949, steps per second: 545, episode reward: 452.500, mean reward: 0.232 [-107.600, 183.200], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.598717, mean_absolute_error: 2.330308, mean_q: 0.084815\n",
      "[-0.27809986  1.1509933 ]\n",
      "[-0.44170645  1.1481848 ]\n",
      "[-1.3087499  1.2188036]\n",
      "[-1.5805426  1.8185971]\n",
      "[-0.56772715  1.9970217 ]\n",
      "[17592, 356616]\n",
      "  374208/1500000: episode: 192, duration: 3.249s, episode steps: 1949, steps per second: 600, episode reward: 214.500, mean reward: 0.110 [-97.500, 172.200], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.118925, mean_absolute_error: 1.599521, mean_q: 0.123530\n",
      "[-1.2122993  0.7729392]\n",
      "[-1.0027013  1.2362686]\n",
      "[-0.89700675  1.5221982 ]\n",
      "[-0.5732255   0.95435524]\n",
      "[0.04371553 0.81535   ]\n",
      "[17658, 358499]\n",
      "  376157/1500000: episode: 193, duration: 3.059s, episode steps: 1949, steps per second: 637, episode reward: 198.500, mean reward: 0.102 [-142.500, 157.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.582417, mean_absolute_error: 1.710132, mean_q: 0.131130\n",
      "[-0.66697407  1.0643394 ]\n",
      "[-0.9059589  0.9849667]\n",
      "[-1.3423564  1.4493626]\n",
      "[-0.927246   1.8693664]\n",
      "[-0.46327388  1.2230204 ]\n",
      "[17711, 360395]\n",
      "  378106/1500000: episode: 194, duration: 3.322s, episode steps: 1949, steps per second: 587, episode reward: 593.400, mean reward: 0.304 [-136.800, 168.200], mean action: 0.973 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.060165, mean_absolute_error: 2.212696, mean_q: 0.137816\n",
      "[-0.87881726  1.6432735 ]\n",
      "[-0.61927295  1.065495  ]\n",
      "[-0.62408525  0.517775  ]\n",
      "[-0.6712186  1.1956855]\n",
      "[-0.7520027  1.098161 ]\n",
      "[17791, 362264]\n",
      "  380055/1500000: episode: 195, duration: 3.196s, episode steps: 1949, steps per second: 610, episode reward: 405.200, mean reward: 0.208 [-82.800, 114.600], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.919746, mean_absolute_error: 1.878216, mean_q: 0.144978\n",
      "[-0.65941435  0.5047428 ]\n",
      "[-0.81591815  0.6086142 ]\n",
      "[-0.5727825  1.1323926]\n",
      "[-0.6645989  0.3677025]\n",
      "[-0.70545805  0.6442948 ]\n",
      "[17859, 364145]\n",
      "  382004/1500000: episode: 196, duration: 3.536s, episode steps: 1949, steps per second: 551, episode reward: 594.400, mean reward: 0.305 [-87.100, 180.000], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.792789, mean_absolute_error: 1.720096, mean_q: 0.131562\n",
      "[-1.2098211  0.4631961]\n",
      "[-1.4379498   0.83464926]\n",
      "[-0.9131884  1.278968 ]\n",
      "[-0.83264196  0.6597393 ]\n",
      "[17946, 366007]\n",
      "  383953/1500000: episode: 197, duration: 3.751s, episode steps: 1949, steps per second: 520, episode reward: 532.700, mean reward: 0.273 [-101.900, 134.800], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.619644, mean_absolute_error: 1.928496, mean_q: 0.120747\n",
      "[-0.8303459  0.6597034]\n",
      "[-1.2579542  1.3656169]\n",
      "[-1.1000334  1.7069567]\n",
      "[-0.8074688  1.1393765]\n",
      "[-1.07523    0.6359634]\n",
      "[18030, 367872]\n",
      "  385902/1500000: episode: 198, duration: 3.367s, episode steps: 1949, steps per second: 579, episode reward: 759.900, mean reward: 0.390 [-86.600, 163.100], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.787460, mean_absolute_error: 1.750232, mean_q: 0.099866\n",
      "[-1.2189848  1.0099264]\n",
      "[-0.48371676  1.3511491 ]\n",
      "[-0.6351529  2.2741158]\n",
      "[-0.84213865  2.076602  ]\n",
      "[-0.24736065  1.0239875 ]\n",
      "[18115, 369736]\n",
      "  387851/1500000: episode: 199, duration: 3.834s, episode steps: 1949, steps per second: 508, episode reward: 556.500, mean reward: 0.286 [-116.000, 174.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.184761, mean_absolute_error: 1.762847, mean_q: 0.087535\n",
      "[-1.0438651  1.424294 ]\n",
      "[-1.149057    0.88255703]\n",
      "[-1.4227446  1.4529701]\n",
      "[-0.9634027  1.6223295]\n",
      "[-0.8234443   0.60632384]\n",
      "[18187, 371613]\n",
      "  389800/1500000: episode: 200, duration: 3.619s, episode steps: 1949, steps per second: 538, episode reward: 587.000, mean reward: 0.301 [-121.700, 151.200], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.862968, mean_absolute_error: 1.743560, mean_q: 0.072210\n",
      "[-0.9381071  0.9500956]\n",
      "[-0.20688237  1.9170376 ]\n",
      "[-0.7196046  1.0383941]\n",
      "[-0.98508704  0.66827166]\n",
      "[-0.9949031  1.084722 ]\n",
      "[18263, 373486]\n",
      "  391749/1500000: episode: 201, duration: 3.401s, episode steps: 1949, steps per second: 573, episode reward: 719.800, mean reward: 0.369 [-109.100, 143.600], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.337318, mean_absolute_error: 2.140692, mean_q: 0.049095\n",
      "[-0.08645827  1.5729954 ]\n",
      "[0.05795517 1.5444287 ]\n",
      "[-0.71510476  1.4627603 ]\n",
      "[-0.72111636  1.4584006 ]\n",
      "[-0.8145037  1.6175017]\n",
      "[18337, 375361]\n",
      "  393698/1500000: episode: 202, duration: 3.364s, episode steps: 1949, steps per second: 579, episode reward: 419.100, mean reward: 0.215 [-120.400, 156.000], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.848564, mean_absolute_error: 1.763631, mean_q: 0.036573\n",
      "[-1.1453007  0.8927123]\n",
      "[-1.2020893  1.5826617]\n",
      "[-1.1494339  1.0455726]\n",
      "[-1.7884712  1.0793297]\n",
      "[-1.2019955  1.1645219]\n",
      "[18407, 377240]\n",
      "  395647/1500000: episode: 203, duration: 3.384s, episode steps: 1949, steps per second: 576, episode reward: 383.000, mean reward: 0.197 [-96.000, 107.400], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.476410, mean_absolute_error: 2.153067, mean_q: 0.033881\n",
      "[-0.49814367  1.2676109 ]\n",
      "[-0.52693385  1.5000907 ]\n",
      "[-0.6588179  1.0055355]\n",
      "[-0.13242353  0.9491399 ]\n",
      "[18489, 379107]\n",
      "  397596/1500000: episode: 204, duration: 3.399s, episode steps: 1949, steps per second: 573, episode reward: 573.100, mean reward: 0.294 [-91.000, 161.800], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.105804, mean_absolute_error: 1.899461, mean_q: 0.040094\n",
      "[-0.9547107  1.0675424]\n",
      "[-0.8227151  0.8015026]\n",
      "[-0.8591317   0.96314985]\n",
      "[-1.2782114  1.7003393]\n",
      "[-1.1489439  1.1493142]\n",
      "[18560, 380985]\n",
      "  399545/1500000: episode: 205, duration: 3.485s, episode steps: 1949, steps per second: 559, episode reward: 840.400, mean reward: 0.431 [-79.500, 166.100], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.787968, mean_absolute_error: 1.832856, mean_q: 0.046504\n",
      "[-0.7064443  0.8970606]\n",
      "[-0.6818133  1.4668272]\n",
      "[-1.3679413  1.186358 ]\n",
      "[-1.4022567  1.1280034]\n",
      "[-0.59318393  1.2790586 ]\n",
      "[18649, 382845]\n",
      "  401494/1500000: episode: 206, duration: 3.354s, episode steps: 1949, steps per second: 581, episode reward: 197.000, mean reward: 0.101 [-92.400, 173.500], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 29.776676, mean_absolute_error: 1.540019, mean_q: 0.049499\n",
      "[-0.7805711   0.68491566]\n",
      "[-0.8297245  0.7632896]\n",
      "[-0.6956727  0.7950425]\n",
      "[-0.67162263  1.0984236 ]\n",
      "[-0.3283684   0.66070276]\n",
      "[18736, 384707]\n",
      "  403443/1500000: episode: 207, duration: 3.326s, episode steps: 1949, steps per second: 586, episode reward: 319.700, mean reward: 0.164 [-124.700, 144.600], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.000710, mean_absolute_error: 1.890393, mean_q: 0.047892\n",
      "[-0.56599617  0.9206304 ]\n",
      "[-1.3328071  0.9950624]\n",
      "[-1.5234628  1.0854261]\n",
      "[-0.99322665  0.9099323 ]\n",
      "[-0.67714006  0.9969096 ]\n",
      "[18825, 386567]\n",
      "  405392/1500000: episode: 208, duration: 3.269s, episode steps: 1949, steps per second: 596, episode reward: 208.300, mean reward: 0.107 [-79.500, 148.800], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.576462, mean_absolute_error: 1.766206, mean_q: 0.047811\n",
      "[-0.61880463  1.3863161 ]\n",
      "[-0.60381836  0.9632354 ]\n",
      "[-1.0225482  1.2732925]\n",
      "[-0.75189054  0.34215736]\n",
      "[-0.6211415  0.7592885]\n",
      "[18918, 388423]\n",
      "  407341/1500000: episode: 209, duration: 3.507s, episode steps: 1949, steps per second: 556, episode reward: 556.800, mean reward: 0.286 [-122.400, 175.600], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.467434, mean_absolute_error: 1.732652, mean_q: 0.048461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3644232  1.5816644]\n",
      "[-1.0075263  1.1329798]\n",
      "[-0.8408463  1.9531236]\n",
      "[-1.3414879  1.7588613]\n",
      "[-1.4678584  1.7286657]\n",
      "[18999, 390291]\n",
      "  409290/1500000: episode: 210, duration: 3.378s, episode steps: 1949, steps per second: 577, episode reward: 590.400, mean reward: 0.303 [-83.100, 217.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.750713, mean_absolute_error: 1.847319, mean_q: 0.047998\n",
      "[-0.3638101  1.2205224]\n",
      "[-1.6384693  1.209928 ]\n",
      "[-1.157191   1.0634674]\n",
      "[-1.1855417   0.99032784]\n",
      "[-0.8095053  1.6628039]\n",
      "[19075, 392164]\n",
      "  411239/1500000: episode: 211, duration: 3.341s, episode steps: 1949, steps per second: 583, episode reward: 527.800, mean reward: 0.271 [-109.900, 178.900], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.596352, mean_absolute_error: 1.642711, mean_q: 0.048753\n",
      "[-1.0670334  1.0106864]\n",
      "[-1.9139738  1.3623861]\n",
      "[-1.434757   1.1147524]\n",
      "[-0.62167364  0.86896455]\n",
      "[19159, 394029]\n",
      "  413188/1500000: episode: 212, duration: 3.469s, episode steps: 1949, steps per second: 562, episode reward: 403.100, mean reward: 0.207 [-86.700, 139.600], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.001221, mean_absolute_error: 1.988266, mean_q: 0.043261\n",
      "[-0.9970575   0.92344224]\n",
      "[-0.8112788  1.6729685]\n",
      "[-1.0550631  1.8954351]\n",
      "[-0.310286    0.51263154]\n",
      "[0.39030144 1.166936  ]\n",
      "[19243, 395894]\n",
      "  415137/1500000: episode: 213, duration: 3.413s, episode steps: 1949, steps per second: 571, episode reward: 228.300, mean reward: 0.117 [-165.500, 210.500], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.457390, mean_absolute_error: 1.747560, mean_q: 0.036132\n",
      "[-0.52013814  0.8006159 ]\n",
      "[-1.1310523  0.3577273]\n",
      "[-0.602226   1.2602537]\n",
      "[-0.6507451  0.8302246]\n",
      "[-1.2684641  1.0624636]\n",
      "[19323, 397763]\n",
      "  417086/1500000: episode: 214, duration: 3.395s, episode steps: 1949, steps per second: 574, episode reward: 462.000, mean reward: 0.237 [-98.700, 175.600], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.302490, mean_absolute_error: 1.576681, mean_q: 0.031242\n",
      "[-0.52876616  1.4640582 ]\n",
      "[-0.93176436  1.0511498 ]\n",
      "[-0.85295177  1.0681016 ]\n",
      "[-0.40490893  1.0214177 ]\n",
      "[-0.44907525  1.1095093 ]\n",
      "[19400, 399635]\n",
      "  419035/1500000: episode: 215, duration: 3.616s, episode steps: 1949, steps per second: 539, episode reward: 641.600, mean reward: 0.329 [-106.900, 150.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.288799, mean_absolute_error: 1.665679, mean_q: 0.029836\n",
      "[-0.88597786  0.8003896 ]\n",
      "[-1.023418   0.4584059]\n",
      "[-1.56561    1.8502954]\n",
      "[-1.0261242  0.8453022]\n",
      "[-1.051182   1.6017162]\n",
      "[19490, 401494]\n",
      "  420984/1500000: episode: 216, duration: 3.403s, episode steps: 1949, steps per second: 573, episode reward: 451.300, mean reward: 0.232 [-134.400, 205.700], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.024555, mean_absolute_error: 1.740065, mean_q: 0.029289\n",
      "[-0.9525273  1.0793848]\n",
      "[-0.901868    0.54517686]\n",
      "[-0.8068056  1.1800267]\n",
      "[-0.58747816  0.8692957 ]\n",
      "[-1.1887068  1.602027 ]\n",
      "[19566, 403367]\n",
      "  422933/1500000: episode: 217, duration: 3.320s, episode steps: 1949, steps per second: 587, episode reward: 396.300, mean reward: 0.203 [-132.500, 125.700], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.759342, mean_absolute_error: 1.935249, mean_q: 0.032107\n",
      "[-0.90924376  1.2923332 ]\n",
      "[-0.11059892  1.4747428 ]\n",
      "[-0.4973501  -0.54581916]\n",
      "[ 0.0717255  -0.00138408]\n",
      "[-0.47622937  0.67550546]\n",
      "[19907, 404975]\n",
      "  424882/1500000: episode: 218, duration: 3.339s, episode steps: 1949, steps per second: 584, episode reward: 564.200, mean reward: 0.289 [-119.400, 205.800], mean action: 0.825 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.224087, mean_absolute_error: 1.705046, mean_q: 0.037552\n",
      "[-0.6114759   0.99235547]\n",
      "[-0.7042938  0.8129353]\n",
      "[-0.370482   1.0363017]\n",
      "[-1.3613383  0.9127675]\n",
      "[-0.8146381  1.322937 ]\n",
      "[19985, 406846]\n",
      "  426831/1500000: episode: 219, duration: 3.338s, episode steps: 1949, steps per second: 584, episode reward: 586.800, mean reward: 0.301 [-105.300, 192.900], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 68.791397, mean_absolute_error: 1.961223, mean_q: 0.046015\n",
      "[-0.3211138  1.4306643]\n",
      "[-0.42686674  1.4844323 ]\n",
      "[-0.7759865  1.040231 ]\n",
      "[-0.52813417  1.4014573 ]\n",
      "[20055, 408725]\n",
      "  428780/1500000: episode: 220, duration: 3.268s, episode steps: 1949, steps per second: 596, episode reward: 142.900, mean reward: 0.073 [-109.400, 166.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 25.990389, mean_absolute_error: 1.497795, mean_q: 0.046393\n",
      "[-1.0353129  1.1592591]\n",
      "[-1.183236    0.88196707]\n",
      "[-0.46250495  1.041675  ]\n",
      "[-1.1924819  0.6049764]\n",
      "[-1.3361112  1.3138051]\n",
      "[20131, 410598]\n",
      "  430729/1500000: episode: 221, duration: 3.336s, episode steps: 1949, steps per second: 584, episode reward: 696.200, mean reward: 0.357 [-90.200, 146.900], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.265705, mean_absolute_error: 1.898013, mean_q: 0.027464\n",
      "[-0.9373777   0.78136194]\n",
      "[-0.45721477  1.0658684 ]\n",
      "[-1.0612766   0.89722687]\n",
      "[-1.1134732   0.61603826]\n",
      "[-1.0092218   0.88829136]\n",
      "[20205, 412473]\n",
      "  432678/1500000: episode: 222, duration: 3.710s, episode steps: 1949, steps per second: 525, episode reward: -18.100, mean reward: -0.009 [-173.600, 161.900], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.862549, mean_absolute_error: 1.739042, mean_q: 0.016883\n",
      "[-0.6049314  0.8765773]\n",
      "[-0.57830733  0.61803836]\n",
      "[-0.02321317  0.780454  ]\n",
      "[-0.58190227  1.3641652 ]\n",
      "[-0.7561261  1.375438 ]\n",
      "[20265, 414362]\n",
      "  434627/1500000: episode: 223, duration: 3.354s, episode steps: 1949, steps per second: 581, episode reward: 494.900, mean reward: 0.254 [-123.100, 175.400], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 30.160257, mean_absolute_error: 1.623493, mean_q: 0.012520\n",
      "[-1.0412629   0.77851605]\n",
      "[-0.77721524  0.4083463 ]\n",
      "[-0.93375456  1.2792981 ]\n",
      "[-0.53422415  1.7423207 ]\n",
      "[-0.64995563  1.192292  ]\n",
      "[20357, 416219]\n",
      "  436576/1500000: episode: 224, duration: 3.450s, episode steps: 1949, steps per second: 565, episode reward: 325.800, mean reward: 0.167 [-168.700, 127.700], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.192978, mean_absolute_error: 1.795476, mean_q: -0.001942\n",
      "[-0.5298505  1.1423784]\n",
      "[-1.0562919  1.1996406]\n",
      "[-1.1483407   0.69129544]\n",
      "[-0.75347275  1.0282048 ]\n",
      "[-1.2831191  1.495214 ]\n",
      "[20450, 418075]\n",
      "  438525/1500000: episode: 225, duration: 3.328s, episode steps: 1949, steps per second: 586, episode reward: 413.700, mean reward: 0.212 [-139.800, 135.500], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 35.769817, mean_absolute_error: 1.413791, mean_q: -0.000660\n",
      "[-0.40389848  1.5185983 ]\n",
      "[-0.97765785  1.455767  ]\n",
      "[-1.1145388  1.3049768]\n",
      "[-1.1162441  1.4005868]\n",
      "[-1.3665696  1.2265673]\n",
      "[20525, 419949]\n",
      "  440474/1500000: episode: 226, duration: 3.257s, episode steps: 1949, steps per second: 598, episode reward: 342.200, mean reward: 0.176 [-201.500, 153.500], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.142231, mean_absolute_error: 1.799067, mean_q: 0.006998\n",
      "[-0.46646777  1.7836549 ]\n",
      "[-1.1650006  1.4898342]\n",
      "[-1.0847055  0.5617757]\n",
      "[-0.98176694  0.32976252]\n",
      "[-1.7007104  1.1567305]\n",
      "[20610, 421813]\n",
      "  442423/1500000: episode: 227, duration: 3.334s, episode steps: 1949, steps per second: 585, episode reward: 640.300, mean reward: 0.329 [-83.000, 146.900], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.618027, mean_absolute_error: 1.548771, mean_q: 0.016739\n",
      "[-0.2926022  0.8642082]\n",
      "[-0.8179942  1.5021379]\n",
      "[-0.6338741  1.1179967]\n",
      "[-0.26559988  0.47383073]\n",
      "[20682, 423690]\n",
      "  444372/1500000: episode: 228, duration: 3.404s, episode steps: 1949, steps per second: 573, episode reward: 480.700, mean reward: 0.247 [-188.400, 163.300], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.318356, mean_absolute_error: 2.027341, mean_q: 0.018835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2477849  0.8085256]\n",
      "[-1.327865   0.9355259]\n",
      "[-0.72124726  0.94285846]\n",
      "[-0.926843  1.33685 ]\n",
      "[-0.92354846  1.3828355 ]\n",
      "[20769, 425552]\n",
      "  446321/1500000: episode: 229, duration: 3.440s, episode steps: 1949, steps per second: 567, episode reward: 195.900, mean reward: 0.101 [-168.700, 148.700], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.794510, mean_absolute_error: 1.987870, mean_q: 0.029277\n",
      "[-0.882904    0.80144733]\n",
      "[-0.7994412  0.6404466]\n",
      "[-0.6640305  1.4211477]\n",
      "[-1.3107109   0.63461554]\n",
      "[-0.9867405  0.6687576]\n",
      "[20846, 427424]\n",
      "  448270/1500000: episode: 230, duration: 3.443s, episode steps: 1949, steps per second: 566, episode reward: 399.300, mean reward: 0.205 [-134.900, 181.600], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.653255, mean_absolute_error: 2.020757, mean_q: 0.029646\n",
      "[-1.2664828  1.4033571]\n",
      "[-0.56144196  0.98128927]\n",
      "[-0.08106322  0.3388789 ]\n",
      "[-0.36878148  1.302113  ]\n",
      "[-0.30126956  1.5532135 ]\n",
      "[20927, 429292]\n",
      "  450219/1500000: episode: 231, duration: 3.365s, episode steps: 1949, steps per second: 579, episode reward: 682.600, mean reward: 0.350 [-91.800, 199.800], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.934669, mean_absolute_error: 2.353631, mean_q: 0.028278\n",
      "[-1.196233   0.7463729]\n",
      "[-1.5617998  1.2602482]\n",
      "[-0.383014   1.2529175]\n",
      "[-0.6070909  1.5669703]\n",
      "[-0.81106454  0.82290155]\n",
      "[21000, 431168]\n",
      "  452168/1500000: episode: 232, duration: 3.234s, episode steps: 1949, steps per second: 603, episode reward: 593.700, mean reward: 0.305 [-90.200, 205.800], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.389473, mean_absolute_error: 1.881955, mean_q: 0.025589\n",
      "[-1.0094504   0.90985435]\n",
      "[-1.4095881  1.3295579]\n",
      "[-1.0607859  1.3370101]\n",
      "[-0.33009377  1.2219104 ]\n",
      "[-0.74081415  1.3360903 ]\n",
      "[21066, 433051]\n",
      "  454117/1500000: episode: 233, duration: 3.321s, episode steps: 1949, steps per second: 587, episode reward: 389.400, mean reward: 0.200 [-195.500, 166.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 73.825645, mean_absolute_error: 2.311177, mean_q: 0.019215\n",
      "[-0.75338435  2.0377407 ]\n",
      "[-0.01062442  0.8381953 ]\n",
      "[-0.5117727  1.132936 ]\n",
      "[-1.1949573   0.89724225]\n",
      "[-1.0716951  1.7553239]\n",
      "[21140, 434926]\n",
      "  456066/1500000: episode: 234, duration: 3.533s, episode steps: 1949, steps per second: 552, episode reward: 813.800, mean reward: 0.418 [-92.400, 198.700], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.674004, mean_absolute_error: 1.718449, mean_q: 0.014802\n",
      "[-0.9688987  1.4728321]\n",
      "[-0.536593   0.9241085]\n",
      "[-0.6918519   0.56161636]\n",
      "[-0.62592566  1.1162822 ]\n",
      "[-0.45858297  0.91643584]\n",
      "[21221, 436794]\n",
      "  458015/1500000: episode: 235, duration: 3.426s, episode steps: 1949, steps per second: 569, episode reward: 606.600, mean reward: 0.311 [-110.700, 173.500], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.153229, mean_absolute_error: 1.707154, mean_q: 0.011483\n",
      "[-0.38545564  1.1645017 ]\n",
      "[-0.5813065  1.2427592]\n",
      "[-0.37153354  0.6802409 ]\n",
      "[-0.7071611   0.57225186]\n",
      "[21285, 438679]\n",
      "  459964/1500000: episode: 236, duration: 3.291s, episode steps: 1949, steps per second: 592, episode reward: 701.100, mean reward: 0.360 [-96.900, 211.700], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.836742, mean_absolute_error: 2.216565, mean_q: 0.008994\n",
      "[-0.7750417  1.1169851]\n",
      "[-0.9528645   0.60945106]\n",
      "[-0.94965714  0.7741685 ]\n",
      "[0.00619549 0.9177893 ]\n",
      "[-0.4721386  1.2000698]\n",
      "[21366, 440547]\n",
      "  461913/1500000: episode: 237, duration: 3.291s, episode steps: 1949, steps per second: 592, episode reward: 804.400, mean reward: 0.413 [-110.400, 175.900], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.955212, mean_absolute_error: 1.989085, mean_q: 0.007164\n",
      "[-0.6578423   0.61858636]\n",
      "[-2.048965   1.2530624]\n",
      "[-0.87627244  1.1049006 ]\n",
      "[-1.271997    0.84916055]\n",
      "[-1.0190796  0.8524219]\n",
      "[21449, 442413]\n",
      "  463862/1500000: episode: 238, duration: 3.376s, episode steps: 1949, steps per second: 577, episode reward: 599.500, mean reward: 0.308 [-111.900, 169.700], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.357761, mean_absolute_error: 1.960419, mean_q: 0.006760\n",
      "[-1.1214948   0.79180443]\n",
      "[-1.2678813  0.9123843]\n",
      "[-0.32286656  1.5235692 ]\n",
      "[-0.45133424  1.030055  ]\n",
      "[-0.62151134  1.3850793 ]\n",
      "[21511, 444300]\n",
      "  465811/1500000: episode: 239, duration: 3.310s, episode steps: 1949, steps per second: 589, episode reward: 611.800, mean reward: 0.314 [-153.200, 238.900], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.081337, mean_absolute_error: 1.873439, mean_q: 0.006357\n",
      "[-0.825198   1.1349461]\n",
      "[-1.0706449  0.9279389]\n",
      "[-0.5635996   0.61357903]\n",
      "[-1.1448411  1.4612026]\n",
      "[-0.8671359  0.9307376]\n",
      "[21594, 446166]\n",
      "  467760/1500000: episode: 240, duration: 3.396s, episode steps: 1949, steps per second: 574, episode reward: 337.200, mean reward: 0.173 [-117.100, 174.700], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.949196, mean_absolute_error: 1.579815, mean_q: 0.006536\n",
      "[-1.0321873   0.70231825]\n",
      "[-1.0576941  1.3602141]\n",
      "[-1.1894403  1.5152262]\n",
      "[-0.74683905  1.3007928 ]\n",
      "[-1.0840118  1.3081925]\n",
      "[21682, 448027]\n",
      "  469709/1500000: episode: 241, duration: 3.383s, episode steps: 1949, steps per second: 576, episode reward: 202.800, mean reward: 0.104 [-105.100, 207.800], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.907822, mean_absolute_error: 1.765943, mean_q: 0.006733\n",
      "[-1.2574955  0.6270341]\n",
      "[-0.97886646  0.873391  ]\n",
      "[-0.68134165  1.6306336 ]\n",
      "[-1.0821022  1.4898815]\n",
      "[-0.93756294  1.4805617 ]\n",
      "[21755, 449903]\n",
      "  471658/1500000: episode: 242, duration: 3.348s, episode steps: 1949, steps per second: 582, episode reward: 248.000, mean reward: 0.127 [-168.300, 173.500], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 35.598473, mean_absolute_error: 1.550100, mean_q: 0.007099\n",
      "[-1.5684578  0.8977257]\n",
      "[-0.7924137  0.829988 ]\n",
      "[-1.024539   1.2831436]\n",
      "[-0.9274186  1.5145504]\n",
      "[-0.73721904  1.297772  ]\n",
      "[21848, 451759]\n",
      "  473607/1500000: episode: 243, duration: 3.438s, episode steps: 1949, steps per second: 567, episode reward: 736.400, mean reward: 0.378 [-95.400, 219.600], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 72.697906, mean_absolute_error: 2.305736, mean_q: 0.007056\n",
      "[-0.04681505  1.3608776 ]\n",
      "[-0.32389697  1.8780042 ]\n",
      "[0.05556339 1.4734867 ]\n",
      "[-0.3172584   0.80395454]\n",
      "[21945, 453611]\n",
      "  475556/1500000: episode: 244, duration: 3.490s, episode steps: 1949, steps per second: 558, episode reward: 118.800, mean reward: 0.061 [-168.700, 161.700], mean action: 0.950 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.223534, mean_absolute_error: 1.802256, mean_q: 0.007780\n",
      "[-1.0308028  0.8024697]\n",
      "[-0.73526555  1.75422   ]\n",
      "[-0.9572689  2.1445673]\n",
      "[-1.5338312  2.0571883]\n",
      "[-0.24910562  1.7495735 ]\n",
      "[22030, 455475]\n",
      "  477505/1500000: episode: 245, duration: 3.485s, episode steps: 1949, steps per second: 559, episode reward: 705.400, mean reward: 0.362 [-115.600, 137.600], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 25.126057, mean_absolute_error: 1.416791, mean_q: 0.008510\n",
      "[-0.99572974  1.2353785 ]\n",
      "[-1.7439159  1.0056508]\n",
      "[-0.79513204  1.0079066 ]\n",
      "[-0.93378544  0.9989382 ]\n",
      "[-0.99840117  1.6247176 ]\n",
      "[22118, 457336]\n",
      "  479454/1500000: episode: 246, duration: 3.218s, episode steps: 1949, steps per second: 606, episode reward: 340.100, mean reward: 0.174 [-139.800, 135.200], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.704758, mean_absolute_error: 1.654509, mean_q: 0.008189\n",
      "[-1.0401713   0.76948994]\n",
      "[-0.5272117  1.711643 ]\n",
      "[-0.6933198  1.5404145]\n",
      "[-0.4528949  1.5122914]\n",
      "[-0.16181651  1.48199   ]\n",
      "[22193, 459210]\n",
      "  481403/1500000: episode: 247, duration: 3.332s, episode steps: 1949, steps per second: 585, episode reward: 342.000, mean reward: 0.175 [-214.000, 168.700], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.313683, mean_absolute_error: 1.693981, mean_q: 0.007311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.86997485  1.403481  ]\n",
      "[-0.6478813  0.9281826]\n",
      "[-1.1383985   0.85204166]\n",
      "[-1.4725384  1.2883267]\n",
      "[-0.78878295  1.149226  ]\n",
      "[22284, 461068]\n",
      "  483352/1500000: episode: 248, duration: 3.329s, episode steps: 1949, steps per second: 585, episode reward: 460.100, mean reward: 0.236 [-96.400, 139.100], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.255299, mean_absolute_error: 1.805865, mean_q: 0.006168\n",
      "[-1.2971065  0.6783154]\n",
      "[-0.26385573  1.2534292 ]\n",
      "[-0.9323862  1.3116394]\n",
      "[-0.55286807  1.0265825 ]\n",
      "[-1.5308983   0.51793975]\n",
      "[22360, 462941]\n",
      "  485301/1500000: episode: 249, duration: 3.279s, episode steps: 1949, steps per second: 594, episode reward: 187.500, mean reward: 0.096 [-93.600, 177.600], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.929691, mean_absolute_error: 1.897082, mean_q: 0.004851\n",
      "[-0.8200247  1.1318368]\n",
      "[-1.2185799  1.3683399]\n",
      "[-0.86593986  1.1598003 ]\n",
      "[-0.8862704  1.5322881]\n",
      "[-0.8559723   0.81680536]\n",
      "[22438, 464812]\n",
      "  487250/1500000: episode: 250, duration: 3.272s, episode steps: 1949, steps per second: 596, episode reward: 251.600, mean reward: 0.129 [-107.200, 214.700], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.112926, mean_absolute_error: 1.629244, mean_q: 0.004160\n",
      "[-1.1066395  1.0850406]\n",
      "[-0.5576166  1.6437267]\n",
      "[-0.82172793  1.0370709 ]\n",
      "[-0.8360161   0.66958445]\n",
      "[22508, 466691]\n",
      "  489199/1500000: episode: 251, duration: 3.284s, episode steps: 1949, steps per second: 593, episode reward: 672.800, mean reward: 0.345 [-98.100, 213.800], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.044765, mean_absolute_error: 2.191445, mean_q: 0.003710\n",
      "[-0.9838812  0.971989 ]\n",
      "[-1.2736738   0.59649175]\n",
      "[-0.64937675  1.2148994 ]\n",
      "[-1.0808898  1.2289721]\n",
      "[-0.43956104  1.4155624 ]\n",
      "[22598, 468550]\n",
      "  491148/1500000: episode: 252, duration: 3.387s, episode steps: 1949, steps per second: 575, episode reward: 330.400, mean reward: 0.170 [-103.000, 150.300], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.958954, mean_absolute_error: 1.981663, mean_q: 0.003568\n",
      "[-0.63607377  1.1972585 ]\n",
      "[-0.42666525  1.4214683 ]\n",
      "[-0.9576578  1.6810513]\n",
      "[0.22756673 1.8289825 ]\n",
      "[-0.7883492   0.21337189]\n",
      "[22669, 470428]\n",
      "  493097/1500000: episode: 253, duration: 3.463s, episode steps: 1949, steps per second: 563, episode reward: 392.100, mean reward: 0.201 [-131.300, 153.600], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.576740, mean_absolute_error: 2.065562, mean_q: 0.003451\n",
      "[-0.93240076  1.1385994 ]\n",
      "[-1.2874857  1.2970661]\n",
      "[-0.79114044  1.4949244 ]\n",
      "[-1.2088637  1.6005287]\n",
      "[-1.3339175   0.19263285]\n",
      "[22746, 472300]\n",
      "  495046/1500000: episode: 254, duration: 3.350s, episode steps: 1949, steps per second: 582, episode reward: 140.600, mean reward: 0.072 [-138.900, 151.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.920490, mean_absolute_error: 1.925791, mean_q: 0.003791\n",
      "[-1.0142978  1.225935 ]\n",
      "[-0.49521318  0.8775686 ]\n",
      "[-0.5405657   0.82861507]\n",
      "[-0.70755553  0.678865  ]\n",
      "[-0.63670534  1.5354834 ]\n",
      "[22827, 474168]\n",
      "  496995/1500000: episode: 255, duration: 3.460s, episode steps: 1949, steps per second: 563, episode reward: 578.300, mean reward: 0.297 [-77.800, 188.200], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.646160, mean_absolute_error: 1.563012, mean_q: 0.003789\n",
      "[-0.51263124  1.2739275 ]\n",
      "[-0.7034586  1.369564 ]\n",
      "[-0.59771293  2.0407    ]\n",
      "[-0.63028115  0.8875223 ]\n",
      "[-0.46525174  1.0219699 ]\n",
      "[22906, 476038]\n",
      "  498944/1500000: episode: 256, duration: 3.288s, episode steps: 1949, steps per second: 593, episode reward: 364.300, mean reward: 0.187 [-112.800, 286.600], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.542549, mean_absolute_error: 1.787900, mean_q: 0.003743\n",
      "[-0.33597493  0.7575685 ]\n",
      "[-1.6881998  1.1449251]\n",
      "[-0.954984   0.8113197]\n",
      "[-0.7834659  1.463265 ]\n",
      "[-1.4742831  1.7701035]\n",
      "[22972, 477921]\n",
      "  500893/1500000: episode: 257, duration: 3.530s, episode steps: 1949, steps per second: 552, episode reward: 811.300, mean reward: 0.416 [-99.500, 139.600], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.067741, mean_absolute_error: 1.735948, mean_q: 0.003582\n",
      "[-0.95031464  0.9575465 ]\n",
      "[-0.8535293  0.7497429]\n",
      "[-0.7981251  1.2606885]\n",
      "[-0.7269129  1.2321911]\n",
      "[-0.5701011  1.6879448]\n",
      "[23058, 479784]\n",
      "  502842/1500000: episode: 258, duration: 3.289s, episode steps: 1949, steps per second: 593, episode reward: 334.600, mean reward: 0.172 [-100.800, 139.800], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.430756, mean_absolute_error: 2.061125, mean_q: 0.003705\n",
      "[-1.3333826  1.3431467]\n",
      "[-0.7780785   0.84239215]\n",
      "[-1.708052   1.2360195]\n",
      "[-1.0744824  1.67477  ]\n",
      "[23133, 481658]\n",
      "  504791/1500000: episode: 259, duration: 3.291s, episode steps: 1949, steps per second: 592, episode reward: 548.800, mean reward: 0.282 [-116.700, 140.400], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.046814, mean_absolute_error: 2.132824, mean_q: 0.003468\n",
      "[-1.1245081  1.0613122]\n",
      "[-0.9685387  0.8875299]\n",
      "[-1.1039269  1.0920954]\n",
      "[-0.9535326  1.0305277]\n",
      "[-0.70355296  0.8939257 ]\n",
      "[23217, 483523]\n",
      "  506740/1500000: episode: 260, duration: 3.343s, episode steps: 1949, steps per second: 583, episode reward: 334.900, mean reward: 0.172 [-69.200, 189.300], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 28.533808, mean_absolute_error: 1.321266, mean_q: 0.003349\n",
      "[-0.900345    0.81046176]\n",
      "[-0.7991016   0.75358886]\n",
      "[-0.9764769  1.5983148]\n",
      "[-0.48377606  1.5727887 ]\n",
      "[-0.02652497  1.2610734 ]\n",
      "[23304, 485385]\n",
      "  508689/1500000: episode: 261, duration: 3.622s, episode steps: 1949, steps per second: 538, episode reward: 608.800, mean reward: 0.312 [-97.500, 199.800], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.452705, mean_absolute_error: 1.875974, mean_q: 0.003705\n",
      "[-1.7481271   0.47510788]\n",
      "[-1.1743251  1.1828402]\n",
      "[-0.823422   1.4553084]\n",
      "[-1.1926512  1.1445868]\n",
      "[-0.7995502  1.3182636]\n",
      "[23376, 487262]\n",
      "  510638/1500000: episode: 262, duration: 3.317s, episode steps: 1949, steps per second: 588, episode reward: 266.900, mean reward: 0.137 [-100.200, 111.800], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.638531, mean_absolute_error: 1.806142, mean_q: 0.004088\n",
      "[-1.0294756   0.35725674]\n",
      "[-1.3966228   0.81246954]\n",
      "[-1.0627623  1.2110914]\n",
      "[-0.6696179  1.7141467]\n",
      "[-0.20110661  1.885635  ]\n",
      "[23449, 489138]\n",
      "  512587/1500000: episode: 263, duration: 3.604s, episode steps: 1949, steps per second: 541, episode reward: 359.900, mean reward: 0.185 [-98.000, 167.000], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.965057, mean_absolute_error: 1.963857, mean_q: 0.004758\n",
      "[-0.88450277  1.3172673 ]\n",
      "[-1.0123459  1.483288 ]\n",
      "[-0.49731398  1.341243  ]\n",
      "[-0.3821229   0.89253664]\n",
      "[-1.2676972  0.7631164]\n",
      "[23526, 491010]\n",
      "  514536/1500000: episode: 264, duration: 3.327s, episode steps: 1949, steps per second: 586, episode reward: 303.800, mean reward: 0.156 [-125.100, 136.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.673485, mean_absolute_error: 2.188209, mean_q: 0.005553\n",
      "[-1.6702731  1.3753089]\n",
      "[-1.0124118  0.8506008]\n",
      "[-1.0196025  1.2408888]\n",
      "[-0.6918193   0.45485517]\n",
      "[0.00426436 1.2545261 ]\n",
      "[23601, 492884]\n",
      "  516485/1500000: episode: 265, duration: 3.317s, episode steps: 1949, steps per second: 588, episode reward: 505.800, mean reward: 0.260 [-101.700, 192.700], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.324055, mean_absolute_error: 1.967182, mean_q: 0.006344\n",
      "[-0.5746292  2.1367743]\n",
      "[-0.862514    0.90778685]\n",
      "[-1.0531086  2.1523035]\n",
      "[-0.6398492  1.6117078]\n",
      "[-0.2367549  1.2287549]\n",
      "[23673, 494761]\n",
      "  518434/1500000: episode: 266, duration: 3.456s, episode steps: 1949, steps per second: 564, episode reward: 610.900, mean reward: 0.313 [-117.100, 183.300], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 26.681074, mean_absolute_error: 1.428479, mean_q: 0.007433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.63753116  1.2745543 ]\n",
      "[-0.88395983  1.5082091 ]\n",
      "[-0.9894282  1.0901322]\n",
      "[0.14257738 0.9182193 ]\n",
      "[23756, 496627]\n",
      "  520383/1500000: episode: 267, duration: 3.323s, episode steps: 1949, steps per second: 586, episode reward: 242.300, mean reward: 0.124 [-206.000, 170.800], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.711773, mean_absolute_error: 1.988221, mean_q: 0.009823\n",
      "[-1.0030231  1.1127074]\n",
      "[-1.0771185  1.200456 ]\n",
      "[-1.0702714  1.4017334]\n",
      "[-1.1048434   0.86021674]\n",
      "[-0.72419554  1.0942726 ]\n",
      "[23833, 498499]\n",
      "  522332/1500000: episode: 268, duration: 3.318s, episode steps: 1949, steps per second: 587, episode reward: 574.900, mean reward: 0.295 [-89.900, 174.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 28.352255, mean_absolute_error: 1.602780, mean_q: 0.013303\n",
      "[-0.849848   1.0266104]\n",
      "[-0.6746306   0.70102036]\n",
      "[-0.7903071  1.219115 ]\n",
      "[-0.30070463  1.6839166 ]\n",
      "[0.1421168 0.761238 ]\n",
      "[23897, 500384]\n",
      "  524281/1500000: episode: 269, duration: 3.347s, episode steps: 1949, steps per second: 582, episode reward: 508.400, mean reward: 0.261 [-204.700, 200.200], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 25.726347, mean_absolute_error: 1.464243, mean_q: 0.013777\n",
      "[-1.2423688  1.107151 ]\n",
      "[-1.2934223   0.58479226]\n",
      "[-0.80667233  0.6843268 ]\n",
      "[-0.9095279  1.4320962]\n",
      "[-0.96856356  1.4615601 ]\n",
      "[23975, 502255]\n",
      "  526230/1500000: episode: 270, duration: 3.360s, episode steps: 1949, steps per second: 580, episode reward: 431.000, mean reward: 0.221 [-88.200, 188.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.063255, mean_absolute_error: 1.830856, mean_q: 0.012900\n",
      "[-0.740069   0.8969436]\n",
      "[-0.23511274  1.014845  ]\n",
      "[-0.71902823  1.3419056 ]\n",
      "[-0.6861452  1.8353642]\n",
      "[-0.71665627  1.6248319 ]\n",
      "[24065, 504114]\n",
      "  528179/1500000: episode: 271, duration: 3.395s, episode steps: 1949, steps per second: 574, episode reward: 287.800, mean reward: 0.148 [-96.200, 97.500], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.086670, mean_absolute_error: 1.958775, mean_q: 0.012306\n",
      "[-0.88734937  0.6820171 ]\n",
      "[-0.8180802  1.2092769]\n",
      "[-1.0624979  1.5034577]\n",
      "[-1.3791922  1.0652286]\n",
      "[-0.25554767  0.870256  ]\n",
      "[24158, 505970]\n",
      "  530128/1500000: episode: 272, duration: 3.436s, episode steps: 1949, steps per second: 567, episode reward: 563.800, mean reward: 0.289 [-214.900, 146.000], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.026989, mean_absolute_error: 1.681069, mean_q: 0.009107\n",
      "[-0.9870684  1.3331378]\n",
      "[-1.19355    1.1889398]\n",
      "[-0.67849725  0.20721318]\n",
      "[-0.8216904  1.228535 ]\n",
      "[-1.725895   0.6143217]\n",
      "[24236, 507841]\n",
      "  532077/1500000: episode: 273, duration: 3.450s, episode steps: 1949, steps per second: 565, episode reward: 367.800, mean reward: 0.189 [-111.800, 191.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.329601, mean_absolute_error: 1.712784, mean_q: 0.007517\n",
      "[-0.44426468  1.3072002 ]\n",
      "[-0.79556304  1.3685622 ]\n",
      "[-0.76297337  1.1043417 ]\n",
      "[0.22912675 1.4120132 ]\n",
      "[-1.561221  1.291883]\n",
      "[24314, 509712]\n",
      "  534026/1500000: episode: 274, duration: 3.546s, episode steps: 1949, steps per second: 550, episode reward: 354.100, mean reward: 0.182 [-135.600, 157.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.180771, mean_absolute_error: 1.872985, mean_q: 0.006128\n",
      "[-0.7986238  1.4085693]\n",
      "[-0.6890708   0.87376916]\n",
      "[-1.1496843  1.408071 ]\n",
      "[-0.46055004  1.1277958 ]\n",
      "[24386, 511589]\n",
      "  535975/1500000: episode: 275, duration: 4.523s, episode steps: 1949, steps per second: 431, episode reward: 417.300, mean reward: 0.214 [-172.400, 156.900], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.243042, mean_absolute_error: 2.082196, mean_q: 0.005141\n",
      "[-0.8759538  1.1884837]\n",
      "[-0.22544521  1.220211  ]\n",
      "[0.10050334 1.4732527 ]\n",
      "[-0.16401628  1.4239824 ]\n",
      "[-0.09032045  0.9739696 ]\n",
      "[24446, 513478]\n",
      "  537924/1500000: episode: 276, duration: 3.259s, episode steps: 1949, steps per second: 598, episode reward: 455.800, mean reward: 0.234 [-101.500, 197.600], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 68.035965, mean_absolute_error: 2.067484, mean_q: 0.003829\n",
      "[-1.2790965  1.1978109]\n",
      "[-1.1605458   0.81912166]\n",
      "[-1.310765   1.3032974]\n",
      "[-1.2487624  1.1028005]\n",
      "[-1.1546559  1.3720727]\n",
      "[24525, 515348]\n",
      "  539873/1500000: episode: 277, duration: 3.420s, episode steps: 1949, steps per second: 570, episode reward: 265.400, mean reward: 0.136 [-183.900, 130.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.376190, mean_absolute_error: 1.782629, mean_q: 0.003288\n",
      "[-0.8152932   0.89605784]\n",
      "[-0.75828564  1.1016234 ]\n",
      "[-1.2881718   0.60372585]\n",
      "[-1.1161509  0.9949183]\n",
      "[-1.0809531  1.5458765]\n",
      "[24611, 517211]\n",
      "  541822/1500000: episode: 278, duration: 3.714s, episode steps: 1949, steps per second: 525, episode reward: 415.800, mean reward: 0.213 [-100.400, 147.600], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 74.053413, mean_absolute_error: 2.318506, mean_q: 0.003222\n",
      "[-0.9280565   0.97642034]\n",
      "[-0.5676992   0.67664146]\n",
      "[-0.58623683  1.4540923 ]\n",
      "[-1.0684433  1.3653008]\n",
      "[-1.4735489  1.8293833]\n",
      "[24682, 519089]\n",
      "  543771/1500000: episode: 279, duration: 3.629s, episode steps: 1949, steps per second: 537, episode reward: 650.500, mean reward: 0.334 [-96.000, 167.100], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.856186, mean_absolute_error: 1.901018, mean_q: 0.002796\n",
      "[-0.6050004  0.8981408]\n",
      "[-0.79410964  0.6004258 ]\n",
      "[-1.2150768  1.1727993]\n",
      "[-0.8239635  1.155886 ]\n",
      "[-1.1578829  1.7333579]\n",
      "[24740, 520980]\n",
      "  545720/1500000: episode: 280, duration: 3.344s, episode steps: 1949, steps per second: 583, episode reward: 697.700, mean reward: 0.358 [-86.100, 205.200], mean action: 0.970 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.849018, mean_absolute_error: 1.688874, mean_q: 0.002453\n",
      "[-0.7212662  1.2676705]\n",
      "[-0.68598384  1.3191981 ]\n",
      "[-1.379483   0.3704026]\n",
      "[-0.8334632  0.8429609]\n",
      "[-0.8069472  1.5858883]\n",
      "[24817, 522852]\n",
      "  547669/1500000: episode: 281, duration: 3.307s, episode steps: 1949, steps per second: 589, episode reward: 417.500, mean reward: 0.214 [-119.500, 176.900], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 86.188385, mean_absolute_error: 2.357176, mean_q: 0.002489\n",
      "[-0.50029314  1.5203962 ]\n",
      "[-1.2379746  1.4104123]\n",
      "[-1.2701755  1.5404269]\n",
      "[-1.241487   1.3784264]\n",
      "[-0.49914905  1.1987586 ]\n",
      "[24893, 524725]\n",
      "  549618/1500000: episode: 282, duration: 3.333s, episode steps: 1949, steps per second: 585, episode reward: 779.800, mean reward: 0.400 [-128.100, 189.300], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.710602, mean_absolute_error: 2.133620, mean_q: 0.003142\n",
      "[-0.399209   0.7739834]\n",
      "[-0.4199532  0.7104424]\n",
      "[-1.0163121  1.5106018]\n",
      "[-1.1227617  1.1041467]\n",
      "[24978, 526589]\n",
      "  551567/1500000: episode: 283, duration: 3.088s, episode steps: 1949, steps per second: 631, episode reward: 605.900, mean reward: 0.311 [-123.900, 206.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.199211, mean_absolute_error: 1.811419, mean_q: 0.002889\n",
      "[-0.8747491  1.0551958]\n",
      "[-0.73117906  1.0469562 ]\n",
      "[-1.0460244  2.081459 ]\n",
      "[-1.2218214  1.5775975]\n",
      "[-0.93947273  1.2109183 ]\n",
      "[25058, 528458]\n",
      "  553516/1500000: episode: 284, duration: 3.132s, episode steps: 1949, steps per second: 622, episode reward: 583.900, mean reward: 0.300 [-92.800, 183.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.648548, mean_absolute_error: 1.666346, mean_q: 0.002172\n",
      "[-1.2111553  1.0795915]\n",
      "[-0.87441254  1.5283947 ]\n",
      "[-1.0460941  1.8276962]\n",
      "[-0.82589483  1.5018572 ]\n",
      "[-0.81817645  1.4718263 ]\n",
      "[25134, 530331]\n",
      "  555465/1500000: episode: 285, duration: 3.555s, episode steps: 1949, steps per second: 548, episode reward: 597.800, mean reward: 0.307 [-111.900, 127.900], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 76.190201, mean_absolute_error: 2.058504, mean_q: 0.001116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6263666  1.9068799]\n",
      "[-0.04876813  0.86170036]\n",
      "[-0.68581617  0.80087876]\n",
      "[-0.561544    0.97519284]\n",
      "[-0.68083125  0.7798603 ]\n",
      "[25213, 532201]\n",
      "  557414/1500000: episode: 286, duration: 3.979s, episode steps: 1949, steps per second: 490, episode reward: 525.400, mean reward: 0.270 [-149.800, 140.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.967697, mean_absolute_error: 1.804132, mean_q: 0.000326\n",
      "[-0.8117966  1.3996458]\n",
      "[-0.26231736  1.0100031 ]\n",
      "[-0.36434993  1.3744639 ]\n",
      "[-0.7366318  1.2159262]\n",
      "[-0.85193646  1.1492347 ]\n",
      "[25295, 534068]\n",
      "  559363/1500000: episode: 287, duration: 3.505s, episode steps: 1949, steps per second: 556, episode reward: 602.100, mean reward: 0.309 [-142.600, 137.700], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 73.403496, mean_absolute_error: 2.229716, mean_q: 0.000058\n",
      "[-0.8676296   0.61045265]\n",
      "[-1.035428   1.0361804]\n",
      "[-0.8599958  0.7939825]\n",
      "[-0.6858415  1.0558676]\n",
      "[-0.91154945  1.1282191 ]\n",
      "[25374, 535938]\n",
      "  561312/1500000: episode: 288, duration: 3.561s, episode steps: 1949, steps per second: 547, episode reward: 408.000, mean reward: 0.209 [-93.700, 124.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.470886, mean_absolute_error: 1.725371, mean_q: -0.000463\n",
      "[-1.4138522  1.7889793]\n",
      "[-1.1815287   0.94818354]\n",
      "[-1.339406  1.012608]\n",
      "[-0.8964284  1.3330851]\n",
      "[-0.7082321  1.808969 ]\n",
      "[25434, 537827]\n",
      "  563261/1500000: episode: 289, duration: 4.512s, episode steps: 1949, steps per second: 432, episode reward: 495.200, mean reward: 0.254 [-143.300, 174.800], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 73.867218, mean_absolute_error: 1.978162, mean_q: -0.000971\n",
      "[-0.79857665  1.1975495 ]\n",
      "[-1.378968  1.095558]\n",
      "[-1.2878186   0.86522675]\n",
      "[-1.0802697   0.25172475]\n",
      "[-0.75893545  0.82471174]\n",
      "[25506, 539704]\n",
      "  565210/1500000: episode: 290, duration: 4.004s, episode steps: 1949, steps per second: 487, episode reward: 472.100, mean reward: 0.242 [-76.700, 123.000], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.133186, mean_absolute_error: 1.777717, mean_q: -0.001392\n",
      "[-0.31484437  1.8651152 ]\n",
      "[-1.1053172  1.2934473]\n",
      "[-0.93338275  1.6207902 ]\n",
      "[-0.16659194  0.9013436 ]\n",
      "[25583, 541576]\n",
      "  567159/1500000: episode: 291, duration: 3.726s, episode steps: 1949, steps per second: 523, episode reward: 987.300, mean reward: 0.507 [-98.300, 191.600], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.501026, mean_absolute_error: 2.056973, mean_q: -0.002009\n",
      "[-0.9841379   0.77428496]\n",
      "[-0.24666741  0.92946243]\n",
      "[0.26691023 1.174644  ]\n",
      "[0.20056215 0.5063201 ]\n",
      "[-0.5074262   0.25890532]\n",
      "[25687, 543421]\n",
      "  569108/1500000: episode: 292, duration: 3.596s, episode steps: 1949, steps per second: 542, episode reward: 708.700, mean reward: 0.364 [-79.500, 228.500], mean action: 0.947 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.285851, mean_absolute_error: 1.784244, mean_q: -0.002893\n",
      "[-0.5655153  0.8904702]\n",
      "[0.07518364 0.8343931 ]\n",
      "[-0.07574818  0.66503525]\n",
      "[-0.44021952  1.0364729 ]\n",
      "[-0.19133674  0.980182  ]\n",
      "[25799, 545258]\n",
      "  571057/1500000: episode: 293, duration: 3.653s, episode steps: 1949, steps per second: 534, episode reward: 184.700, mean reward: 0.095 [-113.900, 156.300], mean action: 0.943 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.877556, mean_absolute_error: 1.713458, mean_q: -0.003679\n",
      "[-0.823396    0.72066784]\n",
      "[-1.1063108   0.75953734]\n",
      "[-1.0163809  1.0682545]\n",
      "[-0.7562743  1.243042 ]\n",
      "[-0.97835284  1.2565296 ]\n",
      "[25871, 547135]\n",
      "  573006/1500000: episode: 294, duration: 2.980s, episode steps: 1949, steps per second: 654, episode reward: 468.200, mean reward: 0.240 [-66.100, 151.200], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.965061, mean_absolute_error: 1.971020, mean_q: -0.004535\n",
      "[-1.0942442   0.12227843]\n",
      "[-1.0301473   0.32697368]\n",
      "[-0.5323174  1.0401134]\n",
      "[-0.24423465  0.7520244 ]\n",
      "[-0.7709256   0.12719168]\n",
      "[25952, 549003]\n",
      "  574955/1500000: episode: 295, duration: 3.327s, episode steps: 1949, steps per second: 586, episode reward: 627.400, mean reward: 0.322 [-100.600, 145.200], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.043308, mean_absolute_error: 1.876864, mean_q: -0.005617\n",
      "[-0.4330797  1.0204127]\n",
      "[-0.8404392  1.0495824]\n",
      "[-1.5054326  1.4023235]\n",
      "[-0.9691897  1.5052869]\n",
      "[-0.58205265  0.89770144]\n",
      "[26033, 550871]\n",
      "  576904/1500000: episode: 296, duration: 3.962s, episode steps: 1949, steps per second: 492, episode reward: 491.700, mean reward: 0.252 [-79.800, 159.200], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.954357, mean_absolute_error: 2.111980, mean_q: -0.006436\n",
      "[-1.1911165  0.8957911]\n",
      "[-0.63774365  0.83180743]\n",
      "[-1.1939572   0.77672064]\n",
      "[-0.7392363   0.52280444]\n",
      "[-1.209899   1.3381861]\n",
      "[26118, 552735]\n",
      "  578853/1500000: episode: 297, duration: 3.332s, episode steps: 1949, steps per second: 585, episode reward: 542.600, mean reward: 0.278 [-110.100, 188.900], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.644978, mean_absolute_error: 1.703087, mean_q: -0.007088\n",
      "[0.0293916 1.2983874]\n",
      "[-0.8359309  1.5234963]\n",
      "[-0.49076626  1.0829062 ]\n",
      "[-0.71446747  1.1018893 ]\n",
      "[-0.9407829  1.2119714]\n",
      "[26185, 554617]\n",
      "  580802/1500000: episode: 298, duration: 3.406s, episode steps: 1949, steps per second: 572, episode reward: 433.400, mean reward: 0.222 [-197.300, 191.300], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 29.231972, mean_absolute_error: 1.356429, mean_q: -0.007709\n",
      "[-1.1132741  1.3096751]\n",
      "[-0.80141026  1.1499543 ]\n",
      "[-0.9930864  1.0924337]\n",
      "[-1.0208105  1.1115242]\n",
      "[26252, 556499]\n",
      "  582751/1500000: episode: 299, duration: 3.085s, episode steps: 1949, steps per second: 632, episode reward: 362.000, mean reward: 0.186 [-190.400, 147.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.943390, mean_absolute_error: 2.048853, mean_q: -0.008305\n",
      "[-0.7150967   0.79967636]\n",
      "[-0.3722791  1.367585 ]\n",
      "[-0.8671299  1.2325819]\n",
      "[-0.6580248  1.3544108]\n",
      "[-0.22661707  2.0831935 ]\n",
      "[26349, 558351]\n",
      "  584700/1500000: episode: 300, duration: 3.102s, episode steps: 1949, steps per second: 628, episode reward: 352.400, mean reward: 0.181 [-90.400, 195.100], mean action: 0.950 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.440582, mean_absolute_error: 1.878841, mean_q: -0.008830\n",
      "[-1.8557884  1.0100777]\n",
      "[-1.2312051  1.3217269]\n",
      "[-0.7583906  0.7604196]\n",
      "[-0.38502824  0.8353817 ]\n",
      "[-0.78196126  1.4969594 ]\n",
      "[26420, 560229]\n",
      "  586649/1500000: episode: 301, duration: 3.302s, episode steps: 1949, steps per second: 590, episode reward: 552.400, mean reward: 0.283 [-100.200, 153.200], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.728458, mean_absolute_error: 1.809363, mean_q: -0.009270\n",
      "[-1.4316463  1.2137665]\n",
      "[-1.3959649  1.4906192]\n",
      "[-0.5837501  1.0890778]\n",
      "[-0.5864088  1.6252143]\n",
      "[-0.42932028  1.5333781 ]\n",
      "[26498, 562100]\n",
      "  588598/1500000: episode: 302, duration: 3.159s, episode steps: 1949, steps per second: 617, episode reward: 446.600, mean reward: 0.229 [-120.700, 150.900], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.889484, mean_absolute_error: 1.899587, mean_q: -0.009726\n",
      "[-0.77533054  0.8062588 ]\n",
      "[-0.2889219  1.2204987]\n",
      "[-1.2255585   0.99913603]\n",
      "[-1.8499613  0.7660243]\n",
      "[-1.2082387  1.1675195]\n",
      "[26582, 563965]\n",
      "  590547/1500000: episode: 303, duration: 4.552s, episode steps: 1949, steps per second: 428, episode reward: 174.000, mean reward: 0.089 [-168.700, 153.600], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.071339, mean_absolute_error: 1.852873, mean_q: -0.010123\n",
      "[-0.89444065  0.6516153 ]\n",
      "[-0.5061571  1.4366317]\n",
      "[-0.8436827  1.3212671]\n",
      "[-1.23033    1.2810321]\n",
      "[-1.05687    1.5386839]\n",
      "[26656, 565840]\n",
      "  592496/1500000: episode: 304, duration: 3.514s, episode steps: 1949, steps per second: 555, episode reward: 243.700, mean reward: 0.125 [-112.100, 171.200], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.685398, mean_absolute_error: 1.708026, mean_q: -0.010517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.74967873  1.1379145 ]\n",
      "[-0.7679327  1.9064869]\n",
      "[-0.8074567  1.587197 ]\n",
      "[-0.6705692  1.5504166]\n",
      "[-0.8113823  1.4512137]\n",
      "[26742, 567703]\n",
      "  594445/1500000: episode: 305, duration: 3.837s, episode steps: 1949, steps per second: 508, episode reward: 740.000, mean reward: 0.380 [-140.400, 189.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.781136, mean_absolute_error: 2.082745, mean_q: -0.010930\n",
      "[-0.8913703   0.74327683]\n",
      "[-0.6749589  1.9677433]\n",
      "[-0.896559   1.3024766]\n",
      "[-0.9604547  1.1559895]\n",
      "[26813, 569581]\n",
      "  596394/1500000: episode: 306, duration: 3.666s, episode steps: 1949, steps per second: 532, episode reward: 630.700, mean reward: 0.324 [-179.600, 127.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 28.400507, mean_absolute_error: 1.586856, mean_q: -0.011254\n",
      "[-0.9800717  0.9824824]\n",
      "[-1.4868972  1.314104 ]\n",
      "[-0.90578526  0.6984122 ]\n",
      "[-0.84488237  0.9862852 ]\n",
      "[-1.1703943  1.114691 ]\n",
      "[26889, 571454]\n",
      "  598343/1500000: episode: 307, duration: 3.262s, episode steps: 1949, steps per second: 597, episode reward: 497.900, mean reward: 0.255 [-133.400, 166.600], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.460045, mean_absolute_error: 1.832895, mean_q: -0.011536\n",
      "[-1.0117306  1.1173111]\n",
      "[-1.4095824  1.5167724]\n",
      "[-0.9382305  1.2162699]\n",
      "[-0.5008329  1.0187728]\n",
      "[-1.186046   1.4814067]\n",
      "[26977, 573315]\n",
      "  600292/1500000: episode: 308, duration: 3.535s, episode steps: 1949, steps per second: 551, episode reward: 676.400, mean reward: 0.347 [-93.400, 197.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 68.257950, mean_absolute_error: 2.246628, mean_q: -0.011811\n",
      "[-0.8444512  1.180327 ]\n",
      "[-0.29418463  1.9208614 ]\n",
      "[-1.1603065  1.5363879]\n",
      "[-1.1493047  1.0585104]\n",
      "[-0.88841605  0.909102  ]\n",
      "[27043, 575198]\n",
      "  602241/1500000: episode: 309, duration: 3.435s, episode steps: 1949, steps per second: 567, episode reward: 409.500, mean reward: 0.210 [-87.200, 156.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.748211, mean_absolute_error: 1.848461, mean_q: -0.011951\n",
      "[-0.58786154  1.2503687 ]\n",
      "[-1.2186152  2.2796018]\n",
      "[-0.81358236  1.4886018 ]\n",
      "[-0.852141   1.4662205]\n",
      "[-0.23961622  1.0460113 ]\n",
      "[27119, 577071]\n",
      "  604190/1500000: episode: 310, duration: 3.274s, episode steps: 1949, steps per second: 595, episode reward: 644.200, mean reward: 0.331 [-131.100, 156.400], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.891914, mean_absolute_error: 1.624151, mean_q: -0.012205\n",
      "[-0.7716714  0.9435981]\n",
      "[-0.3935817   0.56057125]\n",
      "[-0.1412833  0.6461265]\n",
      "[-0.46124658  0.578967  ]\n",
      "[-1.4461279  1.2963415]\n",
      "[27191, 578948]\n",
      "  606139/1500000: episode: 311, duration: 3.527s, episode steps: 1949, steps per second: 553, episode reward: 680.000, mean reward: 0.349 [-104.900, 172.500], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.868217, mean_absolute_error: 2.259312, mean_q: -0.012608\n",
      "[-0.9696811   0.88781303]\n",
      "[-0.63425386  1.6399602 ]\n",
      "[-0.11453618  1.3761269 ]\n",
      "[-0.58060366  0.85632443]\n",
      "[-0.43539315  0.8819099 ]\n",
      "[27272, 580816]\n",
      "  608088/1500000: episode: 312, duration: 4.123s, episode steps: 1949, steps per second: 473, episode reward: 473.900, mean reward: 0.243 [-104.800, 150.500], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.510242, mean_absolute_error: 1.763850, mean_q: -0.012994\n",
      "[-0.37014675  1.3587202 ]\n",
      "[-0.35824057  1.1705083 ]\n",
      "[-0.36390218  1.8703018 ]\n",
      "[-0.88224167  1.8655032 ]\n",
      "[-0.8519867  1.2535938]\n",
      "[27357, 582680]\n",
      "  610037/1500000: episode: 313, duration: 3.463s, episode steps: 1949, steps per second: 563, episode reward: 779.000, mean reward: 0.400 [-147.200, 209.200], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.454868, mean_absolute_error: 1.780983, mean_q: -0.013433\n",
      "[-1.3574427  1.495827 ]\n",
      "[-0.49003085  1.2875115 ]\n",
      "[-0.56716156  1.0599164 ]\n",
      "[-1.3375096   0.62110335]\n",
      "[27438, 584548]\n",
      "  611986/1500000: episode: 314, duration: 3.727s, episode steps: 1949, steps per second: 523, episode reward: 501.700, mean reward: 0.257 [-102.000, 133.900], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.088985, mean_absolute_error: 1.984663, mean_q: -0.013813\n",
      "[-0.78158766  0.8596312 ]\n",
      "[-1.4381785  0.5149403]\n",
      "[0.04284123 1.2761352 ]\n",
      "[-0.91309553  1.7127203 ]\n",
      "[-0.39719072  1.3288434 ]\n",
      "[27518, 586417]\n",
      "  613935/1500000: episode: 315, duration: 4.408s, episode steps: 1949, steps per second: 442, episode reward: 628.800, mean reward: 0.323 [-148.500, 222.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 62.703278, mean_absolute_error: 2.128590, mean_q: -0.014103\n",
      "[-0.9368042  1.3501607]\n",
      "[-0.37447736  1.3758309 ]\n",
      "[-0.6379123  2.2261465]\n",
      "[-1.2781736  2.2042556]\n",
      "[-0.88940585  1.6811256 ]\n",
      "[27599, 588285]\n",
      "  615884/1500000: episode: 316, duration: 3.872s, episode steps: 1949, steps per second: 503, episode reward: 567.000, mean reward: 0.291 [-107.100, 178.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.246851, mean_absolute_error: 1.446029, mean_q: -0.014444\n",
      "[-0.74435323  0.44796726]\n",
      "[-1.0113759  1.2262044]\n",
      "[-1.9387114  1.61514  ]\n",
      "[-0.83545583  2.0117989 ]\n",
      "[-1.1984321  1.9510632]\n",
      "[27668, 590165]\n",
      "  617833/1500000: episode: 317, duration: 3.432s, episode steps: 1949, steps per second: 568, episode reward: 499.800, mean reward: 0.256 [-114.700, 116.600], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.452400, mean_absolute_error: 1.763395, mean_q: -0.014817\n",
      "[-1.4175082  1.6504194]\n",
      "[-0.40443194  0.9441806 ]\n",
      "[-0.4078437  1.0557797]\n",
      "[-0.86408985  1.4352475 ]\n",
      "[-1.0017033  0.8162958]\n",
      "[27752, 592030]\n",
      "  619782/1500000: episode: 318, duration: 3.761s, episode steps: 1949, steps per second: 518, episode reward: 549.000, mean reward: 0.282 [-75.500, 209.100], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.654682, mean_absolute_error: 1.899194, mean_q: -0.015300\n",
      "[-1.1332867  1.2491143]\n",
      "[-1.5354599  1.3035078]\n",
      "[-0.9955105  1.851192 ]\n",
      "[-0.85755503  1.0565803 ]\n",
      "[-0.89583105  0.7981635 ]\n",
      "[27829, 593902]\n",
      "  621731/1500000: episode: 319, duration: 3.292s, episode steps: 1949, steps per second: 592, episode reward: 418.700, mean reward: 0.215 [-90.700, 166.900], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.038750, mean_absolute_error: 1.952000, mean_q: -0.016018\n",
      "[-1.2983711  0.8154914]\n",
      "[-0.1254695  1.7714018]\n",
      "[-0.0572559  1.7881782]\n",
      "[-0.42084596  1.6418705 ]\n",
      "[-0.12651889  1.324522  ]\n",
      "[27914, 595766]\n",
      "  623680/1500000: episode: 320, duration: 3.065s, episode steps: 1949, steps per second: 636, episode reward: 202.000, mean reward: 0.104 [-134.300, 183.500], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.035316, mean_absolute_error: 1.695135, mean_q: -0.016931\n",
      "[-0.64116246  1.5022447 ]\n",
      "[-1.1799855  1.19985  ]\n",
      "[-1.4444686  1.0536505]\n",
      "[-0.9380595  1.0043395]\n",
      "[-0.5909476   0.58328027]\n",
      "[27997, 597632]\n",
      "  625629/1500000: episode: 321, duration: 3.253s, episode steps: 1949, steps per second: 599, episode reward: 728.500, mean reward: 0.374 [-133.500, 154.300], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.880154, mean_absolute_error: 1.800306, mean_q: -0.017754\n",
      "[-0.5036017  1.1195961]\n",
      "[-0.8208213   0.93274283]\n",
      "[-1.4601278  0.4762195]\n",
      "[-1.3200709  1.120737 ]\n",
      "[28064, 599514]\n",
      "  627578/1500000: episode: 322, duration: 3.017s, episode steps: 1949, steps per second: 646, episode reward: 339.000, mean reward: 0.174 [-128.000, 206.300], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.079884, mean_absolute_error: 1.862899, mean_q: -0.018274\n",
      "[-0.954532   0.9892885]\n",
      "[-0.6621485  1.0368276]\n",
      "[-0.88625824  1.3941166 ]\n",
      "[-1.5402406  1.0026101]\n",
      "[-0.9882591  1.3220265]\n",
      "[28158, 601369]\n",
      "  629527/1500000: episode: 323, duration: 2.923s, episode steps: 1949, steps per second: 667, episode reward: 830.200, mean reward: 0.426 [-68.300, 213.800], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.517822, mean_absolute_error: 2.116339, mean_q: -0.018953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9703182  0.7761787]\n",
      "[-0.6186741  1.354098 ]\n",
      "[-0.8807828  1.5724543]\n",
      "[-0.8695407  1.0303494]\n",
      "[-0.92874026  0.9832207 ]\n",
      "[28254, 603222]\n",
      "  631476/1500000: episode: 324, duration: 3.059s, episode steps: 1949, steps per second: 637, episode reward: 974.500, mean reward: 0.500 [-116.800, 181.000], mean action: 0.951 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.676212, mean_absolute_error: 2.313907, mean_q: -0.019706\n",
      "[-1.2553992  0.8529304]\n",
      "[-0.9072144  1.4490812]\n",
      "[-1.4587531  0.1384944]\n",
      "[-0.76261455  1.0970778 ]\n",
      "[-0.34682193  1.2497855 ]\n",
      "[28332, 605093]\n",
      "  633425/1500000: episode: 325, duration: 3.116s, episode steps: 1949, steps per second: 625, episode reward: 666.100, mean reward: 0.342 [-102.800, 147.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.175373, mean_absolute_error: 2.048208, mean_q: -0.020314\n",
      "[-0.7327193  1.578205 ]\n",
      "[-0.47980118  1.5411596 ]\n",
      "[-0.7243351  1.3774794]\n",
      "[-0.61195105  1.1941783 ]\n",
      "[-0.4363018  1.1910865]\n",
      "[28417, 606957]\n",
      "  635374/1500000: episode: 326, duration: 3.424s, episode steps: 1949, steps per second: 569, episode reward: 597.400, mean reward: 0.307 [-107.800, 177.900], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.389355, mean_absolute_error: 2.066045, mean_q: -0.020939\n",
      "[-0.43273902  0.52582425]\n",
      "[-0.9784126  1.0622014]\n",
      "[-0.39927253  1.6414392 ]\n",
      "[-1.1184042  1.521461 ]\n",
      "[-4.2092492e-04  1.6019709e+00]\n",
      "[28478, 608845]\n",
      "  637323/1500000: episode: 327, duration: 3.601s, episode steps: 1949, steps per second: 541, episode reward: 75.100, mean reward: 0.039 [-99.400, 153.800], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.040112, mean_absolute_error: 1.875550, mean_q: -0.021491\n",
      "[-1.0496353   0.74511474]\n",
      "[-0.6096601  1.2275653]\n",
      "[-0.6159546  1.433231 ]\n",
      "[-0.18834601  1.0423708 ]\n",
      "[-0.7039965  1.7706268]\n",
      "[28555, 610717]\n",
      "  639272/1500000: episode: 328, duration: 3.737s, episode steps: 1949, steps per second: 521, episode reward: 662.000, mean reward: 0.340 [-77.600, 177.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 35.151257, mean_absolute_error: 1.676530, mean_q: -0.022137\n",
      "[-0.36402428  0.33405736]\n",
      "[-0.8852151  1.2853926]\n",
      "[-0.81376845  1.7469023 ]\n",
      "[-0.97785795  1.2441518 ]\n",
      "[-0.16287377  1.3460293 ]\n",
      "[28646, 612575]\n",
      "  641221/1500000: episode: 329, duration: 3.384s, episode steps: 1949, steps per second: 576, episode reward: 35.800, mean reward: 0.018 [-168.700, 124.900], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.182362, mean_absolute_error: 2.138084, mean_q: -0.022771\n",
      "[-0.88337845  0.9418458 ]\n",
      "[0.05915228 1.165296  ]\n",
      "[-0.62212986  1.3019218 ]\n",
      "[-0.57797897  0.7918676 ]\n",
      "[28723, 614447]\n",
      "  643170/1500000: episode: 330, duration: 3.404s, episode steps: 1949, steps per second: 572, episode reward: 373.400, mean reward: 0.192 [-134.600, 197.000], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.363277, mean_absolute_error: 1.982396, mean_q: -0.023417\n",
      "[-0.93323165  1.0074658 ]\n",
      "[-0.51791435  1.3567919 ]\n",
      "[-0.69109154  0.9797183 ]\n",
      "[-0.97599334  1.1418099 ]\n",
      "[-0.6868161  1.5644568]\n",
      "[28787, 616332]\n",
      "  645119/1500000: episode: 331, duration: 3.657s, episode steps: 1949, steps per second: 533, episode reward: 607.400, mean reward: 0.312 [-190.900, 144.200], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.776402, mean_absolute_error: 1.838142, mean_q: -0.024127\n",
      "[-0.7157971  1.068752 ]\n",
      "[-0.5012222  1.060228 ]\n",
      "[-1.1989486  1.9695694]\n",
      "[-1.0356065  0.950165 ]\n",
      "[-1.1560509  1.1253282]\n",
      "[28869, 618199]\n",
      "  647068/1500000: episode: 332, duration: 3.482s, episode steps: 1949, steps per second: 560, episode reward: 431.700, mean reward: 0.221 [-82.900, 174.200], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 31.397045, mean_absolute_error: 1.523461, mean_q: -0.024974\n",
      "[-0.8140969  0.7753467]\n",
      "[-0.51389956  1.6421411 ]\n",
      "[-0.6656235  1.2907697]\n",
      "[-0.57662565  0.6313909 ]\n",
      "[-0.88265765  0.8774217 ]\n",
      "[28943, 620074]\n",
      "  649017/1500000: episode: 333, duration: 3.863s, episode steps: 1949, steps per second: 505, episode reward: 398.900, mean reward: 0.205 [-83.500, 190.100], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.877010, mean_absolute_error: 1.907212, mean_q: -0.025969\n",
      "[-0.81223637  1.2120697 ]\n",
      "[-0.76932365  0.9746375 ]\n",
      "[-0.9601161  1.4840317]\n",
      "[-0.5949002  1.057    ]\n",
      "[-0.291707   1.2137728]\n",
      "[29027, 621939]\n",
      "  650966/1500000: episode: 334, duration: 3.802s, episode steps: 1949, steps per second: 513, episode reward: 863.300, mean reward: 0.443 [-122.000, 205.200], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.908081, mean_absolute_error: 1.699147, mean_q: -0.026734\n",
      "[-1.120665  1.207551]\n",
      "[-0.8244018  0.8997709]\n",
      "[-0.73749155  0.45918548]\n",
      "[-0.18221202  1.1756499 ]\n",
      "[-0.7441921   0.96334887]\n",
      "[29108, 623807]\n",
      "  652915/1500000: episode: 335, duration: 3.869s, episode steps: 1949, steps per second: 504, episode reward: 524.900, mean reward: 0.269 [-199.200, 213.800], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.896790, mean_absolute_error: 2.231482, mean_q: -0.027389\n",
      "[-0.56064165  1.1821854 ]\n",
      "[-1.1249653  1.6918544]\n",
      "[-0.97304374  1.9941449 ]\n",
      "[-1.3247814  1.1696218]\n",
      "[-1.2261503  0.982969 ]\n",
      "[29186, 625678]\n",
      "  654864/1500000: episode: 336, duration: 3.624s, episode steps: 1949, steps per second: 538, episode reward: 317.000, mean reward: 0.163 [-96.800, 149.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.551376, mean_absolute_error: 1.855974, mean_q: -0.027954\n",
      "[-0.69786716  0.84878856]\n",
      "[-1.4103733  1.1060816]\n",
      "[-1.1312721  1.0188582]\n",
      "[-0.61003673  0.51686496]\n",
      "[-1.1732477  1.1901418]\n",
      "[29256, 627557]\n",
      "  656813/1500000: episode: 337, duration: 3.511s, episode steps: 1949, steps per second: 555, episode reward: 536.300, mean reward: 0.275 [-97.200, 188.200], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.882915, mean_absolute_error: 1.938691, mean_q: -0.028644\n",
      "[-1.1051474  1.4671391]\n",
      "[-1.2532649  0.9796391]\n",
      "[-0.7223706  1.3869   ]\n",
      "[-0.60363847  1.5507643 ]\n",
      "[29330, 629432]\n",
      "  658762/1500000: episode: 338, duration: 3.863s, episode steps: 1949, steps per second: 505, episode reward: 659.400, mean reward: 0.338 [-160.100, 204.700], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.414463, mean_absolute_error: 1.970738, mean_q: -0.029249\n",
      "[-0.99603206  0.9847614 ]\n",
      "[-0.721098   1.0942831]\n",
      "[-0.09236142  1.1249734 ]\n",
      "[-0.8121667  1.2473733]\n",
      "[-1.1558312   0.82549316]\n",
      "[29407, 631304]\n",
      "  660711/1500000: episode: 339, duration: 3.768s, episode steps: 1949, steps per second: 517, episode reward: -22.400, mean reward: -0.011 [-121.600, 138.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.439098, mean_absolute_error: 1.810116, mean_q: -0.029833\n",
      "[-1.2558528   0.90831196]\n",
      "[-0.8666063   0.37297124]\n",
      "[-0.8227988  1.0759535]\n",
      "[-1.4924449  1.4380039]\n",
      "[-0.6414099  1.5816196]\n",
      "[29503, 633157]\n",
      "  662660/1500000: episode: 340, duration: 4.001s, episode steps: 1949, steps per second: 487, episode reward: 470.100, mean reward: 0.241 [-84.300, 132.200], mean action: 0.951 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.268311, mean_absolute_error: 1.709529, mean_q: -0.030608\n",
      "[-1.7324744   0.87657917]\n",
      "[-0.8458724   0.48785916]\n",
      "[-0.9880397  1.3858796]\n",
      "[-1.234045   1.0023342]\n",
      "[-0.66492    1.7423993]\n",
      "[29583, 635026]\n",
      "  664609/1500000: episode: 341, duration: 3.716s, episode steps: 1949, steps per second: 524, episode reward: 354.000, mean reward: 0.182 [-186.200, 216.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.179398, mean_absolute_error: 1.831502, mean_q: -0.031439\n",
      "[-0.47599903  1.143274  ]\n",
      "[-1.1484641  0.8843763]\n",
      "[-0.92188835  0.79914665]\n",
      "[-1.20674    1.2340945]\n",
      "[-1.009416   1.6983238]\n",
      "[29666, 636892]\n",
      "  666558/1500000: episode: 342, duration: 3.625s, episode steps: 1949, steps per second: 538, episode reward: 144.600, mean reward: 0.074 [-111.400, 141.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.711903, mean_absolute_error: 1.907691, mean_q: -0.032084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5317802  1.0727515]\n",
      "[-0.33669883  0.6735224 ]\n",
      "[-0.22185704  1.0042493 ]\n",
      "[-0.9496105  1.0923536]\n",
      "[-0.5192132  1.1189419]\n",
      "[29747, 638760]\n",
      "  668507/1500000: episode: 343, duration: 3.377s, episode steps: 1949, steps per second: 577, episode reward: 445.400, mean reward: 0.229 [-141.800, 198.300], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.392410, mean_absolute_error: 1.878893, mean_q: -0.032680\n",
      "[-0.618461   1.1841404]\n",
      "[-1.3055218  1.3458128]\n",
      "[-0.8672899  1.0880665]\n",
      "[-0.5159933   0.69071096]\n",
      "[-0.25547755  0.48484692]\n",
      "[29838, 640618]\n",
      "  670456/1500000: episode: 344, duration: 3.352s, episode steps: 1949, steps per second: 581, episode reward: 787.200, mean reward: 0.404 [-91.600, 180.800], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.336983, mean_absolute_error: 2.108833, mean_q: -0.033219\n",
      "[-1.1632954  1.097219 ]\n",
      "[-0.8977039  1.7385591]\n",
      "[-1.0595129  1.2682264]\n",
      "[-0.43141916  1.2307731 ]\n",
      "[-0.82656074  1.7594514 ]\n",
      "[29923, 642482]\n",
      "  672405/1500000: episode: 345, duration: 3.275s, episode steps: 1949, steps per second: 595, episode reward: 455.800, mean reward: 0.234 [-130.900, 207.600], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.209965, mean_absolute_error: 1.686585, mean_q: -0.033292\n",
      "[-0.7959416  0.995633 ]\n",
      "[-0.18910006  1.2945888 ]\n",
      "[-1.4861809  1.5816218]\n",
      "[-1.5896796  1.1104786]\n",
      "[30012, 644342]\n",
      "  674354/1500000: episode: 346, duration: 3.581s, episode steps: 1949, steps per second: 544, episode reward: 405.300, mean reward: 0.208 [-93.100, 204.900], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.348927, mean_absolute_error: 1.931531, mean_q: -0.033154\n",
      "[-0.9289475  0.8619219]\n",
      "[-0.7114418  1.0074545]\n",
      "[-0.8298099  1.347714 ]\n",
      "[-0.8188049  1.306722 ]\n",
      "[-0.6386019  1.2173907]\n",
      "[30088, 646215]\n",
      "  676303/1500000: episode: 347, duration: 3.701s, episode steps: 1949, steps per second: 527, episode reward: 195.400, mean reward: 0.100 [-158.800, 152.100], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.885212, mean_absolute_error: 1.950981, mean_q: -0.033157\n",
      "[-0.7299606  0.7188752]\n",
      "[-1.5166582   0.89576846]\n",
      "[-1.0234698  1.0671905]\n",
      "[-1.18977    0.7097783]\n",
      "[-1.0714868  1.2454163]\n",
      "[30170, 648082]\n",
      "  678252/1500000: episode: 348, duration: 3.628s, episode steps: 1949, steps per second: 537, episode reward: 690.000, mean reward: 0.354 [-183.800, 155.300], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 31.786198, mean_absolute_error: 1.567493, mean_q: -0.033270\n",
      "[-0.83888626  1.404079  ]\n",
      "[-0.3787182  1.020044 ]\n",
      "[-1.5197319  1.7995666]\n",
      "[-1.1543392  1.6614306]\n",
      "[-1.117654   1.4957603]\n",
      "[30247, 649954]\n",
      "  680201/1500000: episode: 349, duration: 3.981s, episode steps: 1949, steps per second: 490, episode reward: 142.500, mean reward: 0.073 [-179.800, 95.700], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.204178, mean_absolute_error: 2.083090, mean_q: -0.033283\n",
      "[-0.5150179   0.86796546]\n",
      "[-0.2580303   0.59397525]\n",
      "[-0.5590924  1.0760264]\n",
      "[-1.065914   1.3223486]\n",
      "[-1.4478358  0.8640353]\n",
      "[30329, 651821]\n",
      "  682150/1500000: episode: 350, duration: 4.505s, episode steps: 1949, steps per second: 433, episode reward: 415.900, mean reward: 0.213 [-109.300, 137.200], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.834343, mean_absolute_error: 1.995394, mean_q: -0.033418\n",
      "[-0.6079142   0.30359703]\n",
      "[-0.30600095  0.36537436]\n",
      "[-0.4353586  0.937825 ]\n",
      "[-0.52138764  1.1737189 ]\n",
      "[-0.5572308   0.41154438]\n",
      "[30401, 653698]\n",
      "  684099/1500000: episode: 351, duration: 3.741s, episode steps: 1949, steps per second: 521, episode reward: 552.800, mean reward: 0.284 [-116.100, 138.900], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.294094, mean_absolute_error: 1.950760, mean_q: -0.033836\n",
      "[-1.2952322  1.3090924]\n",
      "[-1.5291075  1.7019777]\n",
      "[-0.9485166  1.0715176]\n",
      "[-0.826691   1.5288775]\n",
      "[-0.36284938  1.4268678 ]\n",
      "[30506, 655542]\n",
      "  686048/1500000: episode: 352, duration: 4.116s, episode steps: 1949, steps per second: 473, episode reward: 666.200, mean reward: 0.342 [-85.700, 158.900], mean action: 0.946 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.700600, mean_absolute_error: 1.846345, mean_q: -0.034124\n",
      "[0.17497598 0.7956928 ]\n",
      "[-0.9787836  1.5172257]\n",
      "[-0.69209516  1.1366946 ]\n",
      "[-1.0720992   0.63819104]\n",
      "[30577, 657420]\n",
      "  687997/1500000: episode: 353, duration: 3.596s, episode steps: 1949, steps per second: 542, episode reward: 191.600, mean reward: 0.098 [-131.100, 151.800], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.516357, mean_absolute_error: 1.618369, mean_q: -0.034517\n",
      "[-0.9489975  1.0282848]\n",
      "[-1.4725366  1.0450495]\n",
      "[-1.3797894  1.1183923]\n",
      "[-0.94524115  1.3256354 ]\n",
      "[-0.8616055  1.7361795]\n",
      "[30661, 659285]\n",
      "  689946/1500000: episode: 354, duration: 3.318s, episode steps: 1949, steps per second: 587, episode reward: 272.600, mean reward: 0.140 [-162.200, 242.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.881397, mean_absolute_error: 1.741470, mean_q: -0.034986\n",
      "[-0.7460044  0.9501884]\n",
      "[-1.1719514  1.0648386]\n",
      "[-0.4309488  0.8650796]\n",
      "[-0.33083826  1.795173  ]\n",
      "[-0.53648233  1.5943623 ]\n",
      "[30750, 661145]\n",
      "  691895/1500000: episode: 355, duration: 3.429s, episode steps: 1949, steps per second: 568, episode reward: 397.800, mean reward: 0.204 [-104.000, 161.200], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.603638, mean_absolute_error: 1.861363, mean_q: -0.035449\n",
      "[-0.69072187  1.0120183 ]\n",
      "[-0.53391725  1.0424683 ]\n",
      "[-0.53245765  0.79107493]\n",
      "[-1.2757229  1.6258273]\n",
      "[-1.1036031   0.86172575]\n",
      "[30834, 663010]\n",
      "  693844/1500000: episode: 356, duration: 3.294s, episode steps: 1949, steps per second: 592, episode reward: 236.400, mean reward: 0.121 [-123.600, 159.200], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.870232, mean_absolute_error: 2.182045, mean_q: -0.035764\n",
      "[-0.8945817  1.2787706]\n",
      "[-1.1508034  1.0476629]\n",
      "[-0.18059385  1.0329467 ]\n",
      "[-1.0822394  1.4182352]\n",
      "[-0.79094976  0.7839856 ]\n",
      "[30914, 664879]\n",
      "  695793/1500000: episode: 357, duration: 3.515s, episode steps: 1949, steps per second: 555, episode reward: 90.400, mean reward: 0.046 [-141.800, 160.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.822186, mean_absolute_error: 2.088040, mean_q: -0.036079\n",
      "[-0.41245124  1.3127301 ]\n",
      "[-1.4683497  1.2698407]\n",
      "[-1.4862084  0.8616403]\n",
      "[-1.2025797  1.451376 ]\n",
      "[-1.6916727  1.2762216]\n",
      "[31002, 666740]\n",
      "  697742/1500000: episode: 358, duration: 3.520s, episode steps: 1949, steps per second: 554, episode reward: 682.000, mean reward: 0.350 [-125.300, 205.200], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.947163, mean_absolute_error: 1.842575, mean_q: -0.036308\n",
      "[-1.1144927  0.9385568]\n",
      "[-1.2548519   0.88933414]\n",
      "[0.11531911 1.2490054 ]\n",
      "[-0.5182292  1.667985 ]\n",
      "[-0.6539674   0.60312307]\n",
      "[31082, 668609]\n",
      "  699691/1500000: episode: 359, duration: 3.460s, episode steps: 1949, steps per second: 563, episode reward: 817.800, mean reward: 0.420 [-89.700, 169.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.225155, mean_absolute_error: 1.799108, mean_q: -0.036722\n",
      "[-0.41034415  0.39087325]\n",
      "[-0.73874134  1.3061428 ]\n",
      "[-0.75094813  1.2569207 ]\n",
      "[-0.89780146  1.1782954 ]\n",
      "[-0.47943532  1.4546702 ]\n",
      "[31149, 670491]\n",
      "  701640/1500000: episode: 360, duration: 3.312s, episode steps: 1949, steps per second: 588, episode reward: 360.200, mean reward: 0.185 [-188.500, 157.000], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.142082, mean_absolute_error: 2.048009, mean_q: -0.037379\n",
      "[-0.9818907  0.680579 ]\n",
      "[-0.6789049  1.4895334]\n",
      "[-0.31991374  0.9776393 ]\n",
      "[-0.13261418  1.0127866 ]\n",
      "[31228, 672361]\n",
      "  703589/1500000: episode: 361, duration: 3.379s, episode steps: 1949, steps per second: 577, episode reward: 492.900, mean reward: 0.253 [-122.300, 196.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.343842, mean_absolute_error: 2.041747, mean_q: -0.038216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0716021   0.86550397]\n",
      "[-0.57422835  0.1045588 ]\n",
      "[-1.0739508  0.3224164]\n",
      "[-0.71920663  1.0145365 ]\n",
      "[-0.6457427   0.90732455]\n",
      "[31294, 674244]\n",
      "  705538/1500000: episode: 362, duration: 3.411s, episode steps: 1949, steps per second: 571, episode reward: 544.700, mean reward: 0.279 [-184.100, 167.900], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.872456, mean_absolute_error: 1.728941, mean_q: -0.039169\n",
      "[-0.95446754  1.0647794 ]\n",
      "[-0.9506202  1.5297794]\n",
      "[-1.265889    0.79494023]\n",
      "[-0.7357764  1.5430844]\n",
      "[-0.6843452  1.0919205]\n",
      "[31382, 676105]\n",
      "  707487/1500000: episode: 363, duration: 4.000s, episode steps: 1949, steps per second: 487, episode reward: 369.500, mean reward: 0.190 [-126.100, 201.000], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.252937, mean_absolute_error: 1.859365, mean_q: -0.040064\n",
      "[-1.5237308  1.0038339]\n",
      "[-1.1024747  0.9361952]\n",
      "[-1.059264    0.28652236]\n",
      "[-1.2712762  1.4426585]\n",
      "[-0.8134182  1.833975 ]\n",
      "[31446, 677990]\n",
      "  709436/1500000: episode: 364, duration: 3.896s, episode steps: 1949, steps per second: 500, episode reward: 593.100, mean reward: 0.304 [-83.400, 138.700], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.196541, mean_absolute_error: 1.893734, mean_q: -0.041029\n",
      "[-0.17540231  1.2905378 ]\n",
      "[-1.058138   1.0680692]\n",
      "[-1.4233578  1.4594686]\n",
      "[-1.1209168  1.3717766]\n",
      "[-0.13329723  1.46518   ]\n",
      "[31523, 679862]\n",
      "  711385/1500000: episode: 365, duration: 4.122s, episode steps: 1949, steps per second: 473, episode reward: 470.300, mean reward: 0.241 [-121.500, 127.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.642998, mean_absolute_error: 1.979689, mean_q: -0.042139\n",
      "[-0.9350707  1.0211813]\n",
      "[-1.0352201  1.3884991]\n",
      "[-1.1379608  1.1471684]\n",
      "[-0.73180753  1.1012914 ]\n",
      "[-0.5863159  1.1267829]\n",
      "[31594, 681740]\n",
      "  713334/1500000: episode: 366, duration: 5.259s, episode steps: 1949, steps per second: 371, episode reward: 342.700, mean reward: 0.176 [-129.800, 236.500], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.196392, mean_absolute_error: 1.724043, mean_q: -0.043054\n",
      "[-1.0414956   0.41002813]\n",
      "[-1.2345879   0.89724064]\n",
      "[-1.1232194   0.69567406]\n",
      "[-0.5076325   0.63987255]\n",
      "[-0.8223735  0.8887813]\n",
      "[31673, 683610]\n",
      "  715283/1500000: episode: 367, duration: 4.908s, episode steps: 1949, steps per second: 397, episode reward: 273.500, mean reward: 0.140 [-105.100, 220.900], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 80.223572, mean_absolute_error: 2.349121, mean_q: -0.044062\n",
      "[-0.6573936   0.67186064]\n",
      "[-0.65370166  1.1900195 ]\n",
      "[-0.34154975  0.87765217]\n",
      "[-0.26662922  0.9714399 ]\n",
      "[-0.09500885  1.2140615 ]\n",
      "[31756, 685476]\n",
      "  717232/1500000: episode: 368, duration: 4.342s, episode steps: 1949, steps per second: 449, episode reward: 566.600, mean reward: 0.291 [-179.700, 116.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.638149, mean_absolute_error: 1.961180, mean_q: -0.044805\n",
      "[-1.3886644  0.5190535]\n",
      "[-1.118805   1.5077331]\n",
      "[-0.72899765  1.8684645 ]\n",
      "[-0.82763416  1.9033718 ]\n",
      "[31843, 687338]\n",
      "  719181/1500000: episode: 369, duration: 3.996s, episode steps: 1949, steps per second: 488, episode reward: 368.600, mean reward: 0.189 [-98.500, 144.300], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.709354, mean_absolute_error: 2.183655, mean_q: -0.045282\n",
      "[-1.0504893  1.0160171]\n",
      "[-1.316293   1.9553142]\n",
      "[-1.1773517  0.98262  ]\n",
      "[-1.3408988   0.70134044]\n",
      "[-0.9340766  1.1036105]\n",
      "[31937, 689193]\n",
      "  721130/1500000: episode: 370, duration: 4.873s, episode steps: 1949, steps per second: 400, episode reward: 493.600, mean reward: 0.253 [-112.100, 153.000], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.350475, mean_absolute_error: 1.994323, mean_q: -0.045669\n",
      "[-0.9667044  1.0551949]\n",
      "[-0.6894396  0.7648049]\n",
      "[-0.80575746  0.890709  ]\n",
      "[-0.88207674  1.902818  ]\n",
      "[-1.254683  1.103053]\n",
      "[32020, 691059]\n",
      "  723079/1500000: episode: 371, duration: 5.062s, episode steps: 1949, steps per second: 385, episode reward: 704.400, mean reward: 0.361 [-104.600, 151.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.962284, mean_absolute_error: 1.971303, mean_q: -0.046117\n",
      "[-1.5872799  1.0875678]\n",
      "[-1.1193047  1.9212885]\n",
      "[-0.6751881  1.4991221]\n",
      "[-1.2548604  2.1791484]\n",
      "[-1.2827486  1.2921338]\n",
      "[32099, 692929]\n",
      "  725028/1500000: episode: 372, duration: 4.112s, episode steps: 1949, steps per second: 474, episode reward: 644.100, mean reward: 0.330 [-87.200, 140.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.034710, mean_absolute_error: 2.155966, mean_q: -0.046720\n",
      "[-1.2122803   0.81601775]\n",
      "[-1.179566   1.2214915]\n",
      "[-1.0198406  1.1357368]\n",
      "[-0.17658922  1.0844399 ]\n",
      "[-0.6594405  1.9326149]\n",
      "[32170, 694807]\n",
      "  726977/1500000: episode: 373, duration: 4.560s, episode steps: 1949, steps per second: 427, episode reward: 437.500, mean reward: 0.224 [-209.200, 153.200], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.665657, mean_absolute_error: 2.268008, mean_q: -0.047253\n",
      "[-0.8538533  0.8571216]\n",
      "[-0.6665889   0.83759314]\n",
      "[-0.59381837  1.3195492 ]\n",
      "[-0.3633482  1.2229214]\n",
      "[-0.7529997   0.53486943]\n",
      "[32260, 696666]\n",
      "  728926/1500000: episode: 374, duration: 5.638s, episode steps: 1949, steps per second: 346, episode reward: 751.400, mean reward: 0.386 [-84.000, 142.900], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 24.829845, mean_absolute_error: 1.733842, mean_q: -0.047398\n",
      "[-0.98917365  0.98733175]\n",
      "[-1.0113926  1.8239937]\n",
      "[-0.4042712  1.9594493]\n",
      "[-0.39882332  0.59770113]\n",
      "[-1.2084242  1.6529089]\n",
      "[32339, 698536]\n",
      "  730875/1500000: episode: 375, duration: 4.573s, episode steps: 1949, steps per second: 426, episode reward: 640.900, mean reward: 0.329 [-82.600, 210.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.212360, mean_absolute_error: 2.280177, mean_q: -0.047773\n",
      "[-1.0401343  0.9993678]\n",
      "[-0.8497131   0.13886803]\n",
      "[-0.3608684   0.39370432]\n",
      "[-0.69721985  0.46969068]\n",
      "[-0.8311714   0.75818694]\n",
      "[32420, 700404]\n",
      "  732824/1500000: episode: 376, duration: 3.604s, episode steps: 1949, steps per second: 541, episode reward: 127.900, mean reward: 0.066 [-168.500, 156.300], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.179321, mean_absolute_error: 1.889283, mean_q: -0.048201\n",
      "[-0.80311006  1.3264916 ]\n",
      "[-1.3957584  1.4971063]\n",
      "[-1.5267959  1.0364   ]\n",
      "[-0.5992066   0.22724025]\n",
      "[32502, 702271]\n",
      "  734773/1500000: episode: 377, duration: 4.694s, episode steps: 1949, steps per second: 415, episode reward: 409.500, mean reward: 0.210 [-213.300, 212.500], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.277157, mean_absolute_error: 2.032474, mean_q: -0.048453\n",
      "[-0.97269136  1.1379216 ]\n",
      "[-0.63900423  1.4363316 ]\n",
      "[-0.71012396  1.6160489 ]\n",
      "[-0.7500718   0.57896596]\n",
      "[-0.7490462  0.8988875]\n",
      "[32568, 704154]\n",
      "  736722/1500000: episode: 378, duration: 4.411s, episode steps: 1949, steps per second: 442, episode reward: 285.600, mean reward: 0.147 [-118.500, 192.700], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 35.205982, mean_absolute_error: 1.801940, mean_q: -0.048579\n",
      "[-0.6912882  0.9543556]\n",
      "[-1.2042526  1.1773065]\n",
      "[-0.5990814  0.7885759]\n",
      "[-1.3399755  1.0601335]\n",
      "[-0.5854299   0.94880813]\n",
      "[32648, 706023]\n",
      "  738671/1500000: episode: 379, duration: 3.973s, episode steps: 1949, steps per second: 491, episode reward: 615.300, mean reward: 0.316 [-138.900, 143.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.228157, mean_absolute_error: 1.912209, mean_q: -0.048857\n",
      "[-0.64373577  0.90231144]\n",
      "[-0.4268587  1.3143181]\n",
      "[0.03237638 0.7059155 ]\n",
      "[-0.2639587  1.5297389]\n",
      "[-0.35783532  1.5759168 ]\n",
      "[32735, 707885]\n",
      "  740620/1500000: episode: 380, duration: 4.878s, episode steps: 1949, steps per second: 400, episode reward: 607.500, mean reward: 0.312 [-132.100, 159.400], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.913948, mean_absolute_error: 1.843141, mean_q: -0.049232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3265673  1.1650319]\n",
      "[-0.15795535  1.0814586 ]\n",
      "[-0.861488   1.4478208]\n",
      "[-0.8457767  1.5607203]\n",
      "[-0.7214885  1.3809519]\n",
      "[32804, 709765]\n",
      "  742569/1500000: episode: 381, duration: 4.501s, episode steps: 1949, steps per second: 433, episode reward: 529.300, mean reward: 0.272 [-122.600, 178.800], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 74.509377, mean_absolute_error: 2.494843, mean_q: -0.049876\n",
      "[-0.8306388  1.1771736]\n",
      "[-0.9303351  1.2644862]\n",
      "[-0.7342336  1.378566 ]\n",
      "[-0.6799848  1.0131319]\n",
      "[-0.9188263  1.4466382]\n",
      "[32868, 711650]\n",
      "  744518/1500000: episode: 382, duration: 5.485s, episode steps: 1949, steps per second: 355, episode reward: 527.900, mean reward: 0.271 [-191.500, 140.500], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.578457, mean_absolute_error: 2.065631, mean_q: -0.050280\n",
      "[-0.5645556  1.3163943]\n",
      "[-0.6956018  1.0013602]\n",
      "[-0.83879673  1.1182584 ]\n",
      "[-0.69908524  1.3960422 ]\n",
      "[-1.350501    0.73789275]\n",
      "[32944, 713523]\n",
      "  746467/1500000: episode: 383, duration: 4.189s, episode steps: 1949, steps per second: 465, episode reward: 680.600, mean reward: 0.349 [-109.800, 186.300], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.526676, mean_absolute_error: 1.854394, mean_q: -0.050787\n",
      "[-1.4243013  1.0823302]\n",
      "[-1.1270196  1.4197804]\n",
      "[-1.2425249  1.4575331]\n",
      "[0.0098668 0.8982142]\n",
      "[0.29354078 1.111536  ]\n",
      "[33106, 715310]\n",
      "  748416/1500000: episode: 384, duration: 4.391s, episode steps: 1949, steps per second: 444, episode reward: 670.200, mean reward: 0.344 [-166.500, 178.600], mean action: 0.917 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.464489, mean_absolute_error: 1.714809, mean_q: -0.051383\n",
      "[-1.0137492  1.8393594]\n",
      "[-1.2218848  1.5581713]\n",
      "[-1.082833  1.9531  ]\n",
      "[-0.07981192  1.2166171 ]\n",
      "[33193, 717172]\n",
      "  750365/1500000: episode: 385, duration: 4.277s, episode steps: 1949, steps per second: 456, episode reward: 522.600, mean reward: 0.268 [-187.800, 130.400], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.287052, mean_absolute_error: 2.040795, mean_q: -0.052219\n",
      "[-1.1985164  1.045585 ]\n",
      "[-1.0466758  1.2850624]\n",
      "[-0.9178939  1.7264442]\n",
      "[-0.87891656  0.9746428 ]\n",
      "[0.11031865 0.7967984 ]\n",
      "[33270, 719044]\n",
      "  752314/1500000: episode: 386, duration: 3.848s, episode steps: 1949, steps per second: 506, episode reward: 525.900, mean reward: 0.270 [-151.700, 195.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.812286, mean_absolute_error: 2.073446, mean_q: -0.053215\n",
      "[-1.0149739  1.0393453]\n",
      "[-0.5738883  1.0319262]\n",
      "[-0.82193255  1.2045755 ]\n",
      "[-1.0701768  1.0319723]\n",
      "[-1.2292286  1.3452967]\n",
      "[33336, 720927]\n",
      "  754263/1500000: episode: 387, duration: 4.548s, episode steps: 1949, steps per second: 429, episode reward: 590.100, mean reward: 0.303 [-94.800, 227.000], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.548599, mean_absolute_error: 2.290947, mean_q: -0.053905\n",
      "[-0.89700896  1.100728  ]\n",
      "[-0.55750555  0.52898043]\n",
      "[-0.43525085  0.17185326]\n",
      "[-0.82319325  0.69510037]\n",
      "[-0.44362223  1.2026927 ]\n",
      "[33412, 722800]\n",
      "  756212/1500000: episode: 388, duration: 4.855s, episode steps: 1949, steps per second: 401, episode reward: 704.700, mean reward: 0.362 [-93.100, 157.100], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.790417, mean_absolute_error: 1.870260, mean_q: -0.054691\n",
      "[-1.0189757  1.4800978]\n",
      "[-1.074584   0.7237255]\n",
      "[-0.8687897  0.7105739]\n",
      "[-1.5080843  1.070068 ]\n",
      "[-1.040456   1.3675108]\n",
      "[33485, 724676]\n",
      "  758161/1500000: episode: 389, duration: 3.804s, episode steps: 1949, steps per second: 512, episode reward: 529.400, mean reward: 0.272 [-113.300, 189.300], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.754585, mean_absolute_error: 2.345411, mean_q: -0.055605\n",
      "[-1.1221939  0.7764853]\n",
      "[-0.8001051  1.100909 ]\n",
      "[-1.0611873  1.3335217]\n",
      "[-0.75504094  0.98191226]\n",
      "[-1.097335   1.3847184]\n",
      "[33578, 726532]\n",
      "  760110/1500000: episode: 390, duration: 4.088s, episode steps: 1949, steps per second: 477, episode reward: 767.800, mean reward: 0.394 [-97.800, 126.000], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 71.775520, mean_absolute_error: 2.424952, mean_q: -0.056516\n",
      "[-0.46357355  1.34235   ]\n",
      "[-1.3448644  1.1993135]\n",
      "[-1.1332654  0.9588013]\n",
      "[-1.5844661  1.1051755]\n",
      "[-1.215487   1.3198656]\n",
      "[33646, 728413]\n",
      "  762059/1500000: episode: 391, duration: 3.509s, episode steps: 1949, steps per second: 555, episode reward: 414.900, mean reward: 0.213 [-150.500, 147.600], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.771191, mean_absolute_error: 1.953836, mean_q: -0.057384\n",
      "[-1.1054418   0.81027985]\n",
      "[-0.53684187  0.9669923 ]\n",
      "[-1.2103786  0.6038127]\n",
      "[-1.2558367  1.4100424]\n",
      "[-1.33433     0.87117606]\n",
      "[33713, 730295]\n",
      "  764008/1500000: episode: 392, duration: 4.002s, episode steps: 1949, steps per second: 487, episode reward: 705.000, mean reward: 0.362 [-178.400, 176.400], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.327808, mean_absolute_error: 2.106464, mean_q: -0.058564\n",
      "[-0.9180396   0.92791843]\n",
      "[-0.6144664  1.0991038]\n",
      "[-0.98727405  1.4463308 ]\n",
      "[-0.37677094  1.6295072 ]\n",
      "[33785, 732172]\n",
      "  765957/1500000: episode: 393, duration: 4.392s, episode steps: 1949, steps per second: 444, episode reward: 669.100, mean reward: 0.343 [-115.900, 172.300], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 76.516167, mean_absolute_error: 2.511834, mean_q: -0.059778\n",
      "[-0.99139065  1.4957006 ]\n",
      "[-1.0116223  1.5666373]\n",
      "[-0.39181414  1.2200395 ]\n",
      "[-0.78229785  0.89090616]\n",
      "[-0.5250417  1.1941198]\n",
      "[33867, 734039]\n",
      "  767906/1500000: episode: 394, duration: 3.224s, episode steps: 1949, steps per second: 605, episode reward: 549.200, mean reward: 0.282 [-114.000, 173.500], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.603912, mean_absolute_error: 2.087174, mean_q: -0.060747\n",
      "[-0.9771572   0.93620306]\n",
      "[-0.6507035  1.0067892]\n",
      "[-0.92579746  0.94095665]\n",
      "[-1.1458055   0.62912625]\n",
      "[-0.21360323  0.98602074]\n",
      "[33950, 735905]\n",
      "  769855/1500000: episode: 395, duration: 3.356s, episode steps: 1949, steps per second: 581, episode reward: 403.500, mean reward: 0.207 [-81.500, 120.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.799622, mean_absolute_error: 2.346720, mean_q: -0.061708\n",
      "[-1.0844913  1.00362  ]\n",
      "[-1.3345411  1.731715 ]\n",
      "[-0.7075309  1.3067188]\n",
      "[-0.3978386  1.1989259]\n",
      "[-0.6664727  1.746105 ]\n",
      "[34043, 737761]\n",
      "  771804/1500000: episode: 396, duration: 3.407s, episode steps: 1949, steps per second: 572, episode reward: 166.900, mean reward: 0.086 [-168.700, 197.700], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.100880, mean_absolute_error: 2.170840, mean_q: -0.062495\n",
      "[-1.1101977  1.1039681]\n",
      "[-1.4852749  0.9169742]\n",
      "[-1.1821142   0.48339105]\n",
      "[-0.90597934  1.0817933 ]\n",
      "[-0.6869649  1.5714914]\n",
      "[34123, 739630]\n",
      "  773753/1500000: episode: 397, duration: 4.217s, episode steps: 1949, steps per second: 462, episode reward: 159.600, mean reward: 0.082 [-93.300, 180.900], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.233246, mean_absolute_error: 2.048350, mean_q: -0.063165\n",
      "[-1.1334176  0.6124963]\n",
      "[-0.42320627  1.3537731 ]\n",
      "[-0.67505246  0.7091386 ]\n",
      "[-0.6158274  0.5605748]\n",
      "[-1.1418968  1.0878739]\n",
      "[34198, 741504]\n",
      "  775702/1500000: episode: 398, duration: 4.375s, episode steps: 1949, steps per second: 446, episode reward: 399.000, mean reward: 0.205 [-83.300, 206.300], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.378922, mean_absolute_error: 2.289906, mean_q: -0.063785\n",
      "[-0.4972116  1.2087878]\n",
      "[-0.3113317  1.7072246]\n",
      "[-0.47517946  1.5508003 ]\n",
      "[-0.60986716  1.4979995 ]\n",
      "[-0.5880765  1.0780613]\n",
      "[34261, 743390]\n",
      "  777651/1500000: episode: 399, duration: 3.095s, episode steps: 1949, steps per second: 630, episode reward: 390.300, mean reward: 0.200 [-86.000, 194.000], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.289185, mean_absolute_error: 1.911693, mean_q: -0.064455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31662023  1.3684491 ]\n",
      "[-0.568496   0.7004584]\n",
      "[-0.66950005  0.54464406]\n",
      "[-1.1557152  1.0886422]\n",
      "[34340, 745260]\n",
      "[-1.1274195  0.9043399]\n",
      "  779600/1500000: episode: 400, duration: 4.644s, episode steps: 1949, steps per second: 420, episode reward: 100.500, mean reward: 0.052 [-84.300, 152.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.814651, mean_absolute_error: 1.899488, mean_q: -0.065019\n",
      "[-0.7748904  1.4147954]\n",
      "[-1.1641233  0.8106592]\n",
      "[-0.7344903   0.57014465]\n",
      "[-0.73257273  1.1871372 ]\n",
      "[34427, 747122]\n",
      "  781549/1500000: episode: 401, duration: 3.666s, episode steps: 1949, steps per second: 532, episode reward: 457.200, mean reward: 0.235 [-66.100, 157.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.384739, mean_absolute_error: 2.065498, mean_q: -0.065595\n",
      "[-1.257318    0.98308027]\n",
      "[-0.9086442  1.1969938]\n",
      "[-1.2482609  1.3845462]\n",
      "[-0.9915748  1.4109789]\n",
      "[-0.10910094  1.0261575 ]\n",
      "[34507, 748991]\n",
      "  783498/1500000: episode: 402, duration: 4.043s, episode steps: 1949, steps per second: 482, episode reward: 86.700, mean reward: 0.044 [-134.600, 91.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.306107, mean_absolute_error: 2.213970, mean_q: -0.066366\n",
      "[-0.8975943   0.99495625]\n",
      "[-1.4480621  0.6860167]\n",
      "[-0.1337908   0.71866894]\n",
      "[-1.0910164   0.95109415]\n",
      "[-1.015744   1.1837385]\n",
      "[34592, 750855]\n",
      "  785447/1500000: episode: 403, duration: 4.429s, episode steps: 1949, steps per second: 440, episode reward: 338.300, mean reward: 0.174 [-122.600, 197.100], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.936741, mean_absolute_error: 1.821258, mean_q: -0.067155\n",
      "[-0.65801513  1.1959696 ]\n",
      "[-1.1697366  1.2672329]\n",
      "[-0.6557943  1.5939586]\n",
      "[-0.6705558   0.97671753]\n",
      "[-0.1980995  1.2274102]\n",
      "[34673, 752723]\n",
      "  787396/1500000: episode: 404, duration: 4.492s, episode steps: 1949, steps per second: 434, episode reward: 514.500, mean reward: 0.264 [-127.400, 221.900], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.700825, mean_absolute_error: 2.089474, mean_q: -0.068132\n",
      "[-0.83432037  0.9744388 ]\n",
      "[-1.0704789  1.1541   ]\n",
      "[-0.24409777  1.5949166 ]\n",
      "[-0.71304715  1.0722575 ]\n",
      "[-0.44000468  1.7217985 ]\n",
      "[34752, 754593]\n",
      "  789345/1500000: episode: 405, duration: 3.223s, episode steps: 1949, steps per second: 605, episode reward: -24.000, mean reward: -0.012 [-168.700, 138.600], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.597393, mean_absolute_error: 1.699999, mean_q: -0.069056\n",
      "[-0.96015865  0.7539913 ]\n",
      "[-0.6330222   0.87744117]\n",
      "[-0.29033875  1.1304989 ]\n",
      "[-0.49948648  1.278758  ]\n",
      "[-0.46347904  1.6642761 ]\n",
      "[34827, 756467]\n",
      "  791294/1500000: episode: 406, duration: 3.241s, episode steps: 1949, steps per second: 601, episode reward: 524.600, mean reward: 0.269 [-122.600, 205.700], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.625801, mean_absolute_error: 2.068022, mean_q: -0.069934\n",
      "[-0.6090295  0.8064688]\n",
      "[-0.8330288  1.4630909]\n",
      "[-0.86790425  1.3463252 ]\n",
      "[-0.83686566  0.8458706 ]\n",
      "[-0.8506319  0.7351269]\n",
      "[34904, 758339]\n",
      "  793243/1500000: episode: 407, duration: 3.164s, episode steps: 1949, steps per second: 616, episode reward: 278.900, mean reward: 0.143 [-129.000, 141.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.869240, mean_absolute_error: 2.018589, mean_q: -0.070976\n",
      "[-1.2718642   0.92220116]\n",
      "[-0.77453953  1.4314148 ]\n",
      "[-1.2043654  1.269642 ]\n",
      "[-1.0113119  1.2644656]\n",
      "[34980, 760212]\n",
      "  795192/1500000: episode: 408, duration: 3.062s, episode steps: 1949, steps per second: 637, episode reward: 670.400, mean reward: 0.344 [-107.200, 219.500], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.004509, mean_absolute_error: 2.205933, mean_q: -0.072063\n",
      "[-0.7875362   0.91302145]\n",
      "[-0.6070008  0.9886769]\n",
      "[-1.1765262   0.22044736]\n",
      "[-1.090483    0.85263413]\n",
      "[-1.3733717  1.4783539]\n",
      "[35070, 762071]\n",
      "  797141/1500000: episode: 409, duration: 3.326s, episode steps: 1949, steps per second: 586, episode reward: 531.600, mean reward: 0.273 [-138.100, 181.700], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.569862, mean_absolute_error: 2.318132, mean_q: -0.073065\n",
      "[-0.62551296  1.019433  ]\n",
      "[-0.43732914  0.7844836 ]\n",
      "[-0.46053317  0.5677136 ]\n",
      "[-0.2920284  0.4535314]\n",
      "[-0.9470611  0.9362124]\n",
      "[35136, 763954]\n",
      "  799090/1500000: episode: 410, duration: 3.324s, episode steps: 1949, steps per second: 586, episode reward: 428.600, mean reward: 0.220 [-189.600, 174.700], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 71.086594, mean_absolute_error: 2.152481, mean_q: -0.073964\n",
      "[-0.5217505  1.119307 ]\n",
      "[-0.5617526  1.6777451]\n",
      "[-0.11847978  1.5677516 ]\n",
      "[-0.2837177  1.7100496]\n",
      "[-0.7546297  1.165124 ]\n",
      "[35209, 765830]\n",
      "  801039/1500000: episode: 411, duration: 3.980s, episode steps: 1949, steps per second: 490, episode reward: 876.000, mean reward: 0.449 [-109.300, 187.000], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 78.430496, mean_absolute_error: 2.403208, mean_q: -0.074703\n",
      "[-0.8387325  1.0105953]\n",
      "[-0.8180858   0.46374005]\n",
      "[-0.30006254  0.90266204]\n",
      "[-1.1711106  1.1960839]\n",
      "[-0.3595115  1.7444047]\n",
      "[35293, 767695]\n",
      "  802988/1500000: episode: 412, duration: 4.357s, episode steps: 1949, steps per second: 447, episode reward: 350.200, mean reward: 0.180 [-88.400, 164.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.813148, mean_absolute_error: 2.157395, mean_q: -0.075531\n",
      "[-1.2022855  1.2813396]\n",
      "[-1.1377149  1.0683819]\n",
      "[-1.1073037  1.5590601]\n",
      "[-0.86158824  0.8960221 ]\n",
      "[-0.29916474  0.9833124 ]\n",
      "[35358, 769579]\n",
      "  804937/1500000: episode: 413, duration: 4.636s, episode steps: 1949, steps per second: 420, episode reward: 628.200, mean reward: 0.322 [-68.500, 212.500], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.745495, mean_absolute_error: 2.079341, mean_q: -0.076489\n",
      "[-0.6997833  0.6310269]\n",
      "[-0.864944   0.9479745]\n",
      "[-1.0970885  1.6472515]\n",
      "[-1.7488004  1.2367483]\n",
      "[-1.0728507  0.9670195]\n",
      "[35432, 771454]\n",
      "  806886/1500000: episode: 414, duration: 5.123s, episode steps: 1949, steps per second: 380, episode reward: 735.600, mean reward: 0.377 [-135.600, 166.100], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 30.585451, mean_absolute_error: 1.735903, mean_q: -0.077747\n",
      "[-1.3593923  0.8659361]\n",
      "[-0.6370031   0.93742234]\n",
      "[-0.75971    0.9491094]\n",
      "[-0.9017585  1.1727195]\n",
      "[-0.9683854  1.2420602]\n",
      "[35509, 773326]\n",
      "  808835/1500000: episode: 415, duration: 3.728s, episode steps: 1949, steps per second: 523, episode reward: 358.400, mean reward: 0.184 [-81.600, 193.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.514114, mean_absolute_error: 1.839807, mean_q: -0.079089\n",
      "[-0.6162632  1.6794883]\n",
      "[-0.92596626  1.3401787 ]\n",
      "[-0.4494633  1.1802844]\n",
      "[-0.99022025  1.2420248 ]\n",
      "[35581, 775203]\n",
      "  810784/1500000: episode: 416, duration: 3.489s, episode steps: 1949, steps per second: 559, episode reward: 173.800, mean reward: 0.089 [-168.700, 173.500], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.030479, mean_absolute_error: 1.796910, mean_q: -0.080172\n",
      "[-1.081897   0.9474008]\n",
      "[-0.67814845  0.9635767 ]\n",
      "[-0.26944408  1.5100559 ]\n",
      "[-0.24886647  0.90096265]\n",
      "[-0.35967082  0.72193354]\n",
      "[35649, 777084]\n",
      "  812733/1500000: episode: 417, duration: 3.357s, episode steps: 1949, steps per second: 581, episode reward: 891.500, mean reward: 0.457 [-187.700, 166.900], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.156010, mean_absolute_error: 2.127436, mean_q: -0.081312\n",
      "[-0.59527284  1.1725267 ]\n",
      "[-0.3035786  1.2612497]\n",
      "[-0.9847637  1.3417628]\n",
      "[-1.8450052  1.6036416]\n",
      "[-0.22107914  1.62591   ]\n",
      "[35716, 778966]\n",
      "  814682/1500000: episode: 418, duration: 4.141s, episode steps: 1949, steps per second: 471, episode reward: 435.100, mean reward: 0.223 [-120.500, 217.800], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.280167, mean_absolute_error: 2.256917, mean_q: -0.082478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9356985  0.9319262]\n",
      "[-0.4020129  1.672583 ]\n",
      "[-0.6080437  1.7195809]\n",
      "[-0.1317626  1.4626288]\n",
      "[-0.05272229  0.9807562 ]\n",
      "[35793, 780838]\n",
      "  816631/1500000: episode: 419, duration: 3.879s, episode steps: 1949, steps per second: 502, episode reward: 782.800, mean reward: 0.402 [-113.400, 190.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.274910, mean_absolute_error: 2.185137, mean_q: -0.083648\n",
      "[-1.1386837  1.4914285]\n",
      "[-1.5564374   0.79418045]\n",
      "[-1.1541274  1.5522393]\n",
      "[-1.1438001  1.6001644]\n",
      "[-1.367564   1.7379746]\n",
      "[35882, 782698]\n",
      "  818580/1500000: episode: 420, duration: 3.893s, episode steps: 1949, steps per second: 501, episode reward: 401.900, mean reward: 0.206 [-143.400, 181.200], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.970703, mean_absolute_error: 2.389453, mean_q: -0.085035\n",
      "[-1.0190377  1.1157289]\n",
      "[-1.2550063  1.541414 ]\n",
      "[-1.5958207  1.1742913]\n",
      "[-0.62810034  0.9269746 ]\n",
      "[-0.6574082  1.1759307]\n",
      "[35970, 784559]\n",
      "  820529/1500000: episode: 421, duration: 4.182s, episode steps: 1949, steps per second: 466, episode reward: 552.000, mean reward: 0.283 [-94.000, 164.300], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.909847, mean_absolute_error: 2.118333, mean_q: -0.086372\n",
      "[-0.92361903  0.9941097 ]\n",
      "[-0.37212083  1.811734  ]\n",
      "[-0.6548228  1.975582 ]\n",
      "[-0.6452518  1.37745  ]\n",
      "[-1.2005664  1.3663526]\n",
      "[36043, 786435]\n",
      "  822478/1500000: episode: 422, duration: 3.845s, episode steps: 1949, steps per second: 507, episode reward: 637.400, mean reward: 0.327 [-88.600, 132.900], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.384270, mean_absolute_error: 2.304177, mean_q: -0.087764\n",
      "[-1.4050363   0.64899653]\n",
      "[-1.0071266   0.90024394]\n",
      "[-0.07633324  1.4729224 ]\n",
      "[-0.5359445  1.6567799]\n",
      "[-1.1276863  0.8961347]\n",
      "[36113, 788314]\n",
      "  824427/1500000: episode: 423, duration: 3.835s, episode steps: 1949, steps per second: 508, episode reward: 142.800, mean reward: 0.073 [-100.500, 180.100], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.436813, mean_absolute_error: 2.228591, mean_q: -0.088944\n",
      "[-0.78316975  1.2415516 ]\n",
      "[-0.5417303   0.96780246]\n",
      "[-0.8702746  1.317581 ]\n",
      "[-0.47011304  0.85205615]\n",
      "[36192, 790184]\n",
      "  826376/1500000: episode: 424, duration: 3.908s, episode steps: 1949, steps per second: 499, episode reward: 490.400, mean reward: 0.252 [-90.200, 161.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.977169, mean_absolute_error: 2.011348, mean_q: -0.090284\n",
      "[-1.1231081  1.1239407]\n",
      "[-1.3376342  1.5474136]\n",
      "[-1.7065535  1.9228055]\n",
      "[-0.67246884  1.6897    ]\n",
      "[-0.8430129  1.4360076]\n",
      "[36264, 792061]\n",
      "  828325/1500000: episode: 425, duration: 3.613s, episode steps: 1949, steps per second: 539, episode reward: 223.800, mean reward: 0.115 [-124.000, 198.300], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.669338, mean_absolute_error: 1.857697, mean_q: -0.091693\n",
      "[-0.6297719  0.9307698]\n",
      "[-1.0664794  1.8621912]\n",
      "[-1.1129293  1.5275904]\n",
      "[-1.5825857  1.2805508]\n",
      "[-1.00523    1.0702704]\n",
      "[36343, 793931]\n",
      "  830274/1500000: episode: 426, duration: 3.443s, episode steps: 1949, steps per second: 566, episode reward: 685.800, mean reward: 0.352 [-104.500, 164.300], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.472450, mean_absolute_error: 1.975716, mean_q: -0.093098\n",
      "[-1.3208829  0.50748  ]\n",
      "[-1.1850424  0.9465419]\n",
      "[-0.48357055  0.86275774]\n",
      "[-1.2513968  1.0720049]\n",
      "[-1.4015192  1.6399243]\n",
      "[36419, 795804]\n",
      "  832223/1500000: episode: 427, duration: 3.415s, episode steps: 1949, steps per second: 571, episode reward: 693.900, mean reward: 0.356 [-169.100, 164.700], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.789631, mean_absolute_error: 1.972114, mean_q: -0.094639\n",
      "[-0.9097081  0.9540636]\n",
      "[-1.0385889  1.0721068]\n",
      "[-0.7671668  0.6308316]\n",
      "[-0.54180443  0.6798991 ]\n",
      "[-0.40857932  1.2968141 ]\n",
      "[36485, 797687]\n",
      "  834172/1500000: episode: 428, duration: 3.367s, episode steps: 1949, steps per second: 579, episode reward: 538.200, mean reward: 0.276 [-139.400, 180.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.954334, mean_absolute_error: 1.859920, mean_q: -0.096136\n",
      "[-0.95654666  1.5241538 ]\n",
      "[-0.82983834  1.2190534 ]\n",
      "[-0.92710483  0.8345213 ]\n",
      "[-0.8883579  1.343205 ]\n",
      "[-1.4394997   0.92668253]\n",
      "[36569, 799552]\n",
      "  836121/1500000: episode: 429, duration: 3.401s, episode steps: 1949, steps per second: 573, episode reward: 627.600, mean reward: 0.322 [-114.200, 156.700], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 68.227051, mean_absolute_error: 2.122597, mean_q: -0.097572\n",
      "[0.30573407 1.5549103 ]\n",
      "[-0.4102327  1.4907264]\n",
      "[-0.118449  0.899064]\n",
      "[-0.5301608  1.22524  ]\n",
      "[-0.785631   1.3632051]\n",
      "[36652, 801418]\n",
      "  838070/1500000: episode: 430, duration: 3.365s, episode steps: 1949, steps per second: 579, episode reward: 678.200, mean reward: 0.348 [-169.700, 162.300], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 71.211357, mean_absolute_error: 2.315798, mean_q: -0.098696\n",
      "[-1.1797308   0.95138127]\n",
      "[-1.0741069  1.1555351]\n",
      "[-0.02846323  0.66585165]\n",
      "[-0.30513117  1.1980653 ]\n",
      "[-1.2814184  1.0609318]\n",
      "[36737, 803282]\n",
      "  840019/1500000: episode: 431, duration: 4.097s, episode steps: 1949, steps per second: 476, episode reward: 391.200, mean reward: 0.201 [-92.800, 145.000], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.738602, mean_absolute_error: 2.077763, mean_q: -0.099558\n",
      "[-0.69631857  1.8413886 ]\n",
      "[-0.51860195  1.070963  ]\n",
      "[-1.1071681  1.2582666]\n",
      "[-0.30629987  1.3003796 ]\n",
      "[36805, 805163]\n",
      "  841968/1500000: episode: 432, duration: 3.802s, episode steps: 1949, steps per second: 513, episode reward: 667.000, mean reward: 0.342 [-112.500, 225.600], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.459980, mean_absolute_error: 1.976439, mean_q: -0.100391\n",
      "[-1.0212823  0.8826327]\n",
      "[-0.93198943  1.0506591 ]\n",
      "[-0.51202744  1.2411046 ]\n",
      "[-0.1150326   0.95783335]\n",
      "[-0.72977096  1.6181128 ]\n",
      "[36878, 807039]\n",
      "  843917/1500000: episode: 433, duration: 4.751s, episode steps: 1949, steps per second: 410, episode reward: 697.400, mean reward: 0.358 [-126.500, 210.400], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 35.422348, mean_absolute_error: 1.742825, mean_q: -0.101273\n",
      "[-1.1389091  1.3626173]\n",
      "[-0.84678686  1.5143006 ]\n",
      "[-1.2899853  0.8142221]\n",
      "[-0.56529504  1.01103   ]\n",
      "[-0.8424759  1.4506879]\n",
      "[36955, 808911]\n",
      "  845866/1500000: episode: 434, duration: 4.743s, episode steps: 1949, steps per second: 411, episode reward: 613.100, mean reward: 0.315 [-106.100, 137.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.601025, mean_absolute_error: 1.975790, mean_q: -0.102442\n",
      "[-1.093469   1.6166177]\n",
      "[-1.2947319  0.9608974]\n",
      "[-0.47919482  0.9553002 ]\n",
      "[-1.539358   0.9086236]\n",
      "[-1.2978423  1.2596366]\n",
      "[37021, 810794]\n",
      "  847815/1500000: episode: 435, duration: 4.032s, episode steps: 1949, steps per second: 483, episode reward: 735.600, mean reward: 0.377 [-75.400, 177.500], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.066654, mean_absolute_error: 1.873791, mean_q: -0.104101\n",
      "[-0.5472826  1.3454928]\n",
      "[-0.97777003  0.47353822]\n",
      "[-1.191917   1.1055311]\n",
      "[-1.1797903  1.4627122]\n",
      "[-0.8865719  1.0889714]\n",
      "[37104, 812660]\n",
      "  849764/1500000: episode: 436, duration: 3.816s, episode steps: 1949, steps per second: 511, episode reward: 397.100, mean reward: 0.204 [-112.400, 125.400], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.276371, mean_absolute_error: 2.144759, mean_q: -0.105706\n",
      "[-0.98203456  0.6651979 ]\n",
      "[-1.1058416  0.7921229]\n",
      "[-0.7818673  0.8796473]\n",
      "[-1.155165   1.2251906]\n",
      "[-1.1225964   0.41293117]\n",
      "[37179, 814534]\n",
      "  851713/1500000: episode: 437, duration: 3.369s, episode steps: 1949, steps per second: 578, episode reward: 648.900, mean reward: 0.333 [-97.800, 164.300], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.337826, mean_absolute_error: 2.227638, mean_q: -0.107297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5850308   0.76553005]\n",
      "[-1.0610147  0.9587198]\n",
      "[-0.68244964  0.8852112 ]\n",
      "[-0.29426414  0.66925067]\n",
      "[-0.6445574  1.3904555]\n",
      "[37250, 816412]\n",
      "  853662/1500000: episode: 438, duration: 3.999s, episode steps: 1949, steps per second: 487, episode reward: 400.800, mean reward: 0.206 [-126.000, 154.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.627949, mean_absolute_error: 1.618576, mean_q: -0.108933\n",
      "[-0.917404   1.5514534]\n",
      "[-1.4707903  1.3883327]\n",
      "[-0.92864335  1.0899595 ]\n",
      "[-0.39472398  2.041912  ]\n",
      "[-0.45132214  1.237168  ]\n",
      "[37326, 818285]\n",
      "  855611/1500000: episode: 439, duration: 4.145s, episode steps: 1949, steps per second: 470, episode reward: 463.400, mean reward: 0.238 [-86.200, 111.600], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 31.279785, mean_absolute_error: 1.763426, mean_q: -0.110598\n",
      "[-0.9825824  0.8751323]\n",
      "[-1.234393   1.1162268]\n",
      "[-0.47479326  0.79715496]\n",
      "[-0.9010302  0.8201539]\n",
      "[37405, 820155]\n",
      "  857560/1500000: episode: 440, duration: 4.990s, episode steps: 1949, steps per second: 391, episode reward: 343.600, mean reward: 0.176 [-110.700, 186.300], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 87.515518, mean_absolute_error: 2.590545, mean_q: -0.111951\n",
      "[-1.1868868  1.3992562]\n",
      "[-1.407228  1.476663]\n",
      "[-1.1368448  1.3517046]\n",
      "[-0.8427138  2.0045989]\n",
      "[-1.0882382  1.7939969]\n",
      "[37492, 822017]\n",
      "  859509/1500000: episode: 441, duration: 4.048s, episode steps: 1949, steps per second: 481, episode reward: 470.700, mean reward: 0.242 [-158.300, 130.400], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 71.754013, mean_absolute_error: 2.273717, mean_q: -0.112793\n",
      "[-1.2288686  1.2904649]\n",
      "[-1.0163591  1.7611136]\n",
      "[-0.8604269  0.5678217]\n",
      "[-0.98337424  1.0957522 ]\n",
      "[-1.2212297  1.3655787]\n",
      "[37568, 823890]\n",
      "  861458/1500000: episode: 442, duration: 3.879s, episode steps: 1949, steps per second: 502, episode reward: 430.000, mean reward: 0.221 [-101.700, 205.600], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 32.686836, mean_absolute_error: 1.650639, mean_q: -0.113476\n",
      "[-0.95589346  1.2725849 ]\n",
      "[-0.8756011  1.6254307]\n",
      "[-0.5914321  1.2914679]\n",
      "[-0.43974155  1.0646514 ]\n",
      "[-0.9599157  1.0600755]\n",
      "[37651, 825756]\n",
      "  863407/1500000: episode: 443, duration: 3.464s, episode steps: 1949, steps per second: 563, episode reward: 708.000, mean reward: 0.363 [-83.500, 210.500], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.156239, mean_absolute_error: 1.855436, mean_q: -0.114382\n",
      "[-0.58246684  0.6919105 ]\n",
      "[-1.1408112  0.9517914]\n",
      "[-0.85599536  1.6053139 ]\n",
      "[-1.1245952  1.2388761]\n",
      "[-1.0371222  1.1588207]\n",
      "[37744, 827612]\n",
      "  865356/1500000: episode: 444, duration: 3.622s, episode steps: 1949, steps per second: 538, episode reward: 349.300, mean reward: 0.179 [-142.000, 121.900], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.592392, mean_absolute_error: 1.587696, mean_q: -0.115183\n",
      "[-0.98376733  1.2121302 ]\n",
      "[-1.0024165  1.3247609]\n",
      "[-0.8851344  1.0962055]\n",
      "[-0.9352228   0.98859566]\n",
      "[-0.9080055  1.1886332]\n",
      "[37826, 829479]\n",
      "  867305/1500000: episode: 445, duration: 3.573s, episode steps: 1949, steps per second: 545, episode reward: 419.700, mean reward: 0.215 [-74.500, 208.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.806538, mean_absolute_error: 1.913193, mean_q: -0.116182\n",
      "[-0.80557996  0.94006497]\n",
      "[-0.5244077  1.1577098]\n",
      "[-0.8822098  1.5621787]\n",
      "[-1.0959451   0.53951967]\n",
      "[-0.80219513  0.63727224]\n",
      "[37890, 831364]\n",
      "  869254/1500000: episode: 446, duration: 3.805s, episode steps: 1949, steps per second: 512, episode reward: 383.900, mean reward: 0.197 [-211.300, 230.800], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.810326, mean_absolute_error: 2.103172, mean_q: -0.117199\n",
      "[-0.9450451  1.2098676]\n",
      "[-0.7060618  1.0331146]\n",
      "[-0.6643238  0.6005451]\n",
      "[-1.2406929  1.0355114]\n",
      "[-0.87585324  0.7910292 ]\n",
      "[37954, 833249]\n",
      "  871203/1500000: episode: 447, duration: 3.752s, episode steps: 1949, steps per second: 519, episode reward: 551.100, mean reward: 0.283 [-110.400, 226.000], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.103992, mean_absolute_error: 2.025065, mean_q: -0.118226\n",
      "[-0.9800835  0.6059164]\n",
      "[-1.6574228  1.1556811]\n",
      "[-1.1112247   0.87351716]\n",
      "[-0.34988466  1.3789645 ]\n",
      "[38043, 835109]\n",
      "  873152/1500000: episode: 448, duration: 3.614s, episode steps: 1949, steps per second: 539, episode reward: 246.700, mean reward: 0.127 [-81.800, 142.600], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 28.900356, mean_absolute_error: 1.625688, mean_q: -0.119379\n",
      "[-0.8083694  1.0781522]\n",
      "[-1.0407968  0.8428397]\n",
      "[-0.8725855  0.7234787]\n",
      "[-0.7658418  0.684038 ]\n",
      "[-0.97223604  1.5823646 ]\n",
      "[38120, 836981]\n",
      "  875101/1500000: episode: 449, duration: 3.243s, episode steps: 1949, steps per second: 601, episode reward: 56.400, mean reward: 0.029 [-168.700, 105.000], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.772743, mean_absolute_error: 2.059699, mean_q: -0.120610\n",
      "[-0.96833885  1.8377241 ]\n",
      "[-0.36150253  1.2908397 ]\n",
      "[-0.06877018  0.81202227]\n",
      "[-1.0515356  1.1257576]\n",
      "[-0.5403881  1.0380137]\n",
      "[38202, 838848]\n",
      "  877050/1500000: episode: 450, duration: 3.480s, episode steps: 1949, steps per second: 560, episode reward: 207.400, mean reward: 0.106 [-126.000, 167.500], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.268288, mean_absolute_error: 2.023553, mean_q: -0.121870\n",
      "[-0.8082073  1.139773 ]\n",
      "[-0.49961826  0.96288943]\n",
      "[-0.53557134  1.372966  ]\n",
      "[-0.7828385  1.7100791]\n",
      "[-1.0329962  1.288173 ]\n",
      "[38279, 840720]\n",
      "  878999/1500000: episode: 451, duration: 3.198s, episode steps: 1949, steps per second: 609, episode reward: -264.200, mean reward: -0.136 [-168.700, 186.000], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.054161, mean_absolute_error: 2.302965, mean_q: -0.123381\n",
      "[-1.0538845  1.661577 ]\n",
      "[-0.7642078  2.7894077]\n",
      "[-0.7054862  1.7022398]\n",
      "[-0.4442106  1.1700209]\n",
      "[-0.6147743  1.3675516]\n",
      "[38363, 842585]\n",
      "  880948/1500000: episode: 452, duration: 3.059s, episode steps: 1949, steps per second: 637, episode reward: 479.200, mean reward: 0.246 [-107.800, 149.700], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.151070, mean_absolute_error: 2.071213, mean_q: -0.125225\n",
      "[-1.0013927  1.1638974]\n",
      "[-0.98423237  1.3140682 ]\n",
      "[-0.24690783  1.2157326 ]\n",
      "[-0.690282   1.9820429]\n",
      "[-0.5452332  1.7551141]\n",
      "[38450, 844447]\n",
      "  882897/1500000: episode: 453, duration: 3.801s, episode steps: 1949, steps per second: 513, episode reward: 672.100, mean reward: 0.345 [-101.700, 150.700], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.671803, mean_absolute_error: 1.756539, mean_q: -0.126963\n",
      "[-0.8510487  0.4839781]\n",
      "[-0.77879775  0.11927696]\n",
      "[-0.41059002  1.1921277 ]\n",
      "[-0.761527   1.5262206]\n",
      "[-0.7435545  1.9107046]\n",
      "[38533, 846313]\n",
      "  884846/1500000: episode: 454, duration: 3.350s, episode steps: 1949, steps per second: 582, episode reward: 537.800, mean reward: 0.276 [-109.900, 167.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.199821, mean_absolute_error: 1.965094, mean_q: -0.128741\n",
      "[-0.03524547  1.7110684 ]\n",
      "[-0.07335875  1.3831093 ]\n",
      "[-0.8257051  0.9942419]\n",
      "[-0.7322142  0.5560945]\n",
      "[38608, 848187]\n",
      "  886795/1500000: episode: 455, duration: 3.327s, episode steps: 1949, steps per second: 586, episode reward: 744.300, mean reward: 0.382 [-95.600, 319.900], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.171314, mean_absolute_error: 1.955562, mean_q: -0.130436\n",
      "[-1.0516534  0.8823254]\n",
      "[-0.94889915  1.3785086 ]\n",
      "[-1.5211554  1.212832 ]\n",
      "[-1.0336348  1.405667 ]\n",
      "[-0.37579942  2.1349938 ]\n",
      "[38684, 850060]\n",
      "  888744/1500000: episode: 456, duration: 3.272s, episode steps: 1949, steps per second: 596, episode reward: 401.800, mean reward: 0.206 [-106.000, 149.300], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 87.867996, mean_absolute_error: 2.531127, mean_q: -0.132175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6048418  1.0061055]\n",
      "[-0.0051228  1.2379264]\n",
      "[0.21450351 0.970185  ]\n",
      "[-0.56602514  0.6272727 ]\n",
      "[-1.1261706  0.9102624]\n",
      "[38755, 851938]\n",
      "  890693/1500000: episode: 457, duration: 3.181s, episode steps: 1949, steps per second: 613, episode reward: 658.000, mean reward: 0.338 [-95.500, 163.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 74.183174, mean_absolute_error: 2.331282, mean_q: -0.133653\n",
      "[-0.4186604  1.1012362]\n",
      "[-0.56243044  0.69189334]\n",
      "[-0.7754593  1.4102622]\n",
      "[-0.6981288  0.9341963]\n",
      "[-0.5708351   0.23360686]\n",
      "[38860, 853782]\n",
      "  892642/1500000: episode: 458, duration: 3.135s, episode steps: 1949, steps per second: 622, episode reward: 392.800, mean reward: 0.202 [-87.200, 120.000], mean action: 0.946 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 94.663338, mean_absolute_error: 2.879311, mean_q: -0.135006\n",
      "[-1.443901   1.0110692]\n",
      "[-0.7649027  0.9564786]\n",
      "[-1.338463   1.2205619]\n",
      "[-0.85221934  1.0053699 ]\n",
      "[-0.8387805  1.0501138]\n",
      "[38937, 855654]\n",
      "  894591/1500000: episode: 459, duration: 3.372s, episode steps: 1949, steps per second: 578, episode reward: 694.000, mean reward: 0.356 [-123.900, 155.600], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 72.198380, mean_absolute_error: 2.395790, mean_q: -0.136272\n",
      "[-0.6726256  1.487277 ]\n",
      "[-0.6680147  0.8778963]\n",
      "[-0.3957147   0.71342844]\n",
      "[-0.6774517  1.140256 ]\n",
      "[-1.3495119  1.8691372]\n",
      "[39015, 857525]\n",
      "  896540/1500000: episode: 460, duration: 3.401s, episode steps: 1949, steps per second: 573, episode reward: 337.200, mean reward: 0.173 [-96.700, 245.700], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.659500, mean_absolute_error: 1.679256, mean_q: -0.137423\n",
      "[-1.4870999  1.4029129]\n",
      "[-0.7452216  1.916395 ]\n",
      "[-1.0404031  1.6027577]\n",
      "[-0.74917614  1.1867459 ]\n",
      "[-0.15089689  0.6982633 ]\n",
      "[39101, 859388]\n",
      "  898489/1500000: episode: 461, duration: 3.362s, episode steps: 1949, steps per second: 580, episode reward: 572.500, mean reward: 0.294 [-135.500, 179.600], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.547852, mean_absolute_error: 1.880975, mean_q: -0.138630\n",
      "[-0.85380834  0.38956124]\n",
      "[-0.49440518  1.0608693 ]\n",
      "[-0.53796196  1.487626  ]\n",
      "[-0.55702746  1.8440182 ]\n",
      "[-0.6130103  1.5757887]\n",
      "[39181, 861257]\n",
      "  900438/1500000: episode: 462, duration: 3.317s, episode steps: 1949, steps per second: 587, episode reward: 76.500, mean reward: 0.039 [-93.300, 146.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 61.390713, mean_absolute_error: 2.210050, mean_q: -0.139982\n",
      "[-1.3382139  0.9877792]\n",
      "[-0.81993306  1.6141577 ]\n",
      "[-0.7930477  2.050054 ]\n",
      "[-0.7780486  1.5763249]\n",
      "[39259, 863128]\n",
      "  902387/1500000: episode: 463, duration: 3.485s, episode steps: 1949, steps per second: 559, episode reward: 874.200, mean reward: 0.449 [-125.300, 213.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.449390, mean_absolute_error: 1.848529, mean_q: -0.141098\n",
      "[-0.8137295   0.93919045]\n",
      "[-0.904395   0.5145214]\n",
      "[-0.9307488  1.5806298]\n",
      "[-0.92417306  1.5048598 ]\n",
      "[-0.51343817  1.0737343 ]\n",
      "[39335, 865001]\n",
      "  904336/1500000: episode: 464, duration: 3.506s, episode steps: 1949, steps per second: 556, episode reward: 825.000, mean reward: 0.423 [-184.500, 172.000], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.468052, mean_absolute_error: 2.107044, mean_q: -0.142092\n",
      "[-0.97227204  0.8328885 ]\n",
      "[-0.32429433  1.6657313 ]\n",
      "[-0.49821168  1.4938742 ]\n",
      "[-0.17783017  0.9690511 ]\n",
      "[-0.62676954  1.145294  ]\n",
      "[39427, 866858]\n",
      "  906285/1500000: episode: 465, duration: 3.225s, episode steps: 1949, steps per second: 604, episode reward: 192.100, mean reward: 0.099 [-196.900, 117.200], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.458683, mean_absolute_error: 1.957721, mean_q: -0.143038\n",
      "[-0.807475   1.0150021]\n",
      "[-0.955748   1.2402511]\n",
      "[-0.2724114  1.3212857]\n",
      "[-0.43649074  1.8721437 ]\n",
      "[-0.393272   1.4610167]\n",
      "[39498, 868736]\n",
      "  908234/1500000: episode: 466, duration: 3.369s, episode steps: 1949, steps per second: 578, episode reward: 628.400, mean reward: 0.322 [-156.300, 195.400], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.591858, mean_absolute_error: 2.158791, mean_q: -0.144089\n",
      "[-1.0356381  1.2773902]\n",
      "[-0.77840966  2.2775664 ]\n",
      "[-0.25157347  1.6734784 ]\n",
      "[-1.0250632   0.88045573]\n",
      "[-0.40634438  1.5444415 ]\n",
      "[39583, 870600]\n",
      "  910183/1500000: episode: 467, duration: 3.367s, episode steps: 1949, steps per second: 579, episode reward: 564.800, mean reward: 0.290 [-112.500, 195.100], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.611172, mean_absolute_error: 1.881970, mean_q: -0.144796\n",
      "[-1.5585434   0.43345606]\n",
      "[-1.4519614  0.9306182]\n",
      "[-1.0621854   0.78957266]\n",
      "[-0.555784  0.833566]\n",
      "[-0.5484693  1.1947376]\n",
      "[39664, 872468]\n",
      "  912132/1500000: episode: 468, duration: 3.282s, episode steps: 1949, steps per second: 594, episode reward: 550.800, mean reward: 0.283 [-93.400, 151.900], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.280148, mean_absolute_error: 1.930759, mean_q: -0.145452\n",
      "[-1.0626345  0.7136048]\n",
      "[-1.0201209   0.87924916]\n",
      "[-1.189578    0.67540634]\n",
      "[-1.1954894  1.4238181]\n",
      "[-0.8547095  0.8272689]\n",
      "[39740, 874341]\n",
      "  914081/1500000: episode: 469, duration: 3.489s, episode steps: 1949, steps per second: 559, episode reward: 528.500, mean reward: 0.271 [-159.300, 181.500], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.392452, mean_absolute_error: 2.157373, mean_q: -0.146189\n",
      "[-0.7061133  0.8521635]\n",
      "[-0.23075652  0.5398324 ]\n",
      "[-0.7122974  1.1604244]\n",
      "[-0.85622543  1.3656951 ]\n",
      "[-0.558667   1.3713759]\n",
      "[39820, 876210]\n",
      "  916030/1500000: episode: 470, duration: 3.383s, episode steps: 1949, steps per second: 576, episode reward: 158.100, mean reward: 0.081 [-112.500, 149.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.166107, mean_absolute_error: 2.093755, mean_q: -0.147318\n",
      "[-1.8290552  0.8429359]\n",
      "[-1.0059944  1.8665253]\n",
      "[-1.0020144  1.4672178]\n",
      "[-0.45233238  0.356651  ]\n",
      "[39890, 878089]\n",
      "  917979/1500000: episode: 471, duration: 3.315s, episode steps: 1949, steps per second: 588, episode reward: 322.800, mean reward: 0.166 [-105.100, 132.900], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.544937, mean_absolute_error: 1.924908, mean_q: -0.148889\n",
      "[-1.2582093  1.0680002]\n",
      "[-1.4666765  1.1811583]\n",
      "[-1.1824763  0.8832373]\n",
      "[-1.1892277  0.4416091]\n",
      "[-0.5869548  1.088673 ]\n",
      "[39966, 879962]\n",
      "  919928/1500000: episode: 472, duration: 3.533s, episode steps: 1949, steps per second: 552, episode reward: 615.700, mean reward: 0.316 [-108.500, 142.800], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.526394, mean_absolute_error: 2.128381, mean_q: -0.150588\n",
      "[-0.8358754  1.1866755]\n",
      "[-0.87753284  0.93820685]\n",
      "[-0.541592   1.1159368]\n",
      "[-1.2161212  0.8078658]\n",
      "[-1.0731983   0.94350207]\n",
      "[40056, 881821]\n",
      "  921877/1500000: episode: 473, duration: 3.449s, episode steps: 1949, steps per second: 565, episode reward: 555.900, mean reward: 0.285 [-123.300, 209.200], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.714508, mean_absolute_error: 1.962206, mean_q: -0.152286\n",
      "[-0.8266507  1.1693991]\n",
      "[-0.7091967  1.1617999]\n",
      "[-1.0429201   0.92372555]\n",
      "[-0.56026465  0.46796194]\n",
      "[-0.64341855  1.0174949 ]\n",
      "[40135, 883691]\n",
      "  923826/1500000: episode: 474, duration: 3.297s, episode steps: 1949, steps per second: 591, episode reward: 916.700, mean reward: 0.470 [-94.800, 145.600], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.119629, mean_absolute_error: 2.020101, mean_q: -0.153869\n",
      "[-1.2032896  1.2343779]\n",
      "[-0.68652165  1.0876073 ]\n",
      "[-1.0148411   0.95667154]\n",
      "[-1.4056214  0.8238987]\n",
      "[-1.1586887  1.1766777]\n",
      "[40205, 885570]\n",
      "  925775/1500000: episode: 475, duration: 3.414s, episode steps: 1949, steps per second: 571, episode reward: 93.100, mean reward: 0.048 [-118.000, 178.400], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.293945, mean_absolute_error: 1.849811, mean_q: -0.155371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3391255  1.3922071]\n",
      "[-1.0125937  0.5542942]\n",
      "[-0.65485126  0.8895757 ]\n",
      "[-0.60818106  0.49765363]\n",
      "[-1.0226198   0.79178065]\n",
      "[40275, 887449]\n",
      "  927724/1500000: episode: 476, duration: 3.294s, episode steps: 1949, steps per second: 592, episode reward: 81.800, mean reward: 0.042 [-186.300, 128.500], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.818611, mean_absolute_error: 1.930938, mean_q: -0.156645\n",
      "[-0.8593525  0.9819936]\n",
      "[-0.6894169  0.7468363]\n",
      "[-1.0764729  1.3449056]\n",
      "[-1.37947     0.96921957]\n",
      "[-1.00994    1.4462607]\n",
      "[40356, 889317]\n",
      "  929673/1500000: episode: 477, duration: 3.392s, episode steps: 1949, steps per second: 575, episode reward: 361.700, mean reward: 0.186 [-125.300, 128.000], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.005981, mean_absolute_error: 1.916257, mean_q: -0.157997\n",
      "[-0.6379335   0.54292953]\n",
      "[-0.7010257  0.6565689]\n",
      "[-0.6318955  1.019136 ]\n",
      "[-0.47922724  1.718274  ]\n",
      "[-0.37575933  1.6078323 ]\n",
      "[40437, 891185]\n",
      "  931622/1500000: episode: 478, duration: 3.498s, episode steps: 1949, steps per second: 557, episode reward: 393.200, mean reward: 0.202 [-129.300, 123.000], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.588203, mean_absolute_error: 2.058606, mean_q: -0.159451\n",
      "[-0.4214638  0.7391753]\n",
      "[-1.089872  1.456555]\n",
      "[-0.87480485  1.255364  ]\n",
      "[-0.96967953  0.13163002]\n",
      "[40503, 893068]\n",
      "  933571/1500000: episode: 479, duration: 3.269s, episode steps: 1949, steps per second: 596, episode reward: 31.100, mean reward: 0.016 [-125.400, 121.800], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.119827, mean_absolute_error: 2.204084, mean_q: -0.160961\n",
      "[-0.8370282   0.85278225]\n",
      "[-0.3021615  1.5840278]\n",
      "[-0.24117468  1.758547  ]\n",
      "[-0.8833303  1.2786459]\n",
      "[-1.062809   1.3869005]\n",
      "[40575, 894945]\n",
      "  935520/1500000: episode: 480, duration: 3.279s, episode steps: 1949, steps per second: 594, episode reward: 527.900, mean reward: 0.271 [-181.100, 205.200], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.735577, mean_absolute_error: 2.067748, mean_q: -0.162520\n",
      "[-1.039045  0.565015]\n",
      "[-2.3303670e-04  1.2733995e+00]\n",
      "[-1.194535   1.0069919]\n",
      "[-0.51531523  0.7155646 ]\n",
      "[-0.79244894  1.1782349 ]\n",
      "[40633, 896836]\n",
      "  937469/1500000: episode: 481, duration: 3.403s, episode steps: 1949, steps per second: 573, episode reward: 474.800, mean reward: 0.244 [-170.100, 220.700], mean action: 0.970 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.503677, mean_absolute_error: 2.169450, mean_q: -0.163951\n",
      "[-0.94922155  1.2808716 ]\n",
      "[0.04168275 1.840612  ]\n",
      "[-0.65971756  0.84555465]\n",
      "[-1.3991773  0.8980942]\n",
      "[-0.91896117  0.75785214]\n",
      "[40709, 898709]\n",
      "  939418/1500000: episode: 482, duration: 3.472s, episode steps: 1949, steps per second: 561, episode reward: 245.200, mean reward: 0.126 [-119.200, 242.600], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.062649, mean_absolute_error: 2.079367, mean_q: -0.165418\n",
      "[-1.2032598  1.035292 ]\n",
      "[-0.8577913  1.4295454]\n",
      "[-1.1399645  1.3304164]\n",
      "[-0.9425681  2.028169 ]\n",
      "[-0.6083058  1.0558535]\n",
      "[40774, 900593]\n",
      "  941367/1500000: episode: 483, duration: 3.380s, episode steps: 1949, steps per second: 577, episode reward: 558.600, mean reward: 0.287 [-107.300, 203.400], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.662609, mean_absolute_error: 2.191415, mean_q: -0.167278\n",
      "[-0.9503649  1.2621851]\n",
      "[-0.6942304   0.92021805]\n",
      "[-0.8834916  1.9523386]\n",
      "[-0.7173991  1.3312088]\n",
      "[-0.35610148  1.3764576 ]\n",
      "[40852, 902464]\n",
      "  943316/1500000: episode: 484, duration: 3.345s, episode steps: 1949, steps per second: 583, episode reward: 400.400, mean reward: 0.205 [-206.500, 172.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.329369, mean_absolute_error: 2.119272, mean_q: -0.169388\n",
      "[-1.5067011   0.97668344]\n",
      "[-1.4021381  1.5918268]\n",
      "[-1.0745289  1.8355796]\n",
      "[-1.1824882  2.1383576]\n",
      "[-2.0386193  1.3449483]\n",
      "[40930, 904335]\n",
      "  945265/1500000: episode: 485, duration: 3.355s, episode steps: 1949, steps per second: 581, episode reward: 377.100, mean reward: 0.193 [-184.900, 140.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 62.125244, mean_absolute_error: 2.144586, mean_q: -0.171476\n",
      "[-0.4756528   0.67364407]\n",
      "[-1.0708551  0.6213685]\n",
      "[-1.3411274   0.66544044]\n",
      "[-1.8322756  0.8789717]\n",
      "[-1.7261155  0.906182 ]\n",
      "[41004, 906210]\n",
      "  947214/1500000: episode: 486, duration: 3.241s, episode steps: 1949, steps per second: 601, episode reward: 427.900, mean reward: 0.220 [-119.600, 122.400], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.519829, mean_absolute_error: 1.974732, mean_q: -0.173201\n",
      "[-0.0389895  1.5011557]\n",
      "[-0.24529245  1.3721199 ]\n",
      "[-0.71538    1.6117787]\n",
      "[-0.3407637  1.2056118]\n",
      "[41073, 908090]\n",
      "  949163/1500000: episode: 487, duration: 3.631s, episode steps: 1949, steps per second: 537, episode reward: 549.300, mean reward: 0.282 [-111.700, 141.700], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.762596, mean_absolute_error: 1.935201, mean_q: -0.175091\n",
      "[-1.0502253  1.2023823]\n",
      "[-0.7035874  1.5894759]\n",
      "[-0.63614094  0.9212456 ]\n",
      "[-0.6346352  1.083065 ]\n",
      "[-0.34173146  0.90168136]\n",
      "[41153, 909959]\n",
      "  951112/1500000: episode: 488, duration: 4.951s, episode steps: 1949, steps per second: 394, episode reward: 846.700, mean reward: 0.434 [-159.800, 169.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.229881, mean_absolute_error: 2.051224, mean_q: -0.177029\n",
      "[-1.091294   0.9165125]\n",
      "[-0.52812445  0.93176717]\n",
      "[-0.83731055  1.4629356 ]\n",
      "[-0.86429924  1.1719075 ]\n",
      "[-1.3604753  1.2404213]\n",
      "[41246, 911815]\n",
      "  953061/1500000: episode: 489, duration: 4.205s, episode steps: 1949, steps per second: 464, episode reward: 587.800, mean reward: 0.302 [-132.900, 212.500], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.766243, mean_absolute_error: 1.944491, mean_q: -0.178586\n",
      "[-0.69995815  1.0738506 ]\n",
      "[-1.4714919  1.3601236]\n",
      "[-0.6146392  0.9460837]\n",
      "[-0.57576895  1.3505251 ]\n",
      "[-1.0975555  0.5878774]\n",
      "[41332, 913678]\n",
      "  955010/1500000: episode: 490, duration: 3.985s, episode steps: 1949, steps per second: 489, episode reward: 403.500, mean reward: 0.207 [-129.800, 175.000], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.884155, mean_absolute_error: 1.713547, mean_q: -0.179984\n",
      "[-0.3029845  1.3428675]\n",
      "[-0.7462828  1.6851331]\n",
      "[-1.6189171  1.7332445]\n",
      "[-1.3665938  1.6835505]\n",
      "[-1.6939131  1.3969055]\n",
      "[41400, 915559]\n",
      "  956959/1500000: episode: 491, duration: 3.781s, episode steps: 1949, steps per second: 516, episode reward: 794.000, mean reward: 0.407 [-185.400, 163.600], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 32.286446, mean_absolute_error: 1.862291, mean_q: -0.181210\n",
      "[-1.1688509   0.72987056]\n",
      "[-1.0714146  1.2905085]\n",
      "[-0.92347026  1.5629964 ]\n",
      "[-1.145127   1.2406336]\n",
      "[-1.0043355  1.5504459]\n",
      "[41473, 917435]\n",
      "  958908/1500000: episode: 492, duration: 4.078s, episode steps: 1949, steps per second: 478, episode reward: 249.800, mean reward: 0.128 [-97.000, 179.600], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.821976, mean_absolute_error: 2.295765, mean_q: -0.182416\n",
      "[-0.72468567  0.9342537 ]\n",
      "[-0.51053977  1.3294139 ]\n",
      "[0.18392183 0.8517235 ]\n",
      "[-0.7764689  0.9622077]\n",
      "[-0.63790584  0.38610423]\n",
      "[41552, 919305]\n",
      "  960857/1500000: episode: 493, duration: 3.795s, episode steps: 1949, steps per second: 514, episode reward: 489.700, mean reward: 0.251 [-128.900, 255.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.053925, mean_absolute_error: 2.125424, mean_q: -0.183647\n",
      "[-0.9224426   0.22093356]\n",
      "[-0.31617603  0.89718556]\n",
      "[0.23183629 1.3156497 ]\n",
      "[-0.24382968  1.9684988 ]\n",
      "[-0.13665587  1.4642594 ]\n",
      "[41618, 921188]\n",
      "  962806/1500000: episode: 494, duration: 3.446s, episode steps: 1949, steps per second: 566, episode reward: -84.500, mean reward: -0.043 [-168.700, 187.000], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.194359, mean_absolute_error: 2.014481, mean_q: -0.185074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9455375   0.78827024]\n",
      "[0.02630735 0.8695642 ]\n",
      "[-0.14247099  0.7305081 ]\n",
      "[-0.38362202  0.84060085]\n",
      "[41697, 923058]\n",
      "  964755/1500000: episode: 495, duration: 3.364s, episode steps: 1949, steps per second: 579, episode reward: 148.600, mean reward: 0.076 [-140.200, 233.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.130829, mean_absolute_error: 1.776429, mean_q: -0.186459\n",
      "[-1.1562545  1.3972988]\n",
      "[-1.1969198  1.1773721]\n",
      "[-0.40791744  1.6155583 ]\n",
      "[-0.43014538  1.3714504 ]\n",
      "[-0.6730103  1.4382018]\n",
      "[41771, 924933]\n",
      "  966704/1500000: episode: 496, duration: 3.378s, episode steps: 1949, steps per second: 577, episode reward: 640.400, mean reward: 0.329 [-73.500, 156.300], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.466030, mean_absolute_error: 2.125250, mean_q: -0.187749\n",
      "[-0.55090475  0.67358226]\n",
      "[-0.34347516  1.5313499 ]\n",
      "[-1.2106506  1.3155489]\n",
      "[-0.4869023  1.1818948]\n",
      "[-1.5301142  2.062634 ]\n",
      "[41840, 926813]\n",
      "  968653/1500000: episode: 497, duration: 3.527s, episode steps: 1949, steps per second: 553, episode reward: 626.700, mean reward: 0.322 [-87.700, 160.200], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 62.962738, mean_absolute_error: 2.246686, mean_q: -0.189060\n",
      "[-0.9205994  1.1025854]\n",
      "[-1.4321568   0.65987027]\n",
      "[-0.22945721  1.4743495 ]\n",
      "[-0.6031931  1.0706049]\n",
      "[-1.1681242  1.4474593]\n",
      "[41920, 928682]\n",
      "  970602/1500000: episode: 498, duration: 3.354s, episode steps: 1949, steps per second: 581, episode reward: 25.100, mean reward: 0.013 [-135.200, 205.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.234238, mean_absolute_error: 2.112444, mean_q: -0.190306\n",
      "[-0.9507057  1.6898311]\n",
      "[-0.29371932  1.7410924 ]\n",
      "[-0.3876063   0.97547394]\n",
      "[-0.16025642  1.5163013 ]\n",
      "[-0.8137289  1.8096278]\n",
      "[42009, 930542]\n",
      "  972551/1500000: episode: 499, duration: 3.422s, episode steps: 1949, steps per second: 569, episode reward: 444.400, mean reward: 0.228 [-183.200, 147.200], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 68.431969, mean_absolute_error: 2.058379, mean_q: -0.191756\n",
      "[-0.5450173   0.72122353]\n",
      "[-0.7208952  1.1358765]\n",
      "[0.01564031 1.4964924 ]\n",
      "[-0.30549735  0.9670947 ]\n",
      "[-0.5863411  1.3609642]\n",
      "[42097, 932403]\n",
      "  974500/1500000: episode: 500, duration: 3.397s, episode steps: 1949, steps per second: 574, episode reward: 830.800, mean reward: 0.426 [-136.800, 166.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.471355, mean_absolute_error: 1.870488, mean_q: -0.192937\n",
      "[-1.0044781   0.95746326]\n",
      "[-1.2165892  1.1023101]\n",
      "[-1.0520153  0.8314575]\n",
      "[-0.6152959  1.5707823]\n",
      "[-0.8476494   0.92480695]\n",
      "[42173, 934276]\n",
      "  976449/1500000: episode: 501, duration: 3.363s, episode steps: 1949, steps per second: 580, episode reward: 663.200, mean reward: 0.340 [-124.200, 222.200], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.582893, mean_absolute_error: 2.007146, mean_q: -0.193974\n",
      "[-0.9213112  1.1187637]\n",
      "[-1.2225361   0.51135856]\n",
      "[-1.1474842  0.7267244]\n",
      "[-0.98001915  1.303524  ]\n",
      "[42240, 936158]\n",
      "  978398/1500000: episode: 502, duration: 3.449s, episode steps: 1949, steps per second: 565, episode reward: 458.400, mean reward: 0.235 [-105.900, 167.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.112896, mean_absolute_error: 1.992730, mean_q: -0.195236\n",
      "[-0.97075063  1.01932   ]\n",
      "[-0.86071134  1.4628042 ]\n",
      "[-1.0175003  0.9903952]\n",
      "[-0.6070333  1.7645626]\n",
      "[0.02509646 1.44512   ]\n",
      "[42313, 938034]\n",
      "  980347/1500000: episode: 503, duration: 3.399s, episode steps: 1949, steps per second: 573, episode reward: 752.200, mean reward: 0.386 [-113.000, 181.900], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.462273, mean_absolute_error: 2.105590, mean_q: -0.196395\n",
      "[-1.0998932  1.2512023]\n",
      "[-0.4553056  1.845466 ]\n",
      "[-1.1432135  1.0189594]\n",
      "[-0.9930494  0.8542207]\n",
      "[-0.8417269  1.1964173]\n",
      "[42383, 939913]\n",
      "  982296/1500000: episode: 504, duration: 3.456s, episode steps: 1949, steps per second: 564, episode reward: 160.200, mean reward: 0.082 [-136.100, 158.000], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.809399, mean_absolute_error: 2.014010, mean_q: -0.197510\n",
      "[-1.1816729  1.0400889]\n",
      "[-0.49015424  0.7966838 ]\n",
      "[-0.84149903  1.809735  ]\n",
      "[-0.84499836  0.92581683]\n",
      "[-1.1243165  1.0947952]\n",
      "[42461, 941784]\n",
      "  984245/1500000: episode: 505, duration: 3.494s, episode steps: 1949, steps per second: 558, episode reward: 488.700, mean reward: 0.251 [-95.800, 180.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.928596, mean_absolute_error: 2.216745, mean_q: -0.198684\n",
      "[-0.90158075  0.6756617 ]\n",
      "[-0.74230915  1.2768261 ]\n",
      "[-1.0160301  0.9411169]\n",
      "[-0.78813654  0.8424965 ]\n",
      "[-0.84569377  0.51837176]\n",
      "[42549, 943645]\n",
      "  986194/1500000: episode: 506, duration: 3.362s, episode steps: 1949, steps per second: 580, episode reward: 300.300, mean reward: 0.154 [-92.800, 131.600], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 68.006790, mean_absolute_error: 2.253767, mean_q: -0.199828\n",
      "[-0.51298857  0.6447885 ]\n",
      "[-1.0523137  1.2129556]\n",
      "[-1.5424572  1.3301102]\n",
      "[-1.263145   1.3485814]\n",
      "[-0.4512967  1.5884559]\n",
      "[42618, 945525]\n",
      "  988143/1500000: episode: 507, duration: 3.466s, episode steps: 1949, steps per second: 562, episode reward: 481.200, mean reward: 0.247 [-143.500, 179.300], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.416939, mean_absolute_error: 2.330764, mean_q: -0.200521\n",
      "[-0.6199421  0.7749821]\n",
      "[-0.45788762  1.1436328 ]\n",
      "[-1.0104289   0.88370097]\n",
      "[-0.4218883  1.1264936]\n",
      "[-0.45084772  1.0734751 ]\n",
      "[42704, 947388]\n",
      "  990092/1500000: episode: 508, duration: 3.466s, episode steps: 1949, steps per second: 562, episode reward: 666.200, mean reward: 0.342 [-96.900, 201.400], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.396179, mean_absolute_error: 1.738670, mean_q: -0.201052\n",
      "[-1.2792008   0.37521845]\n",
      "[-1.4399407  1.6724541]\n",
      "[-0.5691015  0.5470903]\n",
      "[-0.7064604  0.9533852]\n",
      "[-1.0894805   0.62296647]\n",
      "[42773, 949268]\n",
      "  992041/1500000: episode: 509, duration: 3.727s, episode steps: 1949, steps per second: 523, episode reward: 466.000, mean reward: 0.239 [-85.900, 121.100], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.596584, mean_absolute_error: 1.757709, mean_q: -0.201962\n",
      "[-0.75478303  0.8033653 ]\n",
      "[-0.73454493  1.4522358 ]\n",
      "[-1.382054   1.5826589]\n",
      "[-0.79450685  1.4563249 ]\n",
      "[42847, 951143]\n",
      "  993990/1500000: episode: 510, duration: 3.611s, episode steps: 1949, steps per second: 540, episode reward: 124.300, mean reward: 0.064 [-112.700, 137.600], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.977303, mean_absolute_error: 1.954723, mean_q: -0.202919\n",
      "[-0.9224286  1.0575116]\n",
      "[0.4212695 1.6795218]\n",
      "[-0.38542014  0.76816607]\n",
      "[-0.5957318  1.9073443]\n",
      "[-0.68784165  2.0932217 ]\n",
      "[42908, 953031]\n",
      "  995939/1500000: episode: 511, duration: 3.401s, episode steps: 1949, steps per second: 573, episode reward: 459.200, mean reward: 0.236 [-102.200, 153.600], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.008720, mean_absolute_error: 2.395728, mean_q: -0.204257\n",
      "[-0.97726965  1.0857561 ]\n",
      "[-0.7797343  1.3216575]\n",
      "[-0.9340349  1.7653859]\n",
      "[-1.0282006  0.8183412]\n",
      "[-0.91530305  1.3116597 ]\n",
      "[42993, 954895]\n",
      "  997888/1500000: episode: 512, duration: 3.477s, episode steps: 1949, steps per second: 561, episode reward: 594.200, mean reward: 0.305 [-78.400, 176.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 27.081457, mean_absolute_error: 1.679324, mean_q: -0.205479\n",
      "[-0.98442274  0.703294  ]\n",
      "[-0.24845995  1.2015989 ]\n",
      "[-0.21061692  0.69247353]\n",
      "[-0.2911664  1.0925866]\n",
      "[-0.24035987  1.1563988 ]\n",
      "[43069, 956768]\n",
      "  999837/1500000: episode: 513, duration: 3.417s, episode steps: 1949, steps per second: 570, episode reward: 469.500, mean reward: 0.241 [-146.800, 173.500], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.591850, mean_absolute_error: 2.000724, mean_q: -0.207074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44761744  0.74934256]\n",
      "[-0.8687945  1.4758846]\n",
      "[-1.0989258  0.9208563]\n",
      "[-0.4705138  1.3364443]\n",
      "[-1.0269969  0.8344443]\n",
      "[43131, 958655]\n",
      " 1001786/1500000: episode: 514, duration: 3.231s, episode steps: 1949, steps per second: 603, episode reward: 465.400, mean reward: 0.239 [-101.300, 155.300], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.830318, mean_absolute_error: 2.135512, mean_q: -0.208622\n",
      "[-1.1255184  1.3736105]\n",
      "[-0.5185724  1.4392853]\n",
      "[-1.2665395  0.8299449]\n",
      "[-0.6855217   0.73461616]\n",
      "[-0.5237688   0.92735475]\n",
      "[43214, 960521]\n",
      " 1003735/1500000: episode: 515, duration: 3.223s, episode steps: 1949, steps per second: 605, episode reward: 554.100, mean reward: 0.284 [-129.600, 171.600], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.189171, mean_absolute_error: 2.163368, mean_q: -0.210185\n",
      "[-0.78471214  1.2420838 ]\n",
      "[-0.5692735  1.3023232]\n",
      "[-0.4552199   0.89808446]\n",
      "[-0.79630035  1.27516   ]\n",
      "[-0.64737326  1.2478523 ]\n",
      "[43268, 962416]\n",
      " 1005684/1500000: episode: 516, duration: 3.357s, episode steps: 1949, steps per second: 581, episode reward: 452.300, mean reward: 0.232 [-93.100, 165.700], mean action: 0.972 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.319195, mean_absolute_error: 2.037072, mean_q: -0.211601\n",
      "[-0.9536926  1.7588707]\n",
      "[-1.6409378  1.1947203]\n",
      "[-1.2280222  1.2186921]\n",
      "[-1.4895416  1.3675647]\n",
      "[-1.39731    1.6916957]\n",
      "[43355, 964278]\n",
      " 1007633/1500000: episode: 517, duration: 3.383s, episode steps: 1949, steps per second: 576, episode reward: 704.100, mean reward: 0.361 [-96.100, 144.200], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 61.585468, mean_absolute_error: 2.224223, mean_q: -0.213021\n",
      "[-0.40862894  0.4032848 ]\n",
      "[-1.1829879  1.1899358]\n",
      "[-1.140423   1.2734731]\n",
      "[-0.75130165  1.0814492 ]\n",
      "[43446, 966136]\n",
      " 1009582/1500000: episode: 518, duration: 3.463s, episode steps: 1949, steps per second: 563, episode reward: 441.900, mean reward: 0.227 [-102.200, 179.800], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.294243, mean_absolute_error: 2.081620, mean_q: -0.214428\n",
      "[-0.87428916  0.97219163]\n",
      "[-0.85043985  1.084779  ]\n",
      "[-0.6910734  1.0875578]\n",
      "[-1.7218375  1.3057201]\n",
      "[-0.6951707  1.0656092]\n",
      "[43521, 968010]\n",
      " 1011531/1500000: episode: 519, duration: 3.379s, episode steps: 1949, steps per second: 577, episode reward: 675.000, mean reward: 0.346 [-178.600, 177.000], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.626392, mean_absolute_error: 1.760854, mean_q: -0.215943\n",
      "[-0.90483046  1.1757649 ]\n",
      "[-1.4592966  1.488585 ]\n",
      "[-0.96956164  1.4117184 ]\n",
      "[-1.1166893  1.3022702]\n",
      "[-0.63314617  0.8429072 ]\n",
      "[43615, 969865]\n",
      " 1013480/1500000: episode: 520, duration: 3.402s, episode steps: 1949, steps per second: 573, episode reward: 775.800, mean reward: 0.398 [-109.800, 170.800], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.554558, mean_absolute_error: 1.710430, mean_q: -0.217350\n",
      "[-1.0798826  1.1853614]\n",
      "[-1.3257787  1.0558836]\n",
      "[-0.561173    0.81424814]\n",
      "[-1.0108473  1.37442  ]\n",
      "[-1.2433112  0.8506063]\n",
      "[43681, 971748]\n",
      " 1015429/1500000: episode: 521, duration: 3.223s, episode steps: 1949, steps per second: 605, episode reward: 502.800, mean reward: 0.258 [-139.600, 200.400], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.485073, mean_absolute_error: 1.733159, mean_q: -0.218697\n",
      "[-0.42723703  1.2619662 ]\n",
      "[-0.6270629  0.9938557]\n",
      "[-1.0874104  0.8271651]\n",
      "[-1.3488652  1.075028 ]\n",
      "[-0.6303516  1.0030534]\n",
      "[43751, 973627]\n",
      " 1017378/1500000: episode: 522, duration: 3.283s, episode steps: 1949, steps per second: 594, episode reward: 384.600, mean reward: 0.197 [-121.300, 202.000], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 72.707733, mean_absolute_error: 2.372459, mean_q: -0.220241\n",
      "[-0.4912916  1.3569357]\n",
      "[-0.58722204  1.1477667 ]\n",
      "[-1.0131254  1.8317624]\n",
      "[-0.94568783  1.5082088 ]\n",
      "[-1.5803713  1.3107384]\n",
      "[43825, 975502]\n",
      " 1019327/1500000: episode: 523, duration: 3.329s, episode steps: 1949, steps per second: 585, episode reward: 631.400, mean reward: 0.324 [-97.600, 171.800], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 73.751907, mean_absolute_error: 2.089506, mean_q: -0.221713\n",
      "[-1.0330906  1.1978331]\n",
      "[-0.8019707  1.1897229]\n",
      "[-0.71853745  1.0982625 ]\n",
      "[-0.5354151  1.0148164]\n",
      "[-0.22349802  1.5024422 ]\n",
      "[43909, 977367]\n",
      " 1021276/1500000: episode: 524, duration: 3.334s, episode steps: 1949, steps per second: 585, episode reward: 359.200, mean reward: 0.184 [-100.100, 246.500], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.916084, mean_absolute_error: 1.936744, mean_q: -0.223483\n",
      "[-0.7024871  1.0742736]\n",
      "[-1.0576442  1.4937731]\n",
      "[-1.1276059  1.1474961]\n",
      "[-1.1761034  1.0457964]\n",
      "[-0.2014246  0.9403321]\n",
      "[43998, 979227]\n",
      " 1023225/1500000: episode: 525, duration: 3.320s, episode steps: 1949, steps per second: 587, episode reward: 429.400, mean reward: 0.220 [-118.400, 138.100], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.138489, mean_absolute_error: 2.282253, mean_q: -0.225143\n",
      "[-0.24365467  1.3418181 ]\n",
      "[-1.2686396  1.6464905]\n",
      "[-1.0211957  1.250709 ]\n",
      "[-0.65268785  1.0971112 ]\n",
      "[44082, 981092]\n",
      " 1025174/1500000: episode: 526, duration: 3.438s, episode steps: 1949, steps per second: 567, episode reward: 471.800, mean reward: 0.242 [-107.500, 208.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.924919, mean_absolute_error: 1.913980, mean_q: -0.226726\n",
      "[-0.9773763  1.0914944]\n",
      "[-0.9579689  1.1517613]\n",
      "[-0.56300974  1.4618722 ]\n",
      "[-0.1522782  1.2424343]\n",
      "[-0.7983475  0.9064068]\n",
      "[44162, 982961]\n",
      " 1027123/1500000: episode: 527, duration: 3.546s, episode steps: 1949, steps per second: 550, episode reward: 964.000, mean reward: 0.495 [-77.300, 174.300], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.978363, mean_absolute_error: 1.846269, mean_q: -0.228176\n",
      "[-0.6505032   0.95504844]\n",
      "[-0.8785179  1.5251037]\n",
      "[-1.3025099  1.4502891]\n",
      "[-0.74783915  1.0792041 ]\n",
      "[-0.43713868  0.7491627 ]\n",
      "[44242, 984830]\n",
      " 1029072/1500000: episode: 528, duration: 3.604s, episode steps: 1949, steps per second: 541, episode reward: 460.900, mean reward: 0.236 [-117.500, 171.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.370934, mean_absolute_error: 1.956674, mean_q: -0.229568\n",
      "[-1.2537917  0.5511409]\n",
      "[-0.741695   1.3958739]\n",
      "[-1.2786034  1.4621639]\n",
      "[-0.90841585  1.3150537 ]\n",
      "[-0.52055824  0.9789189 ]\n",
      "[44329, 986692]\n",
      " 1031021/1500000: episode: 529, duration: 3.382s, episode steps: 1949, steps per second: 576, episode reward: 338.500, mean reward: 0.174 [-183.700, 215.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 78.064423, mean_absolute_error: 2.401664, mean_q: -0.230850\n",
      "[-1.003146   1.3599331]\n",
      "[-1.0252416  1.2532648]\n",
      "[-0.5743795  1.3657483]\n",
      "[-0.6521058  1.1424748]\n",
      "[-0.47039518  1.2864066 ]\n",
      "[44404, 988566]\n",
      " 1032970/1500000: episode: 530, duration: 3.332s, episode steps: 1949, steps per second: 585, episode reward: 421.200, mean reward: 0.216 [-135.800, 218.600], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.542931, mean_absolute_error: 1.745468, mean_q: -0.231911\n",
      "[-1.3796173  0.7406538]\n",
      "[-1.5891373  1.6090131]\n",
      "[-1.0510304   0.43534014]\n",
      "[-0.8469203  1.07987  ]\n",
      "[-0.39814553  1.4832239 ]\n",
      "[44483, 990436]\n",
      " 1034919/1500000: episode: 531, duration: 3.357s, episode steps: 1949, steps per second: 581, episode reward: 647.000, mean reward: 0.332 [-122.700, 209.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.019554, mean_absolute_error: 2.237102, mean_q: -0.233003\n",
      "[-0.86005986  1.4229482 ]\n",
      "[-0.49018788  0.5980063 ]\n",
      "[-0.5476187  1.4305197]\n",
      "[-0.7786805  0.843462 ]\n",
      "[-1.3401562  1.1665844]\n",
      "[44568, 992300]\n",
      " 1036868/1500000: episode: 532, duration: 3.397s, episode steps: 1949, steps per second: 574, episode reward: 586.400, mean reward: 0.301 [-96.000, 245.100], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.566418, mean_absolute_error: 2.216093, mean_q: -0.234001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8894686  0.6257511]\n",
      "[-0.83775926  0.95782256]\n",
      "[-0.32423565  1.1620048 ]\n",
      "[-0.374093  1.182018]\n",
      "[-0.5603099  1.2846923]\n",
      "[44644, 994173]\n",
      " 1038817/1500000: episode: 533, duration: 3.345s, episode steps: 1949, steps per second: 583, episode reward: 451.300, mean reward: 0.232 [-137.800, 163.000], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.607307, mean_absolute_error: 2.019620, mean_q: -0.235127\n",
      "[-0.56168246  1.4613957 ]\n",
      "[-1.3918496  1.1383908]\n",
      "[-1.2463112  0.7409782]\n",
      "[-1.0054331  0.7063271]\n",
      "[44721, 996045]\n",
      " 1040766/1500000: episode: 534, duration: 3.388s, episode steps: 1949, steps per second: 575, episode reward: 534.400, mean reward: 0.274 [-124.600, 182.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.083015, mean_absolute_error: 1.959905, mean_q: -0.236243\n",
      "[-0.8864223  1.1365963]\n",
      "[-0.05370181  1.1679996 ]\n",
      "[-1.4084139  0.2580856]\n",
      "[-1.1102196  0.6546229]\n",
      "[-0.6751925  1.309226 ]\n",
      "[44797, 997918]\n",
      " 1042715/1500000: episode: 535, duration: 3.331s, episode steps: 1949, steps per second: 585, episode reward: 667.400, mean reward: 0.342 [-96.500, 220.700], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.814232, mean_absolute_error: 1.988495, mean_q: -0.237338\n",
      "[-0.68952316  1.0376642 ]\n",
      "[-0.63453025  1.5657183 ]\n",
      "[-0.10680961  1.5001765 ]\n",
      "[-0.3871246  1.1805065]\n",
      "[-0.87470806  1.472346  ]\n",
      "[44871, 999793]\n",
      " 1044664/1500000: episode: 536, duration: 3.343s, episode steps: 1949, steps per second: 583, episode reward: 482.900, mean reward: 0.248 [-154.200, 154.400], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 61.971626, mean_absolute_error: 2.169920, mean_q: -0.238183\n",
      "[-0.6401566  1.0546668]\n",
      "[-1.2058594  1.7488939]\n",
      "[-0.6873927  1.7230438]\n",
      "[-0.98755634  0.64095813]\n",
      "[-0.62727267  1.113795  ]\n",
      "[44949, 1001664]\n",
      " 1046613/1500000: episode: 537, duration: 3.430s, episode steps: 1949, steps per second: 568, episode reward: 578.800, mean reward: 0.297 [-116.900, 157.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.991627, mean_absolute_error: 1.821635, mean_q: -0.238983\n",
      "[-1.1582915  1.09396  ]\n",
      "[-1.0188075  0.8269247]\n",
      "[-0.7644641   0.88236827]\n",
      "[-1.3382986  0.6304544]\n",
      "[-1.0152965  0.9658938]\n",
      "[45029, 1003533]\n",
      " 1048562/1500000: episode: 538, duration: 3.330s, episode steps: 1949, steps per second: 585, episode reward: 413.100, mean reward: 0.212 [-96.700, 174.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.416351, mean_absolute_error: 1.970443, mean_q: -0.239811\n",
      "[-0.6594042  1.3374578]\n",
      "[-0.8432555  1.3916717]\n",
      "[-1.1690286  1.3252684]\n",
      "[-1.1286569   0.47744143]\n",
      "[-1.0954475  0.5485607]\n",
      "[45095, 1005416]\n",
      " 1050511/1500000: episode: 539, duration: 3.225s, episode steps: 1949, steps per second: 604, episode reward: 338.600, mean reward: 0.174 [-122.600, 261.800], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.030079, mean_absolute_error: 2.339341, mean_q: -0.240227\n",
      "[-0.7380613  1.766772 ]\n",
      "[-0.30085877  1.840043  ]\n",
      "[-1.2878022  2.0947998]\n",
      "[-1.6938133  1.619342 ]\n",
      "[-1.0730534  1.2281594]\n",
      "[45169, 1007291]\n",
      " 1052460/1500000: episode: 540, duration: 3.003s, episode steps: 1949, steps per second: 649, episode reward: 714.800, mean reward: 0.367 [-116.700, 146.900], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 77.118713, mean_absolute_error: 2.401177, mean_q: -0.240464\n",
      "[-0.8830043  0.8095   ]\n",
      "[-0.80114317  0.57310295]\n",
      "[-0.622669   0.7565095]\n",
      "[-0.7188646  0.8613081]\n",
      "[-0.3503137  1.2868246]\n",
      "[45228, 1009181]\n",
      " 1054409/1500000: episode: 541, duration: 3.266s, episode steps: 1949, steps per second: 597, episode reward: 338.900, mean reward: 0.174 [-102.700, 116.900], mean action: 0.970 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.418346, mean_absolute_error: 1.974035, mean_q: -0.241001\n",
      "[-1.3736016  0.7247729]\n",
      "[-0.8159523  1.5670074]\n",
      "[-0.2535899  1.9634643]\n",
      "[-0.99472207  1.2413391 ]\n",
      "[45322, 1011036]\n",
      " 1056358/1500000: episode: 542, duration: 3.141s, episode steps: 1949, steps per second: 620, episode reward: 332.700, mean reward: 0.171 [-108.300, 154.300], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 30.183393, mean_absolute_error: 1.680891, mean_q: -0.241723\n",
      "[-1.036152    0.88813525]\n",
      "[-0.76512176  1.2656547 ]\n",
      "[-0.07624874  1.4828157 ]\n",
      "[-1.0043193  0.9474587]\n",
      "[-1.0802908  0.767675 ]\n",
      "[45400, 1012907]\n",
      " 1058307/1500000: episode: 543, duration: 3.234s, episode steps: 1949, steps per second: 603, episode reward: 644.400, mean reward: 0.331 [-65.200, 212.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 83.342163, mean_absolute_error: 2.528153, mean_q: -0.242576\n",
      "[-1.1799927  1.1336998]\n",
      "[-1.8308146  1.4402164]\n",
      "[-0.97606725  0.88704747]\n",
      "[-0.71113855  1.4283769 ]\n",
      "[-1.006432   0.5933845]\n",
      "[45489, 1014767]\n",
      " 1060256/1500000: episode: 544, duration: 3.357s, episode steps: 1949, steps per second: 581, episode reward: 766.000, mean reward: 0.393 [-112.000, 198.200], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.251621, mean_absolute_error: 2.021333, mean_q: -0.243614\n",
      "[-1.4580584  0.5156   ]\n",
      "[-0.9807069  1.0423632]\n",
      "[-0.849584   1.9310321]\n",
      "[-1.2720265  2.4986303]\n",
      "[-0.9634301  1.9217291]\n",
      "[45561, 1016644]\n",
      " 1062205/1500000: episode: 545, duration: 3.308s, episode steps: 1949, steps per second: 589, episode reward: 305.400, mean reward: 0.157 [-162.100, 180.100], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.933868, mean_absolute_error: 1.830526, mean_q: -0.244643\n",
      "[-1.1878077  1.1879148]\n",
      "[-0.8732305  1.13928  ]\n",
      "[-0.94813067  1.7139769 ]\n",
      "[-0.96502185  2.147078  ]\n",
      "[-0.32965088  1.4611284 ]\n",
      "[45635, 1018519]\n",
      " 1064154/1500000: episode: 546, duration: 3.298s, episode steps: 1949, steps per second: 591, episode reward: 481.700, mean reward: 0.247 [-93.700, 168.700], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.927555, mean_absolute_error: 2.053034, mean_q: -0.245595\n",
      "[-0.35821056  1.1680603 ]\n",
      "[-0.07747409  1.309018  ]\n",
      "[-1.2762635  1.3362862]\n",
      "[-1.1968434  1.4287025]\n",
      "[-1.1439847  1.0953494]\n",
      "[45722, 1020381]\n",
      " 1066103/1500000: episode: 547, duration: 3.612s, episode steps: 1949, steps per second: 540, episode reward: 178.900, mean reward: 0.092 [-197.300, 151.800], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.587215, mean_absolute_error: 1.672861, mean_q: -0.246479\n",
      "[-0.7440963  0.8036855]\n",
      "[-1.135942   1.7814418]\n",
      "[-1.0543289  1.6387544]\n",
      "[-0.5049825  1.2858198]\n",
      "[-0.618924   1.3050073]\n",
      "[45815, 1022237]\n",
      " 1068052/1500000: episode: 548, duration: 6.090s, episode steps: 1949, steps per second: 320, episode reward: 687.700, mean reward: 0.353 [-84.700, 149.600], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.267540, mean_absolute_error: 2.173325, mean_q: -0.247220\n",
      "[-0.5555611  0.9298593]\n",
      "[-0.81902933  1.2174639 ]\n",
      "[-0.50496954  1.6093051 ]\n",
      "[-0.19721496  1.0746317 ]\n",
      "[-0.76059574  1.0399452 ]\n",
      "[45889, 1024112]\n",
      " 1070001/1500000: episode: 549, duration: 5.601s, episode steps: 1949, steps per second: 348, episode reward: 403.800, mean reward: 0.207 [-123.200, 179.700], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.600555, mean_absolute_error: 2.049128, mean_q: -0.247876\n",
      "[-0.55370784  0.81518143]\n",
      "[-1.181984   1.2652152]\n",
      "[-0.3732918  1.5510998]\n",
      "[-0.7161992  1.1168598]\n",
      "[45975, 1025975]\n",
      " 1071950/1500000: episode: 550, duration: 4.255s, episode steps: 1949, steps per second: 458, episode reward: 483.600, mean reward: 0.248 [-142.500, 149.600], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.216423, mean_absolute_error: 2.211987, mean_q: -0.248908\n",
      "[-0.84624696  1.0268452 ]\n",
      "[-0.64532804  0.9520423 ]\n",
      "[-0.32453454  0.25191537]\n",
      "[-0.373431   1.0515758]\n",
      "[-0.3689355  0.3441793]\n",
      "[46050, 1027849]\n",
      " 1073899/1500000: episode: 551, duration: 4.375s, episode steps: 1949, steps per second: 445, episode reward: 367.100, mean reward: 0.188 [-183.300, 168.800], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.935928, mean_absolute_error: 1.594355, mean_q: -0.249885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6583576  1.1897546]\n",
      "[-0.592756   0.9137004]\n",
      "[-1.1560612  1.6195816]\n",
      "[-0.4508265  1.1517898]\n",
      "[-1.0995743   0.79909444]\n",
      "[46126, 1029722]\n",
      " 1075848/1500000: episode: 552, duration: 4.294s, episode steps: 1949, steps per second: 454, episode reward: 591.400, mean reward: 0.303 [-116.100, 190.900], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.468052, mean_absolute_error: 2.052132, mean_q: -0.250951\n",
      "[-0.9242576  1.210215 ]\n",
      "[-1.0101154  1.6844261]\n",
      "[-0.78640646  0.8968809 ]\n",
      "[-0.5770705  1.0427822]\n",
      "[-0.7581806  0.3664342]\n",
      "[46206, 1031591]\n",
      " 1077797/1500000: episode: 553, duration: 3.794s, episode steps: 1949, steps per second: 514, episode reward: 674.400, mean reward: 0.346 [-128.700, 181.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 35.600613, mean_absolute_error: 1.886384, mean_q: -0.252220\n",
      "[-0.9898562   0.60068685]\n",
      "[-1.4335697  1.1939347]\n",
      "[-1.6543921  0.7601559]\n",
      "[-1.240115  1.02415 ]\n",
      "[-0.7857094  0.6715821]\n",
      "[46285, 1033461]\n",
      " 1079746/1500000: episode: 554, duration: 3.628s, episode steps: 1949, steps per second: 537, episode reward: 462.800, mean reward: 0.237 [-192.300, 147.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.138054, mean_absolute_error: 2.113016, mean_q: -0.253414\n",
      "[-0.7205307  0.721383 ]\n",
      "[-0.5519784  1.4147631]\n",
      "[-1.6080366  1.2341505]\n",
      "[-1.5215379  1.4057006]\n",
      "[-1.6769854  1.4365355]\n",
      "[46354, 1035341]\n",
      " 1081695/1500000: episode: 555, duration: 3.280s, episode steps: 1949, steps per second: 594, episode reward: 814.600, mean reward: 0.418 [-204.700, 210.500], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 71.076569, mean_absolute_error: 2.089054, mean_q: -0.254214\n",
      "[-0.93848145  0.9747575 ]\n",
      "[-0.59836406  1.0429267 ]\n",
      "[-0.6146402  1.9384629]\n",
      "[-0.35513845  1.6611285 ]\n",
      "[-0.3380982  1.0773833]\n",
      "[46430, 1037214]\n",
      " 1083644/1500000: episode: 556, duration: 3.445s, episode steps: 1949, steps per second: 566, episode reward: 451.900, mean reward: 0.232 [-172.900, 156.500], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.738285, mean_absolute_error: 2.051050, mean_q: -0.254989\n",
      "[-0.5526278  1.6340048]\n",
      "[-0.11600002  1.301789  ]\n",
      "[-1.2013702  1.6808115]\n",
      "[-1.2259439  1.2328913]\n",
      "[46498, 1039095]\n",
      " 1085593/1500000: episode: 557, duration: 3.224s, episode steps: 1949, steps per second: 605, episode reward: 323.800, mean reward: 0.166 [-89.800, 148.200], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 72.534523, mean_absolute_error: 2.377060, mean_q: -0.256069\n",
      "[-1.0591761  1.0208035]\n",
      "[-0.9844228  1.2598103]\n",
      "[-0.9488185  0.9631573]\n",
      "[-0.81189585  1.1224551 ]\n",
      "[-0.11993646  0.58149904]\n",
      "[46556, 1040986]\n",
      " 1087542/1500000: episode: 558, duration: 4.365s, episode steps: 1949, steps per second: 446, episode reward: 528.200, mean reward: 0.271 [-109.400, 123.200], mean action: 0.970 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.142750, mean_absolute_error: 2.016154, mean_q: -0.257289\n",
      "[-0.63980967  0.7047497 ]\n",
      "[-0.5791638   0.86196303]\n",
      "[-0.73173994  1.8660661 ]\n",
      "[-0.39609227  1.3804266 ]\n",
      "[-0.5797424  0.9581067]\n",
      "[46636, 1042855]\n",
      " 1089491/1500000: episode: 559, duration: 4.154s, episode steps: 1949, steps per second: 469, episode reward: 532.900, mean reward: 0.273 [-88.700, 165.100], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.814629, mean_absolute_error: 1.985023, mean_q: -0.258872\n",
      "[-0.71595466  0.755541  ]\n",
      "[-0.7621743  1.2387717]\n",
      "[-0.56836694  1.3270643 ]\n",
      "[-0.82088286  0.6640008 ]\n",
      "[-1.2038413  0.9738846]\n",
      "[46712, 1044728]\n",
      " 1091440/1500000: episode: 560, duration: 3.502s, episode steps: 1949, steps per second: 557, episode reward: 533.600, mean reward: 0.274 [-202.000, 152.900], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.706367, mean_absolute_error: 2.417953, mean_q: -0.260548\n",
      "[-1.212313   1.0074013]\n",
      "[-1.2831202  1.2903135]\n",
      "[-0.72907054  0.64733374]\n",
      "[-1.0002501  0.901636 ]\n",
      "[-0.6862264   0.69822854]\n",
      "[46788, 1046601]\n",
      " 1093389/1500000: episode: 561, duration: 3.367s, episode steps: 1949, steps per second: 579, episode reward: 458.000, mean reward: 0.235 [-98.700, 225.500], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.481117, mean_absolute_error: 2.184160, mean_q: -0.262074\n",
      "[-0.87645584  1.3698312 ]\n",
      "[-1.8989192  1.2252828]\n",
      "[-1.12983   0.708159]\n",
      "[-1.1828122  1.5703504]\n",
      "[-0.02108129  0.8620773 ]\n",
      "[46871, 1048467]\n",
      " 1095338/1500000: episode: 562, duration: 3.469s, episode steps: 1949, steps per second: 562, episode reward: 619.900, mean reward: 0.318 [-68.900, 191.100], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.833828, mean_absolute_error: 1.962880, mean_q: -0.263290\n",
      "[-0.8562054   0.89147353]\n",
      "[-0.585384   0.1138126]\n",
      "[-0.2902633  1.1203202]\n",
      "[-0.6641794  1.5908041]\n",
      "[-0.76803476  1.0011065 ]\n",
      "[46956, 1050331]\n",
      " 1097287/1500000: episode: 563, duration: 3.358s, episode steps: 1949, steps per second: 580, episode reward: 647.300, mean reward: 0.332 [-103.300, 199.000], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 68.179634, mean_absolute_error: 2.129012, mean_q: -0.264404\n",
      "[-0.89290315  0.86103195]\n",
      "[-0.9230201  1.1223595]\n",
      "[-0.44596198  0.87235445]\n",
      "[-0.7603555  1.1911204]\n",
      "[-0.32410562  1.4518085 ]\n",
      "[47026, 1052210]\n",
      " 1099236/1500000: episode: 564, duration: 3.470s, episode steps: 1949, steps per second: 562, episode reward: 722.500, mean reward: 0.371 [-119.000, 187.600], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 76.198639, mean_absolute_error: 2.432662, mean_q: -0.265224\n",
      "[-1.0764097  1.3970544]\n",
      "[-0.8398145  1.6994067]\n",
      "[-0.9483978  0.9330465]\n",
      "[-0.4650293  1.3422298]\n",
      "[47123, 1054062]\n",
      " 1101185/1500000: episode: 565, duration: 3.509s, episode steps: 1949, steps per second: 555, episode reward: 879.100, mean reward: 0.451 [-78.100, 112.600], mean action: 0.950 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.472607, mean_absolute_error: 1.894261, mean_q: -0.266026\n",
      "[-0.9772545  0.9043043]\n",
      "[-1.2027569  1.4988399]\n",
      "[-0.6598963  1.4754449]\n",
      "[-0.7061255   0.91312116]\n",
      "[-0.44316858  1.1160167 ]\n",
      "[47214, 1055920]\n",
      " 1103134/1500000: episode: 566, duration: 3.335s, episode steps: 1949, steps per second: 584, episode reward: 270.100, mean reward: 0.139 [-98.800, 173.500], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.747318, mean_absolute_error: 1.966358, mean_q: -0.266873\n",
      "[-0.9231917  1.1628351]\n",
      "[-0.7954513  1.413833 ]\n",
      "[-0.8722461  1.2604462]\n",
      "[-0.80794483  1.1633058 ]\n",
      "[-0.58215433  0.5331493 ]\n",
      "[47293, 1057790]\n",
      " 1105083/1500000: episode: 567, duration: 3.196s, episode steps: 1949, steps per second: 610, episode reward: 761.700, mean reward: 0.391 [-105.000, 204.900], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.583996, mean_absolute_error: 2.063101, mean_q: -0.267521\n",
      "[-0.74033254  0.7758222 ]\n",
      "[-0.2115452   0.95462215]\n",
      "[-0.4081848  1.0691899]\n",
      "[-0.4417183   0.98029596]\n",
      "[-0.80973357  0.74854773]\n",
      "[47383, 1059649]\n",
      " 1107032/1500000: episode: 568, duration: 3.389s, episode steps: 1949, steps per second: 575, episode reward: 603.600, mean reward: 0.310 [-83.900, 155.700], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 32.731911, mean_absolute_error: 1.834868, mean_q: -0.268307\n",
      "[-1.2336749  0.9652442]\n",
      "[-1.8009073   0.62334436]\n",
      "[-0.6984251  1.0553826]\n",
      "[-0.87370193  1.1818193 ]\n",
      "[-0.8713847  1.5999655]\n",
      "[47461, 1061520]\n",
      " 1108981/1500000: episode: 569, duration: 3.392s, episode steps: 1949, steps per second: 575, episode reward: 405.500, mean reward: 0.208 [-97.500, 147.700], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.864990, mean_absolute_error: 1.890482, mean_q: -0.269463\n",
      "[-0.30793992  0.74499303]\n",
      "[-0.80007327  0.96223015]\n",
      "[-0.45779023  0.94995743]\n",
      "[-0.8756519  0.7206628]\n",
      "[-0.6422529  0.9610864]\n",
      "[47538, 1063392]\n",
      " 1110930/1500000: episode: 570, duration: 3.322s, episode steps: 1949, steps per second: 587, episode reward: 676.500, mean reward: 0.347 [-99.300, 209.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 29.562609, mean_absolute_error: 1.584978, mean_q: -0.270577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44491637  1.360523  ]\n",
      "[-0.34269652  1.3855948 ]\n",
      "[-0.90833575  1.169612  ]\n",
      "[-0.8404186  1.5551037]\n",
      "[-0.6124886  0.9482485]\n",
      "[47617, 1065262]\n",
      " 1112879/1500000: episode: 571, duration: 3.599s, episode steps: 1949, steps per second: 542, episode reward: 274.900, mean reward: 0.141 [-133.100, 219.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.695141, mean_absolute_error: 2.013283, mean_q: -0.271493\n",
      "[-1.0855597  1.0506608]\n",
      "[-1.3600852  1.0096475]\n",
      "[-1.4384305  1.4941528]\n",
      "[-1.1000005   0.69782245]\n",
      "[-1.6160178  2.1204948]\n",
      "[47694, 1067134]\n",
      " 1114828/1500000: episode: 572, duration: 3.337s, episode steps: 1949, steps per second: 584, episode reward: 528.900, mean reward: 0.271 [-86.200, 139.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.198582, mean_absolute_error: 2.198668, mean_q: -0.272213\n",
      "[-0.46482563  1.4580903 ]\n",
      "[0.20881279 1.2910275 ]\n",
      "[-0.47479308  1.3762289 ]\n",
      "[-0.2815209  1.1438262]\n",
      "[47779, 1068998]\n",
      " 1116777/1500000: episode: 573, duration: 3.351s, episode steps: 1949, steps per second: 582, episode reward: 604.000, mean reward: 0.310 [-102.800, 157.200], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.612694, mean_absolute_error: 2.031712, mean_q: -0.272624\n",
      "[-1.4904522  0.9733049]\n",
      "[-0.42875248  1.0387311 ]\n",
      "[-0.5320772  1.6339114]\n",
      "[-0.67477715  1.4436947 ]\n",
      "[-1.3118246   0.48638147]\n",
      "[47847, 1070879]\n",
      " 1118726/1500000: episode: 574, duration: 3.335s, episode steps: 1949, steps per second: 584, episode reward: 408.900, mean reward: 0.210 [-201.300, 177.300], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.816162, mean_absolute_error: 2.159868, mean_q: -0.272785\n",
      "[-1.0872557  0.9497907]\n",
      "[-0.6523488  1.1060196]\n",
      "[-1.9272506  1.5052497]\n",
      "[-0.8378469  0.7816467]\n",
      "[-0.7649631  0.6489257]\n",
      "[47919, 1072756]\n",
      " 1120675/1500000: episode: 575, duration: 3.293s, episode steps: 1949, steps per second: 592, episode reward: 754.800, mean reward: 0.387 [-82.500, 194.000], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.737213, mean_absolute_error: 2.238525, mean_q: -0.273112\n",
      "[-0.9103981  1.3217602]\n",
      "[-0.1999086  0.7084337]\n",
      "[-1.5852827  1.0511483]\n",
      "[-0.9655699   0.69054013]\n",
      "[-1.3557317  1.3141888]\n",
      "[48016, 1074608]\n",
      " 1122624/1500000: episode: 576, duration: 3.363s, episode steps: 1949, steps per second: 580, episode reward: 550.600, mean reward: 0.283 [-89.600, 173.500], mean action: 0.950 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.364811, mean_absolute_error: 2.149533, mean_q: -0.273789\n",
      "[-1.4164766  1.3299425]\n",
      "[-0.9826163  1.0583777]\n",
      "[-0.5775964  0.9414528]\n",
      "[-0.75394005  0.7844055 ]\n",
      "[-1.1600754  1.776738 ]\n",
      "[48082, 1076491]\n",
      " 1124573/1500000: episode: 577, duration: 3.477s, episode steps: 1949, steps per second: 561, episode reward: 306.600, mean reward: 0.157 [-159.200, 146.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.815319, mean_absolute_error: 1.929081, mean_q: -0.274685\n",
      "[-1.2618355  1.8078307]\n",
      "[-0.7146951  1.488483 ]\n",
      "[-1.6547792  1.8491262]\n",
      "[-1.0356069  0.7777325]\n",
      "[-0.56774855  1.1322417 ]\n",
      "[48158, 1078364]\n",
      " 1126522/1500000: episode: 578, duration: 3.373s, episode steps: 1949, steps per second: 578, episode reward: 322.800, mean reward: 0.166 [-91.700, 119.600], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 76.535210, mean_absolute_error: 2.352435, mean_q: -0.276093\n",
      "[-0.35007438  1.5203141 ]\n",
      "[-0.27935505  1.3954935 ]\n",
      "[-0.33382002  1.3156307 ]\n",
      "[-0.52496195  1.350173  ]\n",
      "[-0.35531485  1.4944955 ]\n",
      "[48245, 1080226]\n",
      " 1128471/1500000: episode: 579, duration: 3.337s, episode steps: 1949, steps per second: 584, episode reward: 469.000, mean reward: 0.241 [-112.700, 145.900], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.971115, mean_absolute_error: 1.969746, mean_q: -0.277508\n",
      "[-1.1930141  1.2380208]\n",
      "[-0.739055   1.1098274]\n",
      "[-1.2167114  1.4671165]\n",
      "[-1.0572478  1.6381505]\n",
      "[-0.5544319  1.6342899]\n",
      "[48340, 1082080]\n",
      " 1130420/1500000: episode: 580, duration: 3.389s, episode steps: 1949, steps per second: 575, episode reward: 824.000, mean reward: 0.423 [-75.300, 199.200], mean action: 0.951 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 70.809296, mean_absolute_error: 2.406692, mean_q: -0.278838\n",
      "[-0.89218485  0.9960606 ]\n",
      "[-0.8759069  1.5423083]\n",
      "[-0.4955888  1.3427987]\n",
      "[-0.60173506  0.9132492 ]\n",
      "[48425, 1083944]\n",
      " 1132369/1500000: episode: 581, duration: 3.310s, episode steps: 1949, steps per second: 589, episode reward: 339.400, mean reward: 0.174 [-96.800, 148.000], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.605576, mean_absolute_error: 1.992100, mean_q: -0.280106\n",
      "[-0.8670568  0.9370003]\n",
      "[-0.9243217  1.3403958]\n",
      "[-0.85799915  1.6189361 ]\n",
      "[-0.35326812  0.91881126]\n",
      "[-1.3564987  1.0184184]\n",
      "[48495, 1085823]\n",
      " 1134318/1500000: episode: 582, duration: 3.335s, episode steps: 1949, steps per second: 584, episode reward: 183.400, mean reward: 0.094 [-113.000, 165.000], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.097134, mean_absolute_error: 1.909095, mean_q: -0.281182\n",
      "[-0.8815347  1.2794378]\n",
      "[-0.80256677  1.6976701 ]\n",
      "[-0.3972791   0.90395045]\n",
      "[-0.7516782  1.3205191]\n",
      "[-0.5107927  1.4317107]\n",
      "[48586, 1087681]\n",
      " 1136267/1500000: episode: 583, duration: 3.612s, episode steps: 1949, steps per second: 540, episode reward: 275.100, mean reward: 0.141 [-123.000, 114.700], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 29.659010, mean_absolute_error: 1.664950, mean_q: -0.282220\n",
      "[-0.58353215  1.4019663 ]\n",
      "[-0.8545902  0.9782112]\n",
      "[-0.3701532  1.1907221]\n",
      "[-0.92454296  0.90042037]\n",
      "[-0.7727179  1.0113062]\n",
      "[48665, 1089551]\n",
      " 1138216/1500000: episode: 584, duration: 3.251s, episode steps: 1949, steps per second: 599, episode reward: 514.000, mean reward: 0.264 [-137.500, 158.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.511986, mean_absolute_error: 1.917552, mean_q: -0.283333\n",
      "[-0.3466245  1.5657638]\n",
      "[-0.3877939  1.4016298]\n",
      "[-1.1583726  1.2651945]\n",
      "[-0.9346306  1.3679365]\n",
      "[-0.20557833  1.1382607 ]\n",
      "[48733, 1091432]\n",
      " 1140165/1500000: episode: 585, duration: 3.168s, episode steps: 1949, steps per second: 615, episode reward: 318.500, mean reward: 0.163 [-142.900, 210.000], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.650505, mean_absolute_error: 2.054676, mean_q: -0.283997\n",
      "[-1.0108987   0.95345557]\n",
      "[-1.1205214  0.1622669]\n",
      "[-0.5243532  1.5002875]\n",
      "[-0.6998816  1.2667601]\n",
      "[-1.0954088  1.142572 ]\n",
      "[48811, 1093303]\n",
      " 1142114/1500000: episode: 586, duration: 3.567s, episode steps: 1949, steps per second: 546, episode reward: 85.100, mean reward: 0.044 [-107.600, 111.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.121681, mean_absolute_error: 2.136212, mean_q: -0.284638\n",
      "[-0.99475324  1.3613387 ]\n",
      "[-1.02176     0.68280584]\n",
      "[-0.22312655  1.7147282 ]\n",
      "[-0.8114477  1.6786374]\n",
      "[-0.65828615  1.6108828 ]\n",
      "[48885, 1095178]\n",
      " 1144063/1500000: episode: 587, duration: 3.423s, episode steps: 1949, steps per second: 569, episode reward: 331.000, mean reward: 0.170 [-93.900, 118.500], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 26.434021, mean_absolute_error: 1.612143, mean_q: -0.285274\n",
      "[-0.9998803  1.7862496]\n",
      "[-1.1037929  1.3984001]\n",
      "[-0.983593   1.0065212]\n",
      "[-1.4026175  1.392602 ]\n",
      "[-1.1813886  1.5982763]\n",
      "[48954, 1097058]\n",
      " 1146012/1500000: episode: 588, duration: 3.355s, episode steps: 1949, steps per second: 581, episode reward: 522.300, mean reward: 0.268 [-72.400, 149.400], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 74.780746, mean_absolute_error: 2.439379, mean_q: -0.286034\n",
      "[-1.4599208  0.7417115]\n",
      "[-0.92591214  1.2813824 ]\n",
      "[-0.32933128  1.2098973 ]\n",
      "[-1.0844909  1.1064147]\n",
      "[49036, 1098925]\n",
      " 1147961/1500000: episode: 589, duration: 3.349s, episode steps: 1949, steps per second: 582, episode reward: 591.900, mean reward: 0.304 [-96.300, 149.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 61.088329, mean_absolute_error: 2.142721, mean_q: -0.286685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0293336  1.3398552]\n",
      "[-0.57381517  1.2513013 ]\n",
      "[0.03729499 1.7134509 ]\n",
      "[-0.6282244  1.1493795]\n",
      "[-1.0547432  1.4845577]\n",
      "[49119, 1100791]\n",
      " 1149910/1500000: episode: 590, duration: 3.346s, episode steps: 1949, steps per second: 582, episode reward: 714.800, mean reward: 0.367 [-118.800, 162.700], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.970249, mean_absolute_error: 1.908169, mean_q: -0.287284\n",
      "[-0.87397    1.0319988]\n",
      "[-1.1489336  2.1148417]\n",
      "[-0.9454881  1.7988592]\n",
      "[-0.8679849  1.9067208]\n",
      "[-1.5898762  1.4936051]\n",
      "[49200, 1102659]\n",
      " 1151859/1500000: episode: 591, duration: 3.261s, episode steps: 1949, steps per second: 598, episode reward: 495.000, mean reward: 0.254 [-80.100, 139.100], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 76.435028, mean_absolute_error: 2.439809, mean_q: -0.287928\n",
      "[-1.1116602  1.0595024]\n",
      "[-1.2264585  1.6278545]\n",
      "[-0.50001246  1.1996961 ]\n",
      "[-0.46122822  1.1744123 ]\n",
      "[-0.9334091  1.6144158]\n",
      "[49268, 1104540]\n",
      " 1153808/1500000: episode: 592, duration: 3.386s, episode steps: 1949, steps per second: 576, episode reward: 552.200, mean reward: 0.283 [-136.700, 200.200], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.932037, mean_absolute_error: 1.765277, mean_q: -0.288730\n",
      "[-0.6297928  1.6124586]\n",
      "[-0.45733353  0.6804965 ]\n",
      "[-0.30255923  0.6199488 ]\n",
      "[-0.525924    0.86578596]\n",
      "[-1.7055916   0.64647084]\n",
      "[49341, 1106416]\n",
      " 1155757/1500000: episode: 593, duration: 3.204s, episode steps: 1949, steps per second: 608, episode reward: 711.400, mean reward: 0.365 [-104.000, 239.600], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.262077, mean_absolute_error: 2.001956, mean_q: -0.289475\n",
      "[-1.7043245  0.961517 ]\n",
      "[-0.62096375  0.72486234]\n",
      "[-0.7920553  0.6607933]\n",
      "[-0.7200027  1.1906679]\n",
      "[-1.2726024  1.0435445]\n",
      "[49436, 1108270]\n",
      " 1157706/1500000: episode: 594, duration: 3.228s, episode steps: 1949, steps per second: 604, episode reward: 534.400, mean reward: 0.274 [-83.200, 163.300], mean action: 0.951 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.061207, mean_absolute_error: 1.944808, mean_q: -0.290138\n",
      "[-1.3827827  0.9262863]\n",
      "[-0.4764685   0.71811223]\n",
      "[-0.9304668  0.9654618]\n",
      "[-0.44047475  1.0510868 ]\n",
      "[-1.283053   1.2885604]\n",
      "[49513, 1110142]\n",
      " 1159655/1500000: episode: 595, duration: 3.479s, episode steps: 1949, steps per second: 560, episode reward: 782.500, mean reward: 0.401 [-184.300, 167.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.164719, mean_absolute_error: 1.849925, mean_q: -0.290875\n",
      "[-1.3360901  1.3226527]\n",
      "[-1.6258289  1.4130157]\n",
      "[-0.5175404   0.93935794]\n",
      "[-1.1222513  1.0607667]\n",
      "[-0.92794    0.8028913]\n",
      "[49595, 1112009]\n",
      " 1161604/1500000: episode: 596, duration: 3.796s, episode steps: 1949, steps per second: 513, episode reward: 658.500, mean reward: 0.338 [-147.500, 174.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 62.461105, mean_absolute_error: 2.218415, mean_q: -0.291665\n",
      "[-1.8340174  0.7634086]\n",
      "[-1.2564286  1.1119063]\n",
      "[-1.0871614  1.0219828]\n",
      "[-0.9631141   0.86211836]\n",
      "[49662, 1113891]\n",
      " 1163553/1500000: episode: 597, duration: 3.423s, episode steps: 1949, steps per second: 569, episode reward: 759.800, mean reward: 0.390 [-167.700, 221.400], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 72.993103, mean_absolute_error: 2.645487, mean_q: -0.292443\n",
      "[-1.1519753  1.1396754]\n",
      "[-0.873962   1.5102623]\n",
      "[-1.0268072   0.39092234]\n",
      "[-0.68978375  0.66582596]\n",
      "[-0.7725452  1.495173 ]\n",
      "[49735, 1115767]\n",
      " 1165502/1500000: episode: 598, duration: 3.335s, episode steps: 1949, steps per second: 584, episode reward: 171.000, mean reward: 0.088 [-91.800, 189.300], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.143597, mean_absolute_error: 1.685730, mean_q: -0.293015\n",
      "[-0.6573524  0.9701122]\n",
      "[0.35594857 1.156442  ]\n",
      "[-1.1275558   0.84342194]\n",
      "[-0.553984   1.0492936]\n",
      "[-1.152483    0.77019805]\n",
      "[49814, 1117637]\n",
      " 1167451/1500000: episode: 599, duration: 3.335s, episode steps: 1949, steps per second: 584, episode reward: 353.100, mean reward: 0.181 [-114.500, 200.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.890430, mean_absolute_error: 2.023930, mean_q: -0.293803\n",
      "[-1.5530939  1.6474445]\n",
      "[-1.2035952  1.7233788]\n",
      "[-0.3707711   0.96069163]\n",
      "[-0.6809872  0.9570272]\n",
      "[-0.16515274  1.4423574 ]\n",
      "[49900, 1119500]\n",
      " 1169400/1500000: episode: 600, duration: 3.334s, episode steps: 1949, steps per second: 585, episode reward: 409.700, mean reward: 0.210 [-123.600, 198.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 69.364037, mean_absolute_error: 2.327331, mean_q: -0.294467\n",
      "[-0.9368813  0.9556029]\n",
      "[-0.28716925  0.892134  ]\n",
      "[-0.92889786  1.1718864 ]\n",
      "[-0.81135845  1.7145618 ]\n",
      "[-1.2098951  1.5551155]\n",
      "[49966, 1121383]\n",
      " 1171349/1500000: episode: 601, duration: 3.547s, episode steps: 1949, steps per second: 550, episode reward: 847.800, mean reward: 0.435 [-93.900, 153.500], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.839916, mean_absolute_error: 1.574786, mean_q: -0.295020\n",
      "[-0.8614874  1.3022894]\n",
      "[-0.16358034  0.87103593]\n",
      "[-0.99063814  0.75266284]\n",
      "[-0.5851498  1.1726753]\n",
      "[-1.0935718  1.5849501]\n",
      "[50047, 1123251]\n",
      " 1173298/1500000: episode: 602, duration: 3.424s, episode steps: 1949, steps per second: 569, episode reward: 553.500, mean reward: 0.284 [-132.000, 213.800], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.056435, mean_absolute_error: 2.041495, mean_q: -0.295539\n",
      "[-1.2225084  1.0507405]\n",
      "[-0.87943727  1.5531336 ]\n",
      "[-0.78613174  1.6965183 ]\n",
      "[-0.7027951  1.5330414]\n",
      "[0.22429797 1.3535004 ]\n",
      "[50136, 1125111]\n",
      " 1175247/1500000: episode: 603, duration: 3.539s, episode steps: 1949, steps per second: 551, episode reward: 491.100, mean reward: 0.252 [-135.200, 218.900], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.718384, mean_absolute_error: 1.823541, mean_q: -0.295780\n",
      "[-0.8720534  1.1968033]\n",
      "[-0.08086073  1.4219301 ]\n",
      "[-0.49318504  2.0359428 ]\n",
      "[-0.7206643  0.969172 ]\n",
      "[50223, 1126973]\n",
      " 1177196/1500000: episode: 604, duration: 3.265s, episode steps: 1949, steps per second: 597, episode reward: -30.100, mean reward: -0.015 [-168.700, 142.800], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.815422, mean_absolute_error: 1.799614, mean_q: -0.295842\n",
      "[-1.0054882  1.1064376]\n",
      "[-0.8542494  0.3961877]\n",
      "[-0.20160224  1.3479899 ]\n",
      "[-0.7271785  1.2205411]\n",
      "[-0.36907738  0.9586091 ]\n",
      "[50293, 1128852]\n",
      " 1179145/1500000: episode: 605, duration: 3.223s, episode steps: 1949, steps per second: 605, episode reward: 601.400, mean reward: 0.309 [-99.100, 140.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.111839, mean_absolute_error: 2.077944, mean_q: -0.295777\n",
      "[-1.1927936  1.4103849]\n",
      "[-1.79096    1.5326777]\n",
      "[-1.1280954  1.2705879]\n",
      "[-0.6442414  1.4001471]\n",
      "[-0.39066017  1.0709128 ]\n",
      "[50362, 1130732]\n",
      " 1181094/1500000: episode: 606, duration: 3.235s, episode steps: 1949, steps per second: 602, episode reward: 560.700, mean reward: 0.288 [-77.900, 184.300], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.895145, mean_absolute_error: 1.922425, mean_q: -0.295601\n",
      "[-1.2097609  1.1858382]\n",
      "[-1.265058   1.2161844]\n",
      "[-0.9468221   0.95565206]\n",
      "[-1.1185457  2.028122 ]\n",
      "[-0.60573    1.2247949]\n",
      "[50451, 1132592]\n",
      " 1183043/1500000: episode: 607, duration: 3.298s, episode steps: 1949, steps per second: 591, episode reward: 521.700, mean reward: 0.268 [-69.100, 191.600], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.130863, mean_absolute_error: 1.988353, mean_q: -0.295779\n",
      "[-0.81075215  0.6359871 ]\n",
      "[-0.769279   1.0325952]\n",
      "[-1.0298601  1.3024873]\n",
      "[-1.1786271   0.91996396]\n",
      "[-1.3813355  0.4317154]\n",
      "[50527, 1134465]\n",
      " 1184992/1500000: episode: 608, duration: 3.346s, episode steps: 1949, steps per second: 582, episode reward: 213.200, mean reward: 0.109 [-187.000, 168.800], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.046989, mean_absolute_error: 2.220070, mean_q: -0.295980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6618632  1.2443745]\n",
      "[-0.87667733  1.2128216 ]\n",
      "[-0.8380086  1.2303872]\n",
      "[-1.0906614  1.4866556]\n",
      "[-1.0839127  1.3935574]\n",
      "[50609, 1136332]\n",
      " 1186941/1500000: episode: 609, duration: 3.390s, episode steps: 1949, steps per second: 575, episode reward: 565.800, mean reward: 0.290 [-77.200, 191.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.887741, mean_absolute_error: 1.951797, mean_q: -0.295802\n",
      "[-0.87079275  0.9102493 ]\n",
      "[-0.82706195  1.0470626 ]\n",
      "[-0.41758102  1.240504  ]\n",
      "[-0.22491953  1.6117147 ]\n",
      "[-0.6199358  1.3820951]\n",
      "[50686, 1138204]\n",
      " 1188890/1500000: episode: 610, duration: 3.295s, episode steps: 1949, steps per second: 591, episode reward: 545.200, mean reward: 0.280 [-100.200, 150.400], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.754330, mean_absolute_error: 2.198108, mean_q: -0.295841\n",
      "[-1.1611853  0.8740097]\n",
      "[-1.0703583  1.4546673]\n",
      "[-1.3848785  1.8023359]\n",
      "[-1.320983   1.9061843]\n",
      "[-1.3557357  0.754687 ]\n",
      "[50769, 1140070]\n",
      " 1190839/1500000: episode: 611, duration: 3.430s, episode steps: 1949, steps per second: 568, episode reward: 280.200, mean reward: 0.144 [-96.400, 165.100], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.074562, mean_absolute_error: 2.103030, mean_q: -0.296081\n",
      "[-1.2136251  1.5235678]\n",
      "[-1.0203558  1.2938955]\n",
      "[-0.9760577  1.7503649]\n",
      "[-1.1004052   0.68029684]\n",
      "[50856, 1141932]\n",
      " 1192788/1500000: episode: 612, duration: 3.548s, episode steps: 1949, steps per second: 549, episode reward: 481.600, mean reward: 0.247 [-188.000, 153.300], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.866779, mean_absolute_error: 2.147292, mean_q: -0.296359\n",
      "[-1.0103539  1.0182599]\n",
      "[-0.46968848  0.59970486]\n",
      "[-0.689641   1.3714739]\n",
      "[-1.1842843  1.554755 ]\n",
      "[-0.7874784  2.0079293]\n",
      "[50934, 1143803]\n",
      " 1194737/1500000: episode: 613, duration: 4.120s, episode steps: 1949, steps per second: 473, episode reward: 249.800, mean reward: 0.128 [-89.000, 179.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.489830, mean_absolute_error: 1.929037, mean_q: -0.296917\n",
      "[-1.0371948  1.0729918]\n",
      "[-0.80273914  1.2778753 ]\n",
      "[-1.0566145  1.9673376]\n",
      "[-0.46096426  0.5528884 ]\n",
      "[-0.3770843  1.1122702]\n",
      "[51006, 1145680]\n",
      " 1196686/1500000: episode: 614, duration: 3.560s, episode steps: 1949, steps per second: 547, episode reward: 742.500, mean reward: 0.381 [-103.300, 148.100], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 76.377037, mean_absolute_error: 2.382457, mean_q: -0.297882\n",
      "[-0.40552413  1.1639661 ]\n",
      "[-1.0452309  0.9320382]\n",
      "[-0.42583346  1.444154  ]\n",
      "[-0.6507123  1.7884392]\n",
      "[-0.14234403  0.86913097]\n",
      "[51105, 1147530]\n",
      " 1198635/1500000: episode: 615, duration: 3.435s, episode steps: 1949, steps per second: 567, episode reward: 449.200, mean reward: 0.230 [-138.400, 214.700], mean action: 0.949 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 70.148636, mean_absolute_error: 2.380120, mean_q: -0.298835\n",
      "[-0.74030775  0.9880443 ]\n",
      "[-0.9796064  1.2885842]\n",
      "[-0.80193913  1.5756173 ]\n",
      "[-1.1866962  1.1542209]\n",
      "[-0.3968208  1.5175622]\n",
      "[51191, 1149393]\n",
      " 1200584/1500000: episode: 616, duration: 3.351s, episode steps: 1949, steps per second: 582, episode reward: 491.500, mean reward: 0.252 [-91.500, 166.300], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.211288, mean_absolute_error: 1.981747, mean_q: -0.299477\n",
      "[-1.1753503  1.4354156]\n",
      "[-0.895365   1.3333181]\n",
      "[-1.382001   1.7156832]\n",
      "[-1.1730949  0.9216447]\n",
      "[-1.0260855   0.23836271]\n",
      "[51255, 1151278]\n",
      " 1202533/1500000: episode: 617, duration: 3.333s, episode steps: 1949, steps per second: 585, episode reward: 487.800, mean reward: 0.250 [-97.600, 134.000], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.206116, mean_absolute_error: 1.798706, mean_q: -0.299920\n",
      "[-0.747207   1.9794681]\n",
      "[-0.2529173  1.5842484]\n",
      "[-0.5732721  1.0988414]\n",
      "[-0.7893912  1.0170875]\n",
      "[-0.96503353  1.2337221 ]\n",
      "[51322, 1153160]\n",
      " 1204482/1500000: episode: 618, duration: 3.440s, episode steps: 1949, steps per second: 567, episode reward: 245.700, mean reward: 0.126 [-168.700, 130.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.879028, mean_absolute_error: 2.153317, mean_q: -0.300492\n",
      "[-0.3950023   0.64671594]\n",
      "[-0.7189913  0.6923354]\n",
      "[-1.3712503   0.57136136]\n",
      "[-1.0366658  1.529924 ]\n",
      "[-0.63568515  1.6834573 ]\n",
      "[51401, 1155030]\n",
      " 1206431/1500000: episode: 619, duration: 3.459s, episode steps: 1949, steps per second: 563, episode reward: 324.000, mean reward: 0.166 [-122.600, 162.700], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 43.136841, mean_absolute_error: 1.831537, mean_q: -0.301712\n",
      "[-1.0540528  1.0060893]\n",
      "[-1.0363507  1.149725 ]\n",
      "[-0.62552863  1.5080751 ]\n",
      "[-0.57593465  1.7837886 ]\n",
      "[51463, 1156917]\n",
      " 1208380/1500000: episode: 620, duration: 3.487s, episode steps: 1949, steps per second: 559, episode reward: 703.100, mean reward: 0.361 [-102.100, 156.300], mean action: 0.968 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 29.309103, mean_absolute_error: 1.704402, mean_q: -0.303027\n",
      "[-0.85427237  0.9946338 ]\n",
      "[-0.17730047  1.5885247 ]\n",
      "[-1.0014393  1.8711234]\n",
      "[-0.77774966  1.8941488 ]\n",
      "[-1.1896349  1.6170675]\n",
      "[51555, 1158774]\n",
      " 1210329/1500000: episode: 621, duration: 3.438s, episode steps: 1949, steps per second: 567, episode reward: 327.900, mean reward: 0.168 [-115.900, 167.000], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.322021, mean_absolute_error: 2.090030, mean_q: -0.304570\n",
      "[-0.95100087  1.1474221 ]\n",
      "[-1.0407834  1.125713 ]\n",
      "[-1.269492   0.8424105]\n",
      "[-0.70505524  1.6633186 ]\n",
      "[-0.8541169  1.0251554]\n",
      "[51622, 1160656]\n",
      " 1212278/1500000: episode: 622, duration: 3.616s, episode steps: 1949, steps per second: 539, episode reward: 455.100, mean reward: 0.234 [-82.000, 154.000], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.580566, mean_absolute_error: 1.780616, mean_q: -0.305934\n",
      "[-1.0784663  1.3289721]\n",
      "[-0.7282763  0.7895927]\n",
      "[-0.39222303  1.1102346 ]\n",
      "[-0.67934513  1.8094347 ]\n",
      "[-0.56216395  1.4414302 ]\n",
      "[51711, 1162516]\n",
      " 1214227/1500000: episode: 623, duration: 3.378s, episode steps: 1949, steps per second: 577, episode reward: 250.600, mean reward: 0.129 [-100.200, 204.900], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 65.838531, mean_absolute_error: 2.314091, mean_q: -0.307300\n",
      "[-0.94634944  1.152314  ]\n",
      "[-0.86892533  1.5993938 ]\n",
      "[-1.2742332  1.962211 ]\n",
      "[-1.3124791  1.6649395]\n",
      "[-1.1163836  1.1251119]\n",
      "[51794, 1164382]\n",
      " 1216176/1500000: episode: 624, duration: 3.422s, episode steps: 1949, steps per second: 569, episode reward: 730.100, mean reward: 0.375 [-68.500, 175.000], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 31.110456, mean_absolute_error: 1.722100, mean_q: -0.308426\n",
      "[-0.58118695  1.3254731 ]\n",
      "[-1.2895232  1.4165299]\n",
      "[-1.2423203  1.0544008]\n",
      "[-0.44484508  1.9638526 ]\n",
      "[-1.0592813  1.4904728]\n",
      "[51859, 1166266]\n",
      " 1218125/1500000: episode: 625, duration: 3.345s, episode steps: 1949, steps per second: 583, episode reward: 928.500, mean reward: 0.476 [-192.100, 156.300], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.660179, mean_absolute_error: 1.620910, mean_q: -0.309372\n",
      "[-0.6271467  0.8700599]\n",
      "[-0.99077797  1.7836627 ]\n",
      "[-0.36325008  1.2190461 ]\n",
      "[-0.70134914  1.208365  ]\n",
      "[-1.3058436  1.3647753]\n",
      "[51941, 1168133]\n",
      " 1220074/1500000: episode: 626, duration: 3.541s, episode steps: 1949, steps per second: 550, episode reward: 285.400, mean reward: 0.146 [-129.200, 149.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.534153, mean_absolute_error: 2.075679, mean_q: -0.310343\n",
      "[-1.0847676  1.3373684]\n",
      "[-1.156859   1.4563907]\n",
      "[-0.3602677  1.2250221]\n",
      "[-0.6665282  1.2979337]\n",
      "[-0.91878396  1.5620375 ]\n",
      "[52032, 1169991]\n",
      " 1222023/1500000: episode: 627, duration: 3.204s, episode steps: 1949, steps per second: 608, episode reward: 512.900, mean reward: 0.263 [-78.300, 190.600], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 20.405708, mean_absolute_error: 1.430165, mean_q: -0.311460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37140423  1.1947467 ]\n",
      "[-0.59468085  1.0912596 ]\n",
      "[-0.34033567  1.406225  ]\n",
      "[-0.7257767   0.17686538]\n",
      "[52117, 1171855]\n",
      " 1223972/1500000: episode: 628, duration: 3.368s, episode steps: 1949, steps per second: 579, episode reward: 545.200, mean reward: 0.280 [-83.600, 144.400], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.738117, mean_absolute_error: 1.914268, mean_q: -0.312888\n",
      "[-0.9093286  1.1080892]\n",
      "[-1.0713354  0.8002008]\n",
      "[-0.72713083  1.0889277 ]\n",
      "[-1.1143929  1.4780082]\n",
      "[-1.1742395  1.1534561]\n",
      "[52181, 1173740]\n",
      " 1225921/1500000: episode: 629, duration: 3.245s, episode steps: 1949, steps per second: 601, episode reward: 596.600, mean reward: 0.306 [-124.300, 234.400], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.523983, mean_absolute_error: 1.745360, mean_q: -0.314149\n",
      "[-0.9950569   0.81996447]\n",
      "[-0.77437645  0.34292972]\n",
      "[-0.6872927  0.613076 ]\n",
      "[-0.5309923  0.654848 ]\n",
      "[-0.6221775   0.94061685]\n",
      "[52247, 1175623]\n",
      " 1227870/1500000: episode: 630, duration: 3.410s, episode steps: 1949, steps per second: 571, episode reward: 256.900, mean reward: 0.132 [-168.700, 108.600], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.391205, mean_absolute_error: 2.020187, mean_q: -0.315587\n",
      "[-0.34306404  1.2266953 ]\n",
      "[-0.26535875  0.6634869 ]\n",
      "[-0.25349256  0.88517976]\n",
      "[-1.1403723  1.2252941]\n",
      "[-0.49281222  0.89466906]\n",
      "[52333, 1177486]\n",
      " 1229819/1500000: episode: 631, duration: 3.345s, episode steps: 1949, steps per second: 583, episode reward: 479.900, mean reward: 0.246 [-92.100, 143.100], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 23.309299, mean_absolute_error: 1.522315, mean_q: -0.316949\n",
      "[-1.2069241  1.3410338]\n",
      "[-0.9628126  0.8141098]\n",
      "[-0.84348345  1.2958789 ]\n",
      "[-1.0096434  1.2146474]\n",
      "[-0.401246  1.048674]\n",
      "[52412, 1179356]\n",
      " 1231768/1500000: episode: 632, duration: 3.388s, episode steps: 1949, steps per second: 575, episode reward: 343.700, mean reward: 0.176 [-102.800, 177.100], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.852211, mean_absolute_error: 1.898414, mean_q: -0.318515\n",
      "[-1.1771563   0.83898515]\n",
      "[-0.9064996   0.68460256]\n",
      "[-1.7746888  0.4401102]\n",
      "[-1.1307924   0.91872793]\n",
      "[-1.4086013  1.0474958]\n",
      "[52489, 1181228]\n",
      " 1233717/1500000: episode: 633, duration: 3.335s, episode steps: 1949, steps per second: 584, episode reward: 320.900, mean reward: 0.165 [-182.600, 155.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 95.988533, mean_absolute_error: 2.632474, mean_q: -0.320220\n",
      "[-1.0846554  1.5075717]\n",
      "[-0.9232351  1.5013776]\n",
      "[-1.0811986  1.07     ]\n",
      "[-1.3835185  1.3418653]\n",
      "[-0.8754306  1.6307727]\n",
      "[52570, 1183096]\n",
      " 1235666/1500000: episode: 634, duration: 3.376s, episode steps: 1949, steps per second: 577, episode reward: 233.100, mean reward: 0.120 [-83.800, 214.700], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.485241, mean_absolute_error: 2.204818, mean_q: -0.321549\n",
      "[-1.4649502  1.0156398]\n",
      "[-0.17916827  1.1997416 ]\n",
      "[-0.3102398   0.13861042]\n",
      "[-0.30840957  1.1901321 ]\n",
      "[-1.2059231  1.0171177]\n",
      "[52695, 1184920]\n",
      " 1237615/1500000: episode: 635, duration: 3.338s, episode steps: 1949, steps per second: 584, episode reward: 526.300, mean reward: 0.270 [-113.100, 137.200], mean action: 0.936 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 77.897301, mean_absolute_error: 2.279994, mean_q: -0.322650\n",
      "[-0.7099752  1.3990513]\n",
      "[-0.30346128  1.6247361 ]\n",
      "[-0.7399661  1.5139754]\n",
      "[-1.0341085  0.8203309]\n",
      "[52772, 1186792]\n",
      " 1239564/1500000: episode: 636, duration: 3.464s, episode steps: 1949, steps per second: 563, episode reward: 615.000, mean reward: 0.316 [-114.500, 163.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 30.156565, mean_absolute_error: 1.764541, mean_q: -0.323486\n",
      "[-0.9222664  1.0952059]\n",
      "[-0.61798364  1.3570943 ]\n",
      "[-0.39297622  1.4408404 ]\n",
      "[-1.3744217  1.8022188]\n",
      "[-1.3977745  1.0993614]\n",
      "[52847, 1188666]\n",
      " 1241513/1500000: episode: 637, duration: 3.423s, episode steps: 1949, steps per second: 569, episode reward: 662.300, mean reward: 0.340 [-92.800, 148.100], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.919964, mean_absolute_error: 1.960606, mean_q: -0.324405\n",
      "[-1.0895308  1.3648466]\n",
      "[-0.73432803  1.401995  ]\n",
      "[-0.72341514  0.8025112 ]\n",
      "[-0.45475012  1.3850276 ]\n",
      "[-0.9019251  0.9447417]\n",
      "[52920, 1190542]\n",
      " 1243462/1500000: episode: 638, duration: 3.788s, episode steps: 1949, steps per second: 515, episode reward: 449.900, mean reward: 0.231 [-79.000, 150.500], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.988449, mean_absolute_error: 1.754536, mean_q: -0.325340\n",
      "[-0.9710042  0.9902114]\n",
      "[-0.9995041  1.546409 ]\n",
      "[-1.2521151  1.8839297]\n",
      "[-0.6479256  1.6128651]\n",
      "[-0.95557225  1.161634  ]\n",
      "[53014, 1192397]\n",
      " 1245411/1500000: episode: 639, duration: 3.387s, episode steps: 1949, steps per second: 575, episode reward: 108.600, mean reward: 0.056 [-194.500, 160.200], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.081444, mean_absolute_error: 2.005763, mean_q: -0.326274\n",
      "[-1.0174353   0.23489445]\n",
      "[-0.34739366  1.0214475 ]\n",
      "[-0.78050196  1.7201993 ]\n",
      "[-0.7317063  1.6969548]\n",
      "[-1.048846   1.1351743]\n",
      "[53099, 1194261]\n",
      " 1247360/1500000: episode: 640, duration: 3.387s, episode steps: 1949, steps per second: 575, episode reward: 834.900, mean reward: 0.428 [-110.000, 202.100], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.151028, mean_absolute_error: 1.683738, mean_q: -0.327184\n",
      "[-0.93800783  1.5087571 ]\n",
      "[-0.6862353   0.50302815]\n",
      "[-1.0422711   0.55993336]\n",
      "[-0.81075186  0.6172803 ]\n",
      "[-0.5362827  1.0814836]\n",
      "[53180, 1196129]\n",
      " 1249309/1500000: episode: 641, duration: 3.385s, episode steps: 1949, steps per second: 576, episode reward: 874.700, mean reward: 0.449 [-82.400, 154.500], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 24.641388, mean_absolute_error: 1.421597, mean_q: -0.328515\n",
      "[-0.35030782  1.5078884 ]\n",
      "[-1.1790609  1.5807489]\n",
      "[-0.4428206  1.1080755]\n",
      "[-1.3157201  0.9770877]\n",
      "[-1.166263    0.40429667]\n",
      "[53248, 1198010]\n",
      " 1251258/1500000: episode: 642, duration: 3.575s, episode steps: 1949, steps per second: 545, episode reward: 873.900, mean reward: 0.448 [-122.000, 159.400], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.239506, mean_absolute_error: 1.809911, mean_q: -0.329951\n",
      "[-0.5515584  1.4918718]\n",
      "[-1.6970965  1.2196362]\n",
      "[-1.4677541   0.55737734]\n",
      "[-0.51218235  0.98804206]\n",
      "[-0.5254488  1.2283657]\n",
      "[53318, 1199889]\n",
      " 1253207/1500000: episode: 643, duration: 3.466s, episode steps: 1949, steps per second: 562, episode reward: 396.000, mean reward: 0.203 [-149.000, 213.800], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 20.453482, mean_absolute_error: 1.566940, mean_q: -0.331355\n",
      "[-0.8511545  0.6256567]\n",
      "[-0.41129464  1.409389  ]\n",
      "[-0.9542254  2.3164225]\n",
      "[-1.1362805  1.4539272]\n",
      "[53390, 1201766]\n",
      " 1255156/1500000: episode: 644, duration: 3.403s, episode steps: 1949, steps per second: 573, episode reward: 362.500, mean reward: 0.186 [-113.400, 123.000], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.935081, mean_absolute_error: 1.674625, mean_q: -0.332548\n",
      "[-1.205196   1.1034586]\n",
      "[-0.8625761  1.3744879]\n",
      "[-1.44056    1.3157486]\n",
      "[-0.49459827  1.0250293 ]\n",
      "[-1.268009   1.0983348]\n",
      "[53480, 1203625]\n",
      " 1257105/1500000: episode: 645, duration: 3.401s, episode steps: 1949, steps per second: 573, episode reward: 661.400, mean reward: 0.339 [-119.600, 142.600], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.391678, mean_absolute_error: 2.096208, mean_q: -0.333405\n",
      "[-1.0940936  1.368078 ]\n",
      "[-1.879642   0.7234146]\n",
      "[-1.0656855  1.7351599]\n",
      "[-1.27986    1.0777918]\n",
      "[-0.7403998  0.7826823]\n",
      "[53563, 1205491]\n",
      " 1259054/1500000: episode: 646, duration: 3.436s, episode steps: 1949, steps per second: 567, episode reward: 641.700, mean reward: 0.329 [-97.500, 206.300], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.232487, mean_absolute_error: 2.264655, mean_q: -0.333860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5630823  0.8053999]\n",
      "[-1.1082239  1.095236 ]\n",
      "[-1.5091703  1.4849178]\n",
      "[-1.0078832  1.3830327]\n",
      "[-0.8072187  1.606249 ]\n",
      "[53630, 1207373]\n",
      " 1261003/1500000: episode: 647, duration: 3.538s, episode steps: 1949, steps per second: 551, episode reward: 693.300, mean reward: 0.356 [-125.200, 166.100], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.488659, mean_absolute_error: 2.071850, mean_q: -0.334163\n",
      "[-0.51736957  1.0127722 ]\n",
      "[-0.7301423  1.3168434]\n",
      "[-0.82354575  1.862906  ]\n",
      "[-0.23790298  1.4564215 ]\n",
      "[-0.2023297  1.3585724]\n",
      "[53706, 1209246]\n",
      " 1262952/1500000: episode: 648, duration: 3.640s, episode steps: 1949, steps per second: 535, episode reward: 417.400, mean reward: 0.214 [-99.300, 159.700], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.786144, mean_absolute_error: 1.805331, mean_q: -0.334936\n",
      "[-0.32216617  1.9001685 ]\n",
      "[-0.63676095  1.3811705 ]\n",
      "[-0.5849268  1.0180937]\n",
      "[0.04369691 0.6853969 ]\n",
      "[-0.4578479  1.1315429]\n",
      "[53781, 1211120]\n",
      " 1264901/1500000: episode: 649, duration: 3.262s, episode steps: 1949, steps per second: 597, episode reward: 496.900, mean reward: 0.255 [-118.800, 138.100], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.481808, mean_absolute_error: 1.875557, mean_q: -0.335795\n",
      "[-1.4647983   0.74376506]\n",
      "[-1.109993   1.5179589]\n",
      "[-0.69098663  1.6768769 ]\n",
      "[-0.3814599  1.7197196]\n",
      "[-0.87543917  1.2179688 ]\n",
      "[53856, 1212994]\n",
      " 1266850/1500000: episode: 650, duration: 3.422s, episode steps: 1949, steps per second: 569, episode reward: 530.800, mean reward: 0.272 [-96.900, 149.500], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 22.740175, mean_absolute_error: 1.399001, mean_q: -0.336853\n",
      "[-1.3961256  0.9601309]\n",
      "[-0.5987685  1.1533227]\n",
      "[-0.37511846  1.2499316 ]\n",
      "[-0.29711995  1.3000586 ]\n",
      "[53943, 1214856]\n",
      " 1268799/1500000: episode: 651, duration: 3.399s, episode steps: 1949, steps per second: 573, episode reward: 245.200, mean reward: 0.126 [-100.700, 166.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.365093, mean_absolute_error: 1.923079, mean_q: -0.337981\n",
      "[-1.0012536  1.0517184]\n",
      "[-0.53869545  0.6338867 ]\n",
      "[-0.5159939  0.693572 ]\n",
      "[-1.0192335   0.56873935]\n",
      "[-1.0041414  0.5465112]\n",
      "[54034, 1216714]\n",
      " 1270748/1500000: episode: 652, duration: 3.255s, episode steps: 1949, steps per second: 599, episode reward: 270.800, mean reward: 0.139 [-103.700, 168.100], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.308651, mean_absolute_error: 1.896300, mean_q: -0.339063\n",
      "[-0.9343643  0.918463 ]\n",
      "[-0.4092831   0.49932837]\n",
      "[-0.16953248  0.7387141 ]\n",
      "[-0.4983213  1.2692282]\n",
      "[-0.63071275  0.90019   ]\n",
      "[54113, 1218584]\n",
      " 1272697/1500000: episode: 653, duration: 3.370s, episode steps: 1949, steps per second: 578, episode reward: 571.500, mean reward: 0.293 [-126.300, 141.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.313751, mean_absolute_error: 1.992422, mean_q: -0.340418\n",
      "[-0.38042787  1.3396201 ]\n",
      "[-0.75398177  1.3794234 ]\n",
      "[-0.7920048  1.4076054]\n",
      "[-0.95744693  1.676763  ]\n",
      "[-0.87779814  1.316967  ]\n",
      "[54174, 1220472]\n",
      " 1274646/1500000: episode: 654, duration: 3.343s, episode steps: 1949, steps per second: 583, episode reward: 507.800, mean reward: 0.261 [-122.500, 158.600], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.566067, mean_absolute_error: 2.264064, mean_q: -0.341553\n",
      "[-1.0803382  1.2995931]\n",
      "[-1.060899   1.4883258]\n",
      "[-0.7024729  0.6975762]\n",
      "[-0.78093195  1.6133791 ]\n",
      "[-0.45952415  1.8145076 ]\n",
      "[54241, 1222354]\n",
      " 1276595/1500000: episode: 655, duration: 3.314s, episode steps: 1949, steps per second: 588, episode reward: 716.300, mean reward: 0.368 [-123.200, 137.500], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 26.869350, mean_absolute_error: 1.547487, mean_q: -0.342498\n",
      "[-0.5365493   0.60589504]\n",
      "[-0.64660954  0.53488696]\n",
      "[-0.8932327  1.8668159]\n",
      "[-1.1937076  1.1327242]\n",
      "[-0.82825786  1.5211993 ]\n",
      "[54312, 1224232]\n",
      " 1278544/1500000: episode: 656, duration: 3.631s, episode steps: 1949, steps per second: 537, episode reward: 863.000, mean reward: 0.443 [-183.700, 163.700], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.101639, mean_absolute_error: 2.278971, mean_q: -0.343606\n",
      "[-1.0009308  1.4820824]\n",
      "[-1.0868728  1.6182956]\n",
      "[-0.4896542  1.6773249]\n",
      "[-1.0125118  1.306167 ]\n",
      "[-0.91794086  1.5085568 ]\n",
      "[54385, 1226108]\n",
      " 1280493/1500000: episode: 657, duration: 3.343s, episode steps: 1949, steps per second: 583, episode reward: 387.900, mean reward: 0.199 [-128.500, 196.500], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.190685, mean_absolute_error: 1.794144, mean_q: -0.344338\n",
      "[-1.278618   1.0127323]\n",
      "[-0.63028973  1.2436023 ]\n",
      "[-1.2644955  1.3213592]\n",
      "[-1.6300509  1.6433039]\n",
      "[-0.52784306  1.2552549 ]\n",
      "[54459, 1227983]\n",
      " 1282442/1500000: episode: 658, duration: 3.317s, episode steps: 1949, steps per second: 588, episode reward: 407.600, mean reward: 0.209 [-88.700, 164.800], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.702103, mean_absolute_error: 1.807576, mean_q: -0.345136\n",
      "[-1.3746768  0.9062853]\n",
      "[-0.8549471  1.5389538]\n",
      "[-0.9707531  1.442744 ]\n",
      "[-0.72175366  1.5079701 ]\n",
      "[54542, 1229849]\n",
      " 1284391/1500000: episode: 659, duration: 3.400s, episode steps: 1949, steps per second: 573, episode reward: 800.100, mean reward: 0.411 [-100.800, 175.200], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 21.684523, mean_absolute_error: 1.399754, mean_q: -0.345952\n",
      "[-0.94644207  1.1149591 ]\n",
      "[-0.555332   1.7157748]\n",
      "[-0.83036524  1.5991459 ]\n",
      "[-1.1271946  1.1090232]\n",
      "[-0.9220973  0.9727119]\n",
      "[54621, 1231719]\n",
      " 1286340/1500000: episode: 660, duration: 3.423s, episode steps: 1949, steps per second: 569, episode reward: 501.300, mean reward: 0.257 [-186.000, 155.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.524628, mean_absolute_error: 2.311933, mean_q: -0.347056\n",
      "[-1.1668081  1.245883 ]\n",
      "[-2.2980387  1.222225 ]\n",
      "[-1.3607117  1.0725695]\n",
      "[-0.61669374  1.1488417 ]\n",
      "[-1.3462266   0.61348814]\n",
      "[54698, 1233591]\n",
      " 1288289/1500000: episode: 661, duration: 3.500s, episode steps: 1949, steps per second: 557, episode reward: 471.300, mean reward: 0.242 [-160.300, 210.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.933010, mean_absolute_error: 2.079578, mean_q: -0.348312\n",
      "[-1.4022921  0.9556711]\n",
      "[-1.2502743  1.5720497]\n",
      "[-1.0915685  1.3510917]\n",
      "[-0.43461588  1.0920901 ]\n",
      "[-1.1907917  0.9181552]\n",
      "[54784, 1235454]\n",
      " 1290238/1500000: episode: 662, duration: 3.361s, episode steps: 1949, steps per second: 580, episode reward: 538.500, mean reward: 0.276 [-143.600, 163.500], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.948399, mean_absolute_error: 2.152456, mean_q: -0.349526\n",
      "[-1.081097   0.7332006]\n",
      "[-0.5881673   0.40206772]\n",
      "[-0.7386294  1.0571035]\n",
      "[-1.088481   0.9865633]\n",
      "[-1.2072055  1.3271205]\n",
      "[54868, 1237319]\n",
      " 1292187/1500000: episode: 663, duration: 3.348s, episode steps: 1949, steps per second: 582, episode reward: 512.200, mean reward: 0.263 [-139.800, 169.700], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.002728, mean_absolute_error: 2.081975, mean_q: -0.350670\n",
      "[-0.9767365  1.332765 ]\n",
      "[-0.6346941  0.8505017]\n",
      "[-1.0100864  0.9483763]\n",
      "[-0.95667404  0.9875653 ]\n",
      "[-1.338515   1.1984411]\n",
      "[54956, 1239180]\n",
      " 1294136/1500000: episode: 664, duration: 3.378s, episode steps: 1949, steps per second: 577, episode reward: 589.700, mean reward: 0.303 [-99.000, 137.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.277702, mean_absolute_error: 2.275915, mean_q: -0.352090\n",
      "[-0.76165915  1.9245211 ]\n",
      "[-0.98769146  1.5212057 ]\n",
      "[-0.6422569  1.5569539]\n",
      "[-0.6541038  1.9240652]\n",
      "[-1.0828825  1.5091447]\n",
      "[55025, 1241060]\n",
      " 1296085/1500000: episode: 665, duration: 3.576s, episode steps: 1949, steps per second: 545, episode reward: 289.400, mean reward: 0.148 [-111.000, 233.900], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 25.722551, mean_absolute_error: 1.519197, mean_q: -0.353182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92129385  1.4341018 ]\n",
      "[-0.9261815  1.6161942]\n",
      "[-0.73868024  1.7588943 ]\n",
      "[-0.50282687  1.783644  ]\n",
      "[-0.80381817  1.3460331 ]\n",
      "[55103, 1242931]\n",
      " 1298034/1500000: episode: 666, duration: 3.601s, episode steps: 1949, steps per second: 541, episode reward: 231.600, mean reward: 0.119 [-95.400, 145.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.330154, mean_absolute_error: 2.560711, mean_q: -0.354606\n",
      "[-0.6119746  0.3603265]\n",
      "[-1.1161274  2.0059776]\n",
      "[-0.9841933  1.8275393]\n",
      "[-0.15630627  1.2750441 ]\n",
      "[55187, 1244796]\n",
      " 1299983/1500000: episode: 667, duration: 3.366s, episode steps: 1949, steps per second: 579, episode reward: 356.200, mean reward: 0.183 [-78.000, 185.900], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.569260, mean_absolute_error: 2.040473, mean_q: -0.355698\n",
      "[-0.893394   1.0150367]\n",
      "[-1.057578   1.0820202]\n",
      "[-0.9011874  1.7169671]\n",
      "[-0.5859501  0.9720708]\n",
      "[-0.83285093  2.0335793 ]\n",
      "[55275, 1246657]\n",
      " 1301932/1500000: episode: 668, duration: 3.320s, episode steps: 1949, steps per second: 587, episode reward: 331.800, mean reward: 0.170 [-111.800, 178.700], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.280075, mean_absolute_error: 2.057355, mean_q: -0.356863\n",
      "[-0.68416834  1.1399529 ]\n",
      "[-0.2893747  0.9834174]\n",
      "[-0.8578855  1.16631  ]\n",
      "[-0.7810152  1.5837032]\n",
      "[-0.32783654  1.8263795 ]\n",
      "[55346, 1248535]\n",
      " 1303881/1500000: episode: 669, duration: 3.155s, episode steps: 1949, steps per second: 618, episode reward: 624.800, mean reward: 0.321 [-79.900, 169.300], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.783897, mean_absolute_error: 2.304532, mean_q: -0.358048\n",
      "[-1.1628035  1.4065588]\n",
      "[-1.4171796  1.2813652]\n",
      "[-0.6041863  1.614225 ]\n",
      "[-0.385184   1.4102585]\n",
      "[-1.3172096  0.9116147]\n",
      "[55430, 1250400]\n",
      " 1305830/1500000: episode: 670, duration: 3.239s, episode steps: 1949, steps per second: 602, episode reward: 34.600, mean reward: 0.018 [-98.800, 149.000], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.162628, mean_absolute_error: 2.043499, mean_q: -0.358821\n",
      "[-0.56144243  1.5779711 ]\n",
      "[-1.3253148  0.5593991]\n",
      "[-0.88251823  0.749798  ]\n",
      "[-0.98462003  1.228181  ]\n",
      "[-0.29754072  1.7337586 ]\n",
      "[55517, 1252262]\n",
      " 1307779/1500000: episode: 671, duration: 3.310s, episode steps: 1949, steps per second: 589, episode reward: 324.400, mean reward: 0.166 [-105.800, 165.900], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.920746, mean_absolute_error: 2.265903, mean_q: -0.359625\n",
      "[-0.7049201  1.0566832]\n",
      "[-0.26897234  1.3649898 ]\n",
      "[-0.5402393   0.70710534]\n",
      "[-0.7489297  1.4129072]\n",
      "[-0.97510654  1.296131  ]\n",
      "[55594, 1254134]\n",
      " 1309728/1500000: episode: 672, duration: 3.351s, episode steps: 1949, steps per second: 582, episode reward: 452.400, mean reward: 0.232 [-89.400, 157.100], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 49.461151, mean_absolute_error: 2.001096, mean_q: -0.360199\n",
      "[-0.92408746  0.8910811 ]\n",
      "[-0.5844682  0.9290592]\n",
      "[-1.2838352  1.7549367]\n",
      "[-0.9572639  1.3617564]\n",
      "[-0.8856947  1.0475414]\n",
      "[55674, 1256003]\n",
      " 1311677/1500000: episode: 673, duration: 3.344s, episode steps: 1949, steps per second: 583, episode reward: 662.600, mean reward: 0.340 [-82.000, 209.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.235241, mean_absolute_error: 2.210711, mean_q: -0.360771\n",
      "[-0.8948739  1.0393581]\n",
      "[-0.88769037  0.4303783 ]\n",
      "[-0.7754625  0.9291281]\n",
      "[-1.4672321  1.3899037]\n",
      "[-0.8670481  1.1996014]\n",
      "[55754, 1257872]\n",
      " 1313626/1500000: episode: 674, duration: 3.415s, episode steps: 1949, steps per second: 571, episode reward: 368.600, mean reward: 0.189 [-134.600, 173.300], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.278313, mean_absolute_error: 2.062134, mean_q: -0.360985\n",
      "[-0.6906902  1.1905966]\n",
      "[-1.0614798  1.8447616]\n",
      "[-1.0628402  1.440062 ]\n",
      "[-0.82402056  1.420639  ]\n",
      "[55831, 1259744]\n",
      " 1315575/1500000: episode: 675, duration: 3.534s, episode steps: 1949, steps per second: 551, episode reward: 544.000, mean reward: 0.279 [-112.700, 151.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.292488, mean_absolute_error: 2.003264, mean_q: -0.360967\n",
      "[-1.1044652  1.1025903]\n",
      "[-0.7754458  1.1387484]\n",
      "[-1.1704043  1.1431516]\n",
      "[-0.7197324  1.982083 ]\n",
      "[-0.9904814  0.8966222]\n",
      "[55906, 1261618]\n",
      " 1317524/1500000: episode: 676, duration: 3.317s, episode steps: 1949, steps per second: 588, episode reward: 415.400, mean reward: 0.213 [-81.400, 209.200], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.926178, mean_absolute_error: 2.360070, mean_q: -0.360926\n",
      "[-0.8791789  0.929552 ]\n",
      "[-1.0204138  1.1447003]\n",
      "[-1.1209029  0.7586808]\n",
      "[-0.2313926   0.21716763]\n",
      "[-0.87958705  1.4963772 ]\n",
      "[55982, 1263491]\n",
      " 1319473/1500000: episode: 677, duration: 3.502s, episode steps: 1949, steps per second: 557, episode reward: 718.300, mean reward: 0.369 [-99.400, 191.700], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.400509, mean_absolute_error: 1.812420, mean_q: -0.360960\n",
      "[-0.556844    0.60441715]\n",
      "[-1.2839171   0.46268693]\n",
      "[-0.5055701  0.6569544]\n",
      "[-0.39194658  0.30166772]\n",
      "[-1.3442777   0.87614864]\n",
      "[56050, 1265372]\n",
      " 1321422/1500000: episode: 678, duration: 3.309s, episode steps: 1949, steps per second: 589, episode reward: 681.000, mean reward: 0.349 [-76.900, 219.500], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 73.659294, mean_absolute_error: 2.386454, mean_q: -0.361259\n",
      "[-0.8963228  0.9178606]\n",
      "[-1.0440749   0.78727245]\n",
      "[-1.2409087  1.4873875]\n",
      "[-1.4079314  1.1937603]\n",
      "[-1.1894705   0.54627454]\n",
      "[56133, 1267238]\n",
      " 1323371/1500000: episode: 679, duration: 3.348s, episode steps: 1949, steps per second: 582, episode reward: 644.400, mean reward: 0.331 [-99.700, 169.500], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.976330, mean_absolute_error: 1.918838, mean_q: -0.361830\n",
      "[-1.1815016  1.1512492]\n",
      "[-1.08746    1.1267612]\n",
      "[-0.6072549  0.802355 ]\n",
      "[-1.0635417  1.6958594]\n",
      "[-0.67888004  1.1072242 ]\n",
      "[56211, 1269109]\n",
      " 1325320/1500000: episode: 680, duration: 3.336s, episode steps: 1949, steps per second: 584, episode reward: 261.100, mean reward: 0.134 [-97.700, 169.700], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.993279, mean_absolute_error: 1.769051, mean_q: -0.362414\n",
      "[-1.5362127   0.42412278]\n",
      "[-1.353257   1.0975943]\n",
      "[-0.7709128  0.5403585]\n",
      "[-1.2390733  0.535675 ]\n",
      "[-1.0090023  1.6069479]\n",
      "[56296, 1270973]\n",
      " 1327269/1500000: episode: 681, duration: 3.518s, episode steps: 1949, steps per second: 554, episode reward: 583.800, mean reward: 0.300 [-97.700, 181.200], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.324757, mean_absolute_error: 1.947980, mean_q: -0.362831\n",
      "[-0.71950996  0.5627489 ]\n",
      "[-0.3697919  0.8863045]\n",
      "[-0.7958959   0.73643816]\n",
      "[-1.5893126  1.3913778]\n",
      "[-0.95395833  1.5959703 ]\n",
      "[56383, 1272835]\n",
      " 1329218/1500000: episode: 682, duration: 3.382s, episode steps: 1949, steps per second: 576, episode reward: 107.200, mean reward: 0.055 [-90.100, 179.700], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.471973, mean_absolute_error: 1.850833, mean_q: -0.362877\n",
      "[-0.61603975  1.3392131 ]\n",
      "[-0.47667235  1.517287  ]\n",
      "[-0.3825946  1.2066401]\n",
      "[-0.9427181  1.284768 ]\n",
      "[56447, 1274720]\n",
      " 1331167/1500000: episode: 683, duration: 3.369s, episode steps: 1949, steps per second: 579, episode reward: 315.900, mean reward: 0.162 [-206.800, 195.100], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.759743, mean_absolute_error: 1.645066, mean_q: -0.363111\n",
      "[-1.0694224   0.99646455]\n",
      "[-1.2928689  1.4517993]\n",
      "[-0.5133846  1.065678 ]\n",
      "[-0.5413882  1.4627998]\n",
      "[-1.3567858  2.0848582]\n",
      "[56534, 1276582]\n",
      " 1333116/1500000: episode: 684, duration: 3.396s, episode steps: 1949, steps per second: 574, episode reward: 523.200, mean reward: 0.268 [-128.400, 195.100], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.449471, mean_absolute_error: 2.226673, mean_q: -0.363685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9443396  1.1990167]\n",
      "[-0.4582081  1.4873006]\n",
      "[-0.93540716  1.7743313 ]\n",
      "[-0.01408641  0.9397537 ]\n",
      "[-0.5484299  1.4745566]\n",
      "[56611, 1278454]\n",
      " 1335065/1500000: episode: 685, duration: 3.446s, episode steps: 1949, steps per second: 566, episode reward: 498.400, mean reward: 0.256 [-122.400, 164.700], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.318150, mean_absolute_error: 1.956772, mean_q: -0.364457\n",
      "[-0.6063968  1.3749802]\n",
      "[-1.1646777  1.5108289]\n",
      "[-0.293895   1.3833687]\n",
      "[-0.60165787  1.513385  ]\n",
      "[-0.49131644  1.1373373 ]\n",
      "[56682, 1280332]\n",
      " 1337014/1500000: episode: 686, duration: 3.384s, episode steps: 1949, steps per second: 576, episode reward: 592.200, mean reward: 0.304 [-79.600, 197.700], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.184586, mean_absolute_error: 1.753466, mean_q: -0.365104\n",
      "[-0.9792493  1.2526945]\n",
      "[-0.75313586  1.4796937 ]\n",
      "[-1.4756007  1.1090472]\n",
      "[-1.3344558   0.62470436]\n",
      "[-1.3147637   0.98038054]\n",
      "[56760, 1282203]\n",
      " 1338963/1500000: episode: 687, duration: 3.360s, episode steps: 1949, steps per second: 580, episode reward: 143.700, mean reward: 0.074 [-98.300, 139.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.009281, mean_absolute_error: 2.112185, mean_q: -0.365601\n",
      "[-0.6870278   0.94047487]\n",
      "[-0.58807534  1.0622907 ]\n",
      "[-1.0239958  1.0100709]\n",
      "[-0.81737804  1.1479583 ]\n",
      "[-0.9810851  1.400935 ]\n",
      "[56820, 1284092]\n",
      " 1340912/1500000: episode: 688, duration: 3.281s, episode steps: 1949, steps per second: 594, episode reward: 278.200, mean reward: 0.143 [-168.700, 204.700], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.727352, mean_absolute_error: 1.810069, mean_q: -0.366132\n",
      "[-0.68358177  1.5916092 ]\n",
      "[-0.83463764  1.0826588 ]\n",
      "[-0.8918889  1.2165929]\n",
      "[-0.36501992  1.1457652 ]\n",
      "[-0.2351716  1.6290174]\n",
      "[56887, 1285974]\n",
      " 1342861/1500000: episode: 689, duration: 3.394s, episode steps: 1949, steps per second: 574, episode reward: 333.100, mean reward: 0.171 [-162.800, 134.500], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.679199, mean_absolute_error: 1.807474, mean_q: -0.366938\n",
      "[-0.924319   1.2818849]\n",
      "[-0.05396866  0.637383  ]\n",
      "[-0.20179984  1.727795  ]\n",
      "[-0.52311224  1.2993642 ]\n",
      "[-1.0889632  1.6817961]\n",
      "[56974, 1287836]\n",
      " 1344810/1500000: episode: 690, duration: 3.414s, episode steps: 1949, steps per second: 571, episode reward: 493.100, mean reward: 0.253 [-143.500, 161.900], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.969696, mean_absolute_error: 2.207360, mean_q: -0.368043\n",
      "[-0.64699656  1.0661347 ]\n",
      "[-0.4967209  1.5467858]\n",
      "[-0.8909813  1.1779076]\n",
      "[-1.0215312  1.1153263]\n",
      "[57051, 1289708]\n",
      " 1346759/1500000: episode: 691, duration: 3.437s, episode steps: 1949, steps per second: 567, episode reward: 541.400, mean reward: 0.278 [-173.600, 139.600], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 67.563133, mean_absolute_error: 2.051255, mean_q: -0.368708\n",
      "[-0.9288733  0.953194 ]\n",
      "[-0.9389266  1.0455831]\n",
      "[-0.7213894  0.9961176]\n",
      "[-1.0073601  1.21813  ]\n",
      "[-0.9650668  1.0215276]\n",
      "[57122, 1291586]\n",
      " 1348708/1500000: episode: 692, duration: 3.294s, episode steps: 1949, steps per second: 592, episode reward: 154.000, mean reward: 0.079 [-142.700, 184.900], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.163086, mean_absolute_error: 1.820872, mean_q: -0.369252\n",
      "[-1.5890912  1.2392476]\n",
      "[-1.4923143   0.42417172]\n",
      "[-0.5882363  0.7169186]\n",
      "[-1.5793742  1.5625762]\n",
      "[-0.7766508  1.6130004]\n",
      "[57201, 1293456]\n",
      " 1350657/1500000: episode: 693, duration: 3.207s, episode steps: 1949, steps per second: 608, episode reward: 548.500, mean reward: 0.281 [-98.900, 212.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.002117, mean_absolute_error: 1.738595, mean_q: -0.369951\n",
      "[-1.1843193  1.2467742]\n",
      "[-1.4438878  1.1363938]\n",
      "[-1.5479355  0.6106898]\n",
      "[-0.6254016  1.0448335]\n",
      "[-0.6999612  1.4853576]\n",
      "[57258, 1295348]\n",
      " 1352606/1500000: episode: 694, duration: 3.682s, episode steps: 1949, steps per second: 529, episode reward: 509.700, mean reward: 0.262 [-149.100, 154.500], mean action: 0.971 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.549236, mean_absolute_error: 2.039306, mean_q: -0.370804\n",
      "[-1.1746385   0.22085889]\n",
      "[-0.93259037  1.039547  ]\n",
      "[-1.1018779   0.80132604]\n",
      "[-0.64692134  1.0858961 ]\n",
      "[-0.8633249  1.4113841]\n",
      "[57345, 1297210]\n",
      " 1354555/1500000: episode: 695, duration: 4.031s, episode steps: 1949, steps per second: 483, episode reward: 612.000, mean reward: 0.314 [-74.200, 199.800], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.415718, mean_absolute_error: 1.721559, mean_q: -0.371419\n",
      "[-1.1818608  1.5259095]\n",
      "[-1.2477595  1.2962956]\n",
      "[-1.1714127   0.34352168]\n",
      "[-1.2320057  1.3681419]\n",
      "[-0.9797884  1.2764482]\n",
      "[57419, 1299085]\n",
      " 1356504/1500000: episode: 696, duration: 4.267s, episode steps: 1949, steps per second: 457, episode reward: 162.800, mean reward: 0.084 [-168.700, 110.300], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 64.129433, mean_absolute_error: 2.104973, mean_q: -0.372172\n",
      "[-0.34042764  1.3584546 ]\n",
      "[-0.278204   1.3205715]\n",
      "[-0.47156724  1.4414486 ]\n",
      "[-0.71592814  1.1433628 ]\n",
      "[-0.780942   0.8706396]\n",
      "[57489, 1300964]\n",
      " 1358453/1500000: episode: 697, duration: 4.302s, episode steps: 1949, steps per second: 453, episode reward: 367.900, mean reward: 0.189 [-111.500, 204.400], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 28.754753, mean_absolute_error: 1.550486, mean_q: -0.372996\n",
      "[-0.41029382  0.44934207]\n",
      "[-0.42413425  1.5210633 ]\n",
      "[-0.4680665  1.5431201]\n",
      "[-0.7227559  1.1734805]\n",
      "[-1.4198128  1.203656 ]\n",
      "[57565, 1302837]\n",
      " 1360402/1500000: episode: 698, duration: 4.105s, episode steps: 1949, steps per second: 475, episode reward: 484.400, mean reward: 0.249 [-105.400, 179.300], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.318954, mean_absolute_error: 1.711225, mean_q: -0.374189\n",
      "[-0.37259194  1.8082443 ]\n",
      "[-0.31296763  1.7512431 ]\n",
      "[-1.1665558  1.529437 ]\n",
      "[-0.9089876  1.0005883]\n",
      "[57636, 1304715]\n",
      " 1362351/1500000: episode: 699, duration: 4.456s, episode steps: 1949, steps per second: 437, episode reward: 665.800, mean reward: 0.342 [-110.100, 128.400], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.715332, mean_absolute_error: 2.000478, mean_q: -0.375199\n",
      "[-0.37978542  1.2035679 ]\n",
      "[-1.2567701  1.1803821]\n",
      "[-0.86998785  0.6453863 ]\n",
      "[-1.2610803  1.1543959]\n",
      "[-0.7564081  0.9832711]\n",
      "[57715, 1306585]\n",
      " 1364300/1500000: episode: 700, duration: 4.209s, episode steps: 1949, steps per second: 463, episode reward: 491.000, mean reward: 0.252 [-143.500, 109.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.790577, mean_absolute_error: 1.886482, mean_q: -0.375903\n",
      "[-0.6614392  1.1952361]\n",
      "[-0.9628656  0.8745568]\n",
      "[-0.8692463  0.7972743]\n",
      "[-0.86399347  0.8417423 ]\n",
      "[-1.2740884  1.3813603]\n",
      "[57801, 1308448]\n",
      " 1366249/1500000: episode: 701, duration: 3.542s, episode steps: 1949, steps per second: 550, episode reward: 410.300, mean reward: 0.211 [-108.400, 225.100], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.710121, mean_absolute_error: 1.948500, mean_q: -0.376727\n",
      "[-0.8811097   0.66839314]\n",
      "[-1.0429425  1.1989512]\n",
      "[-1.2184665   0.35128245]\n",
      "[-0.502055   1.3812947]\n",
      "[-0.9546286  1.4247917]\n",
      "[57885, 1310313]\n",
      " 1368198/1500000: episode: 702, duration: 4.119s, episode steps: 1949, steps per second: 473, episode reward: 244.900, mean reward: 0.126 [-106.200, 194.000], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.928959, mean_absolute_error: 1.953087, mean_q: -0.377698\n",
      "[-1.0345491  1.0186173]\n",
      "[-1.5575721  1.4928212]\n",
      "[-1.1804328   0.80942917]\n",
      "[-0.8151225  0.9089169]\n",
      "[-0.80423397  0.6757292 ]\n",
      "[57962, 1312185]\n",
      " 1370147/1500000: episode: 703, duration: 4.080s, episode steps: 1949, steps per second: 478, episode reward: 385.500, mean reward: 0.198 [-110.800, 213.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.108173, mean_absolute_error: 2.039929, mean_q: -0.378832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.85290587  1.2310306 ]\n",
      "[-0.39249352  1.2961514 ]\n",
      "[-0.87564385  0.51980793]\n",
      "[-0.9173384  1.0839119]\n",
      "[-0.9452787  0.7893274]\n",
      "[58053, 1314043]\n",
      " 1372096/1500000: episode: 704, duration: 4.164s, episode steps: 1949, steps per second: 468, episode reward: 403.600, mean reward: 0.207 [-102.800, 167.800], mean action: 0.953 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 71.682358, mean_absolute_error: 2.395014, mean_q: -0.380017\n",
      "[-1.4034111  1.7180488]\n",
      "[-1.1234437  1.0973871]\n",
      "[-1.788163   1.2637795]\n",
      "[-1.0551885   0.95857817]\n",
      "[-0.41588733  0.7251099 ]\n",
      "[58131, 1315914]\n",
      " 1374045/1500000: episode: 705, duration: 3.507s, episode steps: 1949, steps per second: 556, episode reward: 855.500, mean reward: 0.439 [-128.900, 218.900], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.586559, mean_absolute_error: 1.833470, mean_q: -0.380966\n",
      "[-1.3967937  1.3918976]\n",
      "[-0.898399   1.5029818]\n",
      "[-0.8337799   0.75015384]\n",
      "[-0.43116426  1.0930331 ]\n",
      "[58204, 1317790]\n",
      " 1375994/1500000: episode: 706, duration: 3.447s, episode steps: 1949, steps per second: 565, episode reward: 329.900, mean reward: 0.169 [-120.400, 147.000], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.912075, mean_absolute_error: 2.055061, mean_q: -0.381889\n",
      "[-1.0549585   0.96123815]\n",
      "[-0.3174832  1.175595 ]\n",
      "[-0.22929463  1.0235175 ]\n",
      "[-0.652142    0.66840285]\n",
      "[-0.6746255  1.5877064]\n",
      "[58283, 1319660]\n",
      " 1377943/1500000: episode: 707, duration: 3.426s, episode steps: 1949, steps per second: 569, episode reward: 673.500, mean reward: 0.346 [-84.300, 190.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.958874, mean_absolute_error: 2.147896, mean_q: -0.382499\n",
      "[-0.51852167  1.0754663 ]\n",
      "[0.14272825 0.700099  ]\n",
      "[-1.132714   1.5902421]\n",
      "[-1.0568125  1.2993057]\n",
      "[-0.8312635  1.4502498]\n",
      "[58378, 1321514]\n",
      " 1379892/1500000: episode: 708, duration: 3.449s, episode steps: 1949, steps per second: 565, episode reward: 440.400, mean reward: 0.226 [-88.100, 147.300], mean action: 0.951 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.466537, mean_absolute_error: 1.759454, mean_q: -0.382996\n",
      "[-1.357247  1.085736]\n",
      "[-1.3872994  0.8683981]\n",
      "[-0.89305955  0.6245372 ]\n",
      "[-1.6736106  1.0675983]\n",
      "[-1.3104835  1.1324916]\n",
      "[58467, 1323374]\n",
      " 1381841/1500000: episode: 709, duration: 3.737s, episode steps: 1949, steps per second: 521, episode reward: 360.000, mean reward: 0.185 [-69.300, 206.600], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.718464, mean_absolute_error: 2.065704, mean_q: -0.383593\n",
      "[-1.1354963  1.146834 ]\n",
      "[-0.8048185  1.1786125]\n",
      "[-1.4519861  1.1242957]\n",
      "[-1.2111746   0.45059514]\n",
      "[-1.3651385  1.6686696]\n",
      "[58542, 1325248]\n",
      " 1383790/1500000: episode: 710, duration: 3.380s, episode steps: 1949, steps per second: 577, episode reward: 412.900, mean reward: 0.212 [-91.100, 161.400], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 62.072155, mean_absolute_error: 2.103121, mean_q: -0.384254\n",
      "[-1.2060579  1.1044478]\n",
      "[-1.4608713  2.15065  ]\n",
      "[-1.4717214  1.496302 ]\n",
      "[-0.9848239  1.4135596]\n",
      "[-1.2329503  0.7396034]\n",
      "[58611, 1327128]\n",
      " 1385739/1500000: episode: 711, duration: 3.918s, episode steps: 1949, steps per second: 497, episode reward: 644.100, mean reward: 0.330 [-148.700, 139.300], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.961334, mean_absolute_error: 1.704686, mean_q: -0.384885\n",
      "[-1.2681043  1.334577 ]\n",
      "[-1.0039996  1.8295958]\n",
      "[-0.4142379  1.4272995]\n",
      "[-1.0690268  1.3494023]\n",
      "[-1.4468644  1.8523159]\n",
      "[58696, 1328992]\n",
      " 1387688/1500000: episode: 712, duration: 5.066s, episode steps: 1949, steps per second: 385, episode reward: 567.200, mean reward: 0.291 [-115.600, 157.500], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.868622, mean_absolute_error: 1.875549, mean_q: -0.385368\n",
      "[-0.34133607  1.1390936 ]\n",
      "[-1.1084745  1.0300734]\n",
      "[-0.5753075  0.8504414]\n",
      "[-0.26542443  1.4410834 ]\n",
      "[-0.17070164  0.90974665]\n",
      "[58786, 1330851]\n",
      " 1389637/1500000: episode: 713, duration: 3.938s, episode steps: 1949, steps per second: 495, episode reward: 758.600, mean reward: 0.389 [-78.000, 174.500], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.396381, mean_absolute_error: 1.786432, mean_q: -0.386169\n",
      "[-0.9547654  0.8121504]\n",
      "[-0.6288559  1.1204361]\n",
      "[-0.817262   0.8473724]\n",
      "[-0.49235514 -0.33008146]\n",
      "[58883, 1332703]\n",
      " 1391586/1500000: episode: 714, duration: 4.017s, episode steps: 1949, steps per second: 485, episode reward: 538.200, mean reward: 0.276 [-103.600, 178.400], mean action: 0.950 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 29.965019, mean_absolute_error: 1.737718, mean_q: -0.386973\n",
      "[-0.67628646  1.0099168 ]\n",
      "[-0.8174133  1.1388952]\n",
      "[-0.4933098  1.2906647]\n",
      "[-1.080314   1.7922311]\n",
      "[-0.76521105  1.3164582 ]\n",
      "[58966, 1334569]\n",
      " 1393535/1500000: episode: 715, duration: 4.572s, episode steps: 1949, steps per second: 426, episode reward: 34.300, mean reward: 0.018 [-85.400, 151.800], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 40.723213, mean_absolute_error: 1.756415, mean_q: -0.387960\n",
      "[-1.160428   1.1411872]\n",
      "[-1.0723019   0.36243388]\n",
      "[-1.0075711  1.2769848]\n",
      "[-0.71669465  0.7531594 ]\n",
      "[-1.0822527   0.85554564]\n",
      "[59042, 1336442]\n",
      " 1395484/1500000: episode: 716, duration: 3.675s, episode steps: 1949, steps per second: 530, episode reward: 405.800, mean reward: 0.208 [-112.000, 195.200], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.455219, mean_absolute_error: 1.712965, mean_q: -0.388863\n",
      "[-1.3611704   0.43105885]\n",
      "[-0.47153074  1.1103338 ]\n",
      "[-0.87061656  1.0763881 ]\n",
      "[-1.180866   0.9429856]\n",
      "[-1.5418437  1.5415688]\n",
      "[59121, 1338312]\n",
      " 1397433/1500000: episode: 717, duration: 3.503s, episode steps: 1949, steps per second: 556, episode reward: 639.000, mean reward: 0.328 [-83.700, 213.800], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 50.153931, mean_absolute_error: 1.997851, mean_q: -0.389727\n",
      "[-1.3565798  1.2618823]\n",
      "[-0.7944945  1.4493197]\n",
      "[-1.0700121  1.1825756]\n",
      "[-0.48031542  1.8644991 ]\n",
      "[-0.8521864  1.4615865]\n",
      "[59202, 1340180]\n",
      " 1399382/1500000: episode: 718, duration: 3.333s, episode steps: 1949, steps per second: 585, episode reward: 712.000, mean reward: 0.365 [-108.600, 213.800], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 42.754066, mean_absolute_error: 1.859231, mean_q: -0.390846\n",
      "[-0.7030588  1.3380752]\n",
      "[-0.97705644  1.9922975 ]\n",
      "[-0.8617958  1.1987269]\n",
      "[-0.58653414  1.0612615 ]\n",
      "[-1.30414    1.3639934]\n",
      "[59281, 1342050]\n",
      " 1401331/1500000: episode: 719, duration: 3.341s, episode steps: 1949, steps per second: 583, episode reward: 332.300, mean reward: 0.170 [-128.500, 157.900], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 37.472187, mean_absolute_error: 1.735600, mean_q: -0.392067\n",
      "[-0.82007915  1.2018336 ]\n",
      "[-0.48431772  1.4541366 ]\n",
      "[-0.8292088  1.068051 ]\n",
      "[-1.0091981  1.9260731]\n",
      "[-0.92344743  1.8718956 ]\n",
      "[59375, 1343905]\n",
      " 1403280/1500000: episode: 720, duration: 3.624s, episode steps: 1949, steps per second: 538, episode reward: 177.200, mean reward: 0.091 [-168.700, 141.700], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 70.948608, mean_absolute_error: 2.302714, mean_q: -0.393308\n",
      "[-1.1566881  1.0281723]\n",
      "[-0.94305915  0.49175403]\n",
      "[0.13442923 1.094818  ]\n",
      "[-0.9608715  1.4783224]\n",
      "[-0.40875962  1.662248  ]\n",
      "[59454, 1345775]\n",
      " 1405229/1500000: episode: 721, duration: 3.404s, episode steps: 1949, steps per second: 573, episode reward: 454.800, mean reward: 0.233 [-83.700, 119.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 54.528088, mean_absolute_error: 2.108253, mean_q: -0.394608\n",
      "[-1.2518885  1.2543213]\n",
      "[-0.85841644  0.9466093 ]\n",
      "[-1.0496765  0.7503748]\n",
      "[-0.98669636  1.1246787 ]\n",
      "[59538, 1347640]\n",
      " 1407178/1500000: episode: 722, duration: 3.369s, episode steps: 1949, steps per second: 579, episode reward: 707.200, mean reward: 0.363 [-98.900, 188.800], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 34.307301, mean_absolute_error: 1.758210, mean_q: -0.395867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0364769   0.95909506]\n",
      "[-0.5173044  0.7661029]\n",
      "[-1.1073413  1.010639 ]\n",
      "[-0.94348055  1.0296167 ]\n",
      "[-0.6504701  0.8773251]\n",
      "[59610, 1349517]\n",
      " 1409127/1500000: episode: 723, duration: 3.345s, episode steps: 1949, steps per second: 583, episode reward: 631.700, mean reward: 0.324 [-95.800, 180.900], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 47.893196, mean_absolute_error: 1.931076, mean_q: -0.397303\n",
      "[-0.9888509  1.1044514]\n",
      "[-1.6624947  1.3965265]\n",
      "[-1.6490355  1.2223213]\n",
      "[-0.49568868  1.0771755 ]\n",
      "[-0.34770867  1.5346464 ]\n",
      "[59691, 1351385]\n",
      " 1411076/1500000: episode: 724, duration: 3.278s, episode steps: 1949, steps per second: 595, episode reward: 487.900, mean reward: 0.250 [-131.100, 191.300], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.565369, mean_absolute_error: 1.976332, mean_q: -0.398531\n",
      "[-0.61049324  0.9398681 ]\n",
      "[-0.88782763  0.9773562 ]\n",
      "[-0.9665268  1.3111594]\n",
      "[-0.59697485  1.3443047 ]\n",
      "[-0.8397107  1.287059 ]\n",
      "[59775, 1353250]\n",
      " 1413025/1500000: episode: 725, duration: 3.223s, episode steps: 1949, steps per second: 605, episode reward: 581.100, mean reward: 0.298 [-139.200, 169.300], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.772335, mean_absolute_error: 1.908994, mean_q: -0.399534\n",
      "[-0.8345258  1.1787374]\n",
      "[-0.72568977  0.858543  ]\n",
      "[-0.31258366  1.2182521 ]\n",
      "[-0.83571064  0.54194397]\n",
      "[-0.37053645  1.3891894 ]\n",
      "[59851, 1355123]\n",
      " 1414974/1500000: episode: 726, duration: 3.257s, episode steps: 1949, steps per second: 598, episode reward: 820.300, mean reward: 0.421 [-135.300, 203.500], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.147186, mean_absolute_error: 1.956416, mean_q: -0.400426\n",
      "[0.16185598 1.6989696 ]\n",
      "[-0.39274874  1.224966  ]\n",
      "[-0.6910214   0.82533044]\n",
      "[-0.6374359  0.9689108]\n",
      "[-0.03672759  1.6148783 ]\n",
      "[59924, 1356999]\n",
      " 1416923/1500000: episode: 727, duration: 3.329s, episode steps: 1949, steps per second: 586, episode reward: 289.200, mean reward: 0.148 [-83.900, 128.500], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 74.085220, mean_absolute_error: 2.405553, mean_q: -0.400856\n",
      "[-0.7120047  1.3226172]\n",
      "[-0.5969559  1.6161393]\n",
      "[-0.5530753  0.9804786]\n",
      "[-1.0311755  1.2170917]\n",
      "[-1.0007831  1.3833727]\n",
      "[59996, 1358876]\n",
      " 1418872/1500000: episode: 728, duration: 3.252s, episode steps: 1949, steps per second: 599, episode reward: 768.600, mean reward: 0.394 [-87.400, 179.700], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.591923, mean_absolute_error: 2.129879, mean_q: -0.401230\n",
      "[-0.8056993  1.177857 ]\n",
      "[-0.902622   1.6666126]\n",
      "[-0.32049757  1.303606  ]\n",
      "[-0.61305445  1.3017051 ]\n",
      "[-0.1873154   0.82322466]\n",
      "[60070, 1360751]\n",
      " 1420821/1500000: episode: 729, duration: 3.300s, episode steps: 1949, steps per second: 591, episode reward: 211.500, mean reward: 0.109 [-111.400, 172.900], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 33.947350, mean_absolute_error: 1.539043, mean_q: -0.401526\n",
      "[-0.6372764  1.048803 ]\n",
      "[-0.85190713  1.5475492 ]\n",
      "[-0.8801034  1.7960534]\n",
      "[-0.5732649  0.8657432]\n",
      "[60147, 1362623]\n",
      " 1422770/1500000: episode: 730, duration: 3.434s, episode steps: 1949, steps per second: 568, episode reward: 350.700, mean reward: 0.180 [-130.400, 143.900], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 61.626442, mean_absolute_error: 2.050943, mean_q: -0.402094\n",
      "[-1.0981702  1.0322679]\n",
      "[-0.9903006  1.1735251]\n",
      "[-0.7581052  0.9207405]\n",
      "[-0.23947948  0.81750476]\n",
      "[-0.75063103  0.9806207 ]\n",
      "[60234, 1364485]\n",
      " 1424719/1500000: episode: 731, duration: 3.374s, episode steps: 1949, steps per second: 578, episode reward: 338.500, mean reward: 0.174 [-123.700, 146.900], mean action: 0.955 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.848015, mean_absolute_error: 1.732019, mean_q: -0.402510\n",
      "[-1.0471172  0.8039533]\n",
      "[-1.3008424  1.1001613]\n",
      "[-1.7034612  2.0169027]\n",
      "[-1.3228891  1.9665486]\n",
      "[-1.531192   0.9054765]\n",
      "[60313, 1366355]\n",
      " 1426668/1500000: episode: 732, duration: 3.425s, episode steps: 1949, steps per second: 569, episode reward: 662.800, mean reward: 0.340 [-80.000, 190.200], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.987015, mean_absolute_error: 2.030592, mean_q: -0.403116\n",
      "[-0.49075356  0.9880746 ]\n",
      "[-1.3140537  1.8282931]\n",
      "[-0.91759646  1.9507871 ]\n",
      "[-0.00527466  2.4514105 ]\n",
      "[-0.9173333  1.2286428]\n",
      "[60399, 1368218]\n",
      " 1428617/1500000: episode: 733, duration: 3.256s, episode steps: 1949, steps per second: 599, episode reward: 615.000, mean reward: 0.316 [-90.000, 255.600], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.333202, mean_absolute_error: 1.456640, mean_q: -0.403615\n",
      "[-0.06534383  1.3597596 ]\n",
      "[-1.1313708  1.3065147]\n",
      "[-1.010874   1.9328127]\n",
      "[-0.5336829  1.1401045]\n",
      "[-1.0806808  1.2905205]\n",
      "[60483, 1370083]\n",
      " 1430566/1500000: episode: 734, duration: 3.546s, episode steps: 1949, steps per second: 550, episode reward: 675.000, mean reward: 0.346 [-178.100, 205.200], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.013855, mean_absolute_error: 1.936476, mean_q: -0.404106\n",
      "[-0.41128466  0.8389388 ]\n",
      "[-0.5373277  0.8763661]\n",
      "[-0.65375835  0.90051836]\n",
      "[-1.0673623  0.9161319]\n",
      "[-1.1470397  1.5454521]\n",
      "[60547, 1371968]\n",
      " 1432515/1500000: episode: 735, duration: 3.366s, episode steps: 1949, steps per second: 579, episode reward: 411.200, mean reward: 0.211 [-132.100, 196.300], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 26.126371, mean_absolute_error: 1.633247, mean_q: -0.404533\n",
      "[-0.7803685  1.0667145]\n",
      "[-0.7294418  0.7949669]\n",
      "[-0.64398015  1.0192015 ]\n",
      "[-1.1254578   0.85741293]\n",
      "[-0.57658803  1.2309798 ]\n",
      "[60626, 1373838]\n",
      " 1434464/1500000: episode: 736, duration: 3.684s, episode steps: 1949, steps per second: 529, episode reward: 667.500, mean reward: 0.342 [-107.800, 190.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 63.502621, mean_absolute_error: 2.134446, mean_q: -0.405198\n",
      "[-1.2797855  0.4947929]\n",
      "[-0.56862795  0.72777796]\n",
      "[-1.054967   0.8851857]\n",
      "[-1.2879962   0.76855433]\n",
      "[-0.4911848  1.5457672]\n",
      "[60692, 1375721]\n",
      " 1436413/1500000: episode: 737, duration: 3.380s, episode steps: 1949, steps per second: 577, episode reward: 402.700, mean reward: 0.207 [-111.500, 124.800], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.489830, mean_absolute_error: 1.817937, mean_q: -0.405569\n",
      "[-1.375317   1.2609084]\n",
      "[-1.4253833  1.7226413]\n",
      "[-0.8510675  1.6502786]\n",
      "[-1.288139   1.5042483]\n",
      "[60771, 1377591]\n",
      " 1438362/1500000: episode: 738, duration: 3.520s, episode steps: 1949, steps per second: 554, episode reward: 437.400, mean reward: 0.224 [-89.400, 189.300], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 45.402596, mean_absolute_error: 1.731706, mean_q: -0.405968\n",
      "[-1.1121753  1.2244942]\n",
      "[-0.4581043  1.454017 ]\n",
      "[-1.1825976  1.9806532]\n",
      "[-1.6512969  1.377609 ]\n",
      "[-0.8551429  1.4057692]\n",
      "[60849, 1379462]\n",
      " 1440311/1500000: episode: 739, duration: 3.689s, episode steps: 1949, steps per second: 528, episode reward: 510.000, mean reward: 0.262 [-112.800, 142.500], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.005138, mean_absolute_error: 1.716821, mean_q: -0.406438\n",
      "[-1.1686157  1.1968378]\n",
      "[-0.78688234  0.7587308 ]\n",
      "[-0.9631205  1.2333411]\n",
      "[-1.0580481  1.2807667]\n",
      "[-1.2459285  1.3695917]\n",
      "[60935, 1381325]\n",
      " 1442260/1500000: episode: 740, duration: 3.580s, episode steps: 1949, steps per second: 544, episode reward: 565.200, mean reward: 0.290 [-88.000, 166.100], mean action: 0.956 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.671753, mean_absolute_error: 2.102760, mean_q: -0.407287\n",
      "[-0.7543761   0.78435713]\n",
      "[-0.7958597  0.9860701]\n",
      "[-0.629469   0.7315678]\n",
      "[-0.48252907  0.74661714]\n",
      "[-0.87293947  0.67335784]\n",
      "[61006, 1383203]\n",
      " 1444209/1500000: episode: 741, duration: 3.369s, episode steps: 1949, steps per second: 578, episode reward: 365.400, mean reward: 0.187 [-135.600, 183.200], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.572704, mean_absolute_error: 1.901271, mean_q: -0.407875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1506741   0.94458675]\n",
      "[-1.105642   1.1050653]\n",
      "[-0.94306815  0.8204344 ]\n",
      "[-0.31453955  1.3911545 ]\n",
      "[-0.8009477  1.4364538]\n",
      "[61082, 1385076]\n",
      " 1446158/1500000: episode: 742, duration: 3.200s, episode steps: 1949, steps per second: 609, episode reward: 313.900, mean reward: 0.161 [-81.700, 137.700], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.702091, mean_absolute_error: 1.687602, mean_q: -0.408638\n",
      "[-1.048137   0.7956102]\n",
      "[-0.7903216  0.802692 ]\n",
      "[-0.03469247  1.1239685 ]\n",
      "[-0.37131202  1.1921322 ]\n",
      "[-0.52299696  1.6819993 ]\n",
      "[61162, 1386945]\n",
      " 1448107/1500000: episode: 743, duration: 3.231s, episode steps: 1949, steps per second: 603, episode reward: 447.400, mean reward: 0.230 [-89.200, 137.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 77.829018, mean_absolute_error: 2.362497, mean_q: -0.409439\n",
      "[-1.0478022  0.6559612]\n",
      "[-0.61450434  1.7633475 ]\n",
      "[-0.47746983  1.0760907 ]\n",
      "[-0.9260469   0.90597683]\n",
      "[-0.9503909  1.1319484]\n",
      "[61245, 1388811]\n",
      " 1450056/1500000: episode: 744, duration: 3.464s, episode steps: 1949, steps per second: 563, episode reward: 557.700, mean reward: 0.286 [-76.100, 135.100], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 51.204155, mean_absolute_error: 1.862654, mean_q: -0.409798\n",
      "[-0.33857456  1.6197897 ]\n",
      "[-0.390836   1.3291273]\n",
      "[-1.0104465  1.1912861]\n",
      "[-0.9012603   0.99682254]\n",
      "[-0.6259082  1.3037815]\n",
      "[61306, 1390699]\n",
      " 1452005/1500000: episode: 745, duration: 3.405s, episode steps: 1949, steps per second: 572, episode reward: 252.800, mean reward: 0.130 [-104.600, 128.800], mean action: 0.969 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 38.168007, mean_absolute_error: 1.615141, mean_q: -0.410128\n",
      "[-1.1094872  0.610226 ]\n",
      "[-1.206709   1.3501853]\n",
      "[-0.6744741   0.77015054]\n",
      "[-0.20097877  0.52201533]\n",
      "[61383, 1392571]\n",
      " 1453954/1500000: episode: 746, duration: 3.343s, episode steps: 1949, steps per second: 583, episode reward: 230.800, mean reward: 0.118 [-187.700, 145.300], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.128376, mean_absolute_error: 1.769100, mean_q: -0.410616\n",
      "[-0.9149086   0.96906257]\n",
      "[-0.6142017  1.3839233]\n",
      "[-0.32105133  1.0372268 ]\n",
      "[-0.26876283  0.85798436]\n",
      "[-0.31011918  1.3061209 ]\n",
      "[61451, 1394452]\n",
      " 1455903/1500000: episode: 747, duration: 3.996s, episode steps: 1949, steps per second: 488, episode reward: 333.000, mean reward: 0.171 [-106.200, 138.000], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.469345, mean_absolute_error: 2.275653, mean_q: -0.411268\n",
      "[-0.8300034   0.88000566]\n",
      "[-1.3587966  0.7868975]\n",
      "[-1.2185429  1.3830365]\n",
      "[-0.912169   1.7894787]\n",
      "[-0.7572308  1.4533948]\n",
      "[61524, 1396328]\n",
      " 1457852/1500000: episode: 748, duration: 4.088s, episode steps: 1949, steps per second: 477, episode reward: 540.900, mean reward: 0.278 [-130.500, 154.800], mean action: 0.963 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 92.236206, mean_absolute_error: 2.584141, mean_q: -0.411545\n",
      "[-0.19939488  1.3275698 ]\n",
      "[-0.5297853  1.0330372]\n",
      "[-0.8561998  1.0589235]\n",
      "[-0.7527991  1.5303674]\n",
      "[-0.79953617  1.3543429 ]\n",
      "[61606, 1398195]\n",
      " 1459801/1500000: episode: 749, duration: 3.772s, episode steps: 1949, steps per second: 517, episode reward: 622.500, mean reward: 0.319 [-131.300, 190.200], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 59.460411, mean_absolute_error: 1.899293, mean_q: -0.411293\n",
      "[-0.3052888  1.6326734]\n",
      "[-0.4188067   0.82198435]\n",
      "[-0.80794394  1.1246539 ]\n",
      "[-0.4521714  0.8345257]\n",
      "[-0.6803936  1.4376808]\n",
      "[61680, 1400070]\n",
      " 1461750/1500000: episode: 750, duration: 4.241s, episode steps: 1949, steps per second: 460, episode reward: 452.600, mean reward: 0.232 [-133.600, 156.300], mean action: 0.962 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 39.905113, mean_absolute_error: 1.804752, mean_q: -0.411123\n",
      "[-1.3073025   0.40924495]\n",
      "[-0.61995876  1.5836356 ]\n",
      "[-0.42521745  1.5309951 ]\n",
      "[-0.6801902  1.2627012]\n",
      "[-1.0245106  1.5245876]\n",
      "[61745, 1401954]\n",
      " 1463699/1500000: episode: 751, duration: 3.607s, episode steps: 1949, steps per second: 540, episode reward: 639.800, mean reward: 0.328 [-131.000, 196.500], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.926952, mean_absolute_error: 2.106776, mean_q: -0.411123\n",
      "[-1.550596   1.2239343]\n",
      "[-1.3040712  1.0458289]\n",
      "[-1.0023301  1.2352012]\n",
      "[-0.54546183  1.3864832 ]\n",
      "[-0.48470154  1.0449622 ]\n",
      "[61839, 1403809]\n",
      " 1465648/1500000: episode: 752, duration: 3.961s, episode steps: 1949, steps per second: 492, episode reward: 237.900, mean reward: 0.122 [-125.300, 157.100], mean action: 0.952 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 55.408146, mean_absolute_error: 1.901129, mean_q: -0.411338\n",
      "[-0.9525585  0.8018324]\n",
      "[-0.5332443  1.1122998]\n",
      "[-0.9758923  0.5251664]\n",
      "[-0.9141491  0.9898338]\n",
      "[61908, 1405689]\n",
      " 1467597/1500000: episode: 753, duration: 3.530s, episode steps: 1949, steps per second: 552, episode reward: 749.200, mean reward: 0.384 [-143.100, 198.700], mean action: 0.965 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 52.827293, mean_absolute_error: 1.847005, mean_q: -0.411489\n",
      "[-0.9438376  1.0032144]\n",
      "[-0.6060925  1.134623 ]\n",
      "[-0.70466053  0.9548606 ]\n",
      "[-0.9685019  0.9727599]\n",
      "[-1.0124788  0.7155992]\n",
      "[61978, 1407568]\n",
      " 1469546/1500000: episode: 754, duration: 3.550s, episode steps: 1949, steps per second: 549, episode reward: 315.000, mean reward: 0.162 [-82.800, 154.200], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 41.442268, mean_absolute_error: 1.780554, mean_q: -0.412107\n",
      "[-1.1506462  1.4562736]\n",
      "[-0.6525789  1.3538402]\n",
      "[-1.0238268  1.1783141]\n",
      "[-0.5364236  1.3028593]\n",
      "[-0.6919473  1.6169882]\n",
      "[62057, 1409438]\n",
      " 1471495/1500000: episode: 755, duration: 3.935s, episode steps: 1949, steps per second: 495, episode reward: 306.300, mean reward: 0.157 [-116.900, 129.500], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 58.685677, mean_absolute_error: 2.217247, mean_q: -0.412554\n",
      "[-1.1899033  0.9036725]\n",
      "[-1.0219445  1.4394534]\n",
      "[0.21014768 1.5508313 ]\n",
      "[-0.81640613  0.92919505]\n",
      "[-1.0329133  1.6293643]\n",
      "[62135, 1411309]\n",
      " 1473444/1500000: episode: 756, duration: 3.716s, episode steps: 1949, steps per second: 524, episode reward: 162.000, mean reward: 0.083 [-138.000, 238.800], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.056168, mean_absolute_error: 1.808750, mean_q: -0.413085\n",
      "[-1.0597435  0.802474 ]\n",
      "[-1.1537443  1.2572125]\n",
      "[-0.91575766  1.2777549 ]\n",
      "[-0.7848801  1.4276776]\n",
      "[-0.8525373  1.6472472]\n",
      "[62224, 1413169]\n",
      " 1475393/1500000: episode: 757, duration: 3.387s, episode steps: 1949, steps per second: 575, episode reward: 305.800, mean reward: 0.157 [-84.900, 148.300], mean action: 0.954 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 53.371243, mean_absolute_error: 2.126672, mean_q: -0.413538\n",
      "[-1.6110711  1.1086571]\n",
      "[-1.5089356   0.42169562]\n",
      "[-1.1027305  1.5595294]\n",
      "[-0.8485816  1.2911443]\n",
      "[-0.5017198  0.8829474]\n",
      "[62301, 1415041]\n",
      " 1477342/1500000: episode: 758, duration: 4.224s, episode steps: 1949, steps per second: 461, episode reward: 551.600, mean reward: 0.283 [-70.100, 200.200], mean action: 0.960 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 60.958427, mean_absolute_error: 2.069889, mean_q: -0.413804\n",
      "[-1.0104278  1.7120616]\n",
      "[-0.5381775  1.5200925]\n",
      "[-0.8959141  1.8395582]\n",
      "[-0.4871961  1.4590361]\n",
      "[-1.2941886  1.0918099]\n",
      "[62380, 1416911]\n",
      " 1479291/1500000: episode: 759, duration: 3.545s, episode steps: 1949, steps per second: 550, episode reward: 509.300, mean reward: 0.261 [-111.900, 187.000], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.758560, mean_absolute_error: 2.414364, mean_q: -0.414132\n",
      "[-1.6488031  1.0343034]\n",
      "[-1.3877301  1.6347073]\n",
      "[-0.7027411  0.7557184]\n",
      "[-0.51737607  0.26813814]\n",
      "[-0.7353779  1.1655546]\n",
      "[62459, 1418781]\n",
      " 1481240/1500000: episode: 760, duration: 3.467s, episode steps: 1949, steps per second: 562, episode reward: 792.500, mean reward: 0.407 [-87.300, 114.400], mean action: 0.959 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.687084, mean_absolute_error: 1.955232, mean_q: -0.414528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9448727   0.91107637]\n",
      "[-0.8106914  1.14888  ]\n",
      "[-0.42360422  1.621548  ]\n",
      "[-0.49215755  1.4684026 ]\n",
      "[62523, 1420666]\n",
      " 1483189/1500000: episode: 761, duration: 3.141s, episode steps: 1949, steps per second: 621, episode reward: 319.600, mean reward: 0.164 [-143.000, 210.500], mean action: 0.967 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 61.126213, mean_absolute_error: 2.090224, mean_q: -0.414820\n",
      "[-1.0370952   0.90009457]\n",
      "[-3.587425e-04  1.738701e+00]\n",
      "[-0.6891679  1.4065993]\n",
      "[-0.6414686  1.5867418]\n",
      "[-1.0684195   0.93399745]\n",
      "[62607, 1422531]\n",
      " 1485138/1500000: episode: 762, duration: 3.270s, episode steps: 1949, steps per second: 596, episode reward: 226.600, mean reward: 0.116 [-195.400, 121.500], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 56.284611, mean_absolute_error: 2.022878, mean_q: -0.414848\n",
      "[-1.1017401  0.9255993]\n",
      "[-0.7768265   0.66459453]\n",
      "[-0.52180666  1.0688686 ]\n",
      "[-0.90474844  0.5658823 ]\n",
      "[-0.58737266  1.2314787 ]\n",
      "[62677, 1424410]\n",
      " 1487087/1500000: episode: 763, duration: 3.309s, episode steps: 1949, steps per second: 589, episode reward: 619.500, mean reward: 0.318 [-86.200, 242.000], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 57.334919, mean_absolute_error: 2.185578, mean_q: -0.415283\n",
      "[-0.98310673  1.6702076 ]\n",
      "[-1.5107086  1.2214633]\n",
      "[-1.6830227  1.3167753]\n",
      "[-1.2700585  1.0505582]\n",
      "[-1.1385434  0.7181124]\n",
      "[62744, 1426292]\n",
      " 1489036/1500000: episode: 764, duration: 3.328s, episode steps: 1949, steps per second: 586, episode reward: 544.700, mean reward: 0.279 [-110.200, 173.400], mean action: 0.966 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 36.895550, mean_absolute_error: 1.677691, mean_q: -0.415993\n",
      "[-0.61244255  1.2888292 ]\n",
      "[-0.5553621  0.8026329]\n",
      "[-0.67995197  1.5878835 ]\n",
      "[-0.53966516  1.7702091 ]\n",
      "[-1.1196625  1.3055781]\n",
      "[62815, 1428170]\n",
      " 1490985/1500000: episode: 765, duration: 3.253s, episode steps: 1949, steps per second: 599, episode reward: 488.600, mean reward: 0.251 [-114.000, 263.800], mean action: 0.964 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 44.270676, mean_absolute_error: 1.906895, mean_q: -0.416588\n",
      "[-1.1485958   0.94504166]\n",
      "[-0.9450309  1.2179424]\n",
      "[-0.609196   1.0995169]\n",
      "[-0.9761666  1.3536485]\n",
      "[-0.9397677   0.84576255]\n",
      "[62896, 1430038]\n",
      " 1492934/1500000: episode: 766, duration: 3.734s, episode steps: 1949, steps per second: 522, episode reward: 462.800, mean reward: 0.237 [-87.400, 192.000], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 48.592594, mean_absolute_error: 1.805842, mean_q: -0.416984\n",
      "[-0.52660495  1.0165032 ]\n",
      "[-0.6378623  1.4406663]\n",
      "[-0.9350071  1.4750009]\n",
      "[-0.7749694  1.7603964]\n",
      "[-0.46453547  0.782323  ]\n",
      "[62972, 1431911]\n",
      " 1494883/1500000: episode: 767, duration: 3.301s, episode steps: 1949, steps per second: 590, episode reward: 369.900, mean reward: 0.190 [-111.500, 151.100], mean action: 0.961 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 66.423920, mean_absolute_error: 2.383920, mean_q: -0.417570\n",
      "[-0.92585087  1.2025125 ]\n",
      "[-1.0041344  1.2786516]\n",
      "[-0.53175944  1.4898962 ]\n",
      "[-0.8645078  1.9103401]\n",
      "[-0.64265925  1.2456805 ]\n",
      "[63055, 1433777]\n",
      " 1496832/1500000: episode: 768, duration: 3.390s, episode steps: 1949, steps per second: 575, episode reward: 589.600, mean reward: 0.303 [-106.600, 115.600], mean action: 0.957 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 75.083786, mean_absolute_error: 2.270796, mean_q: -0.418291\n",
      "[-1.0002928  1.2016425]\n",
      "[-0.67855626  1.0033087 ]\n",
      "[-1.0587646  1.5825902]\n",
      "[-1.0828402  1.0963314]\n",
      "[63137, 1435644]\n",
      " 1498781/1500000: episode: 769, duration: 3.290s, episode steps: 1949, steps per second: 592, episode reward: 594.500, mean reward: 0.305 [-93.600, 129.600], mean action: 0.958 [0.000, 1.000], mean observation: 0.533 [-0.005, 1.095], loss: 46.141788, mean_absolute_error: 1.962672, mean_q: -0.418862\n",
      "[-1.163446    0.95802283]\n",
      "[-0.62924075  1.5994927 ]\n",
      "[-0.8844455  1.6999863]\n",
      "[-0.83549625  1.872596  ]\n",
      "done, took 2730.525 seconds\n",
      "done, took 2730.525 seconds\n"
     ]
    }
   ],
   "source": [
    "agent.fit(env, nb_steps=1500000, callbacks=callbacks, visualize=False, verbose=2)\n",
    "agent.save_weights('dqn_weights_{}_final.h5f'.format(train_no), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = 13\n",
    "agent.load_weights('dqn_weights_{}_final.h5f'.format(no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gym.make('forex-v0', frame_bound=(50,2000), window_size=window_size)\n",
    "env_test.reset()\n",
    "processor.train_mode(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 1 episodes ...\n",
      "[0.42188352 0.5781165 ]\n",
      "[0.4715852  0.52841485]\n",
      "[0.3474589 0.6525411]\n",
      "[0.4439975  0.55600244]\n",
      "[0.45925543 0.54074454]\n",
      "[128, 3770]\n",
      "Episode 1: reward: 490.300, steps: 1949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2c823ef0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.test(env_test,visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6327154085620736\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(env_test.max_possible_profit())\n",
    "plt.cla()\n",
    "env_test.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot train graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2b6b9208>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "no = 13\n",
    "\n",
    "csv_data = pandas.read_csv('dqn_log_{}.csv'.format(no), delimiter=',', header=None)\n",
    "plt.plot(csv_data[0],csv_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
